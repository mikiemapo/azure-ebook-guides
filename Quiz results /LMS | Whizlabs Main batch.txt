10/5/25, 15:19LMS | Whizlabs
Page 1 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationPractice Test III - Practice ModeCompleted on Sun, 21 Sep 20251stAttempt28/55Marks Obtained50.91%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Manage Azure identities andgovernance17116002Implement and manage storage1477003Deploy and manage Azurecompute resources1248004Implement and manage virtualnetworking1064005Monitor and maintain Azureresources20200TotalAll Domains55282700Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Implement and manage virtual networkingHome/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Practice Test III/ReportBack to the Courseh
Download Report
10/26/25, 10:14LMS | Whizlabs
Page 1 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
Incorrect
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationAzure Virtual Networks - Practice ModeCompleted on Sun, 26 Oct 20251stAttempt2/6Marks Obtained33.33%Your ScoreFAILResultDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Implement and manage virtualnetworking62400TotalAll Domains62400Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Implement and manage virtual networkingYour organization is deploying various types of load balancers in an Azure environment, each serving different purposes. Each loadbalancer requires a specific type of IP address configuration. Match each load balancer scenario with the most appropriate public orprivate IP configuration.Scenarios:Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Azure Virtual Networks/ReportBack to the Courseh
Download Report
A public-facing load balancer with multiple backend virtual machines.An internal load balancer managing traffic across private subnets.A cross-region load balancer for a global application.
boDashboardMy CoursesHands-on LabsSandboxSupport

10/26/25, 10:14LMS | Whizlabs
Page 2 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
 Note: Match the load balancer scenarios with their correct public IP allocation method. (Check both the tables correctly)
Explanation:Correct Answers: 1-A, 2-C, 3-D and 4-B
1. Public-facing load balancer requires a Standard SKU Static Public IP. This is the best choice because a public-facing loadbalancer distributes internet traffic, and a static IP address ensures a consistent, unchanging address. This is critical for DNSA load balancer requires sticky sessions for consistent client-server mapping.
Your AnswersA. Standard SKU Static Public IPLoad balancer with sticky sessions
B. Standard SKU Dynamic Public IPCross-region load balancer
C. Basic SKU Public IPPublic-facing load balancer
D. Private IPInternal load balancerCorrect AnswersA. Standard SKU Static Public IPPublic-facing load balancerB. Standard SKU Dynamic Public IPCross-region load balancerC. Basic SKU Public IPLoad balancer with sticky sessionsD. Private IPInternal load balancer
Public-facing load balancer 
 Standard SKU Static Public IPInternal load balancer 
 Private IPCross-region load balancer 
 Standard SKU Dynamic Public IPLoad balancer with sticky sessions 
 Basic SKU Public IP
10/26/25, 10:14LMS | Whizlabs
Page 3 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
configurations and for high-availability, high-traffic applications.2. Internal load balancer requires a Private IP. An internal load balancer operates exclusively within a virtual network and is notexposed to the public internet. Therefore, it uses a private IP address for traffic management between resources withinprivate subnets, enhancing security by keeping traffic isolated.3. Cross-region load balancer requires a Standard SKU Dynamic Public IP. Cross-region load balancers are designed forglobally distributed applications. The dynamic nature of the IP allows it to adapt to routing changes and efficiently redirecttraffic in response to regional failures or latency shifts, which is essential for high availability and resilience across multipleregions.4. Load balancer with sticky sessions requires a Basic SKU Public IP. Sticky sessions (or session persistence) ensure that aclient's requests are consistently routed to the same backend instance. For this purpose, the Basic SKU is a cost-effectiveoption that provides the necessary functionality without the advanced features of the Standard SKU, making it suitable forsmaller-scale applications.
References:
Ask our Expertshttps://learn.microsoft.com/en-us/azure/virtual-network/ip-services/public-ip-addresses#statichttps://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-overview#internal-load-balancerhttps://learn.microsoft.com/en-us/azure/load-balancer/cross-region-overview#standard-skuhttps://learn.microsoft.com/en-us/azure/load-balancer/distribution-mode-concepts#session-persistence
10/26/25, 10:14LMS | Whizlabs
Page 4 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
CorrectDid you like this Question?Question 2Domain: Implement and manage virtual networkingA web app hosted in an Azure VM is unreachable from other VNets in the same region, even though VNet peering is configured.  Whatsteps should you take to troubleshoot? (Select two options)
Explanation:Correct Answers: A and BOption A: Confirm NSG rules allow traffic between the VNets is correct because Network Security Groups (NSGs) control inbound andoutbound traffic to subnets and virtual machines (VMs). When VNets are peered, the traffic between them must comply with NSGrules on both ends. If the NSG rules block traffic from the source or to the destination VNet, communication will fail. For example, NSGrules might allow only specific source IP ranges or block traffic on required ports. You need to ensure that the NSG allows theappropriate protocol (e.g., TCP) and port (e.g., 80 or 443 for a web app) for communication between the VNets. Additionally, NSG logscan be reviewed in Azure Monitor to confirm whether traffic is being denied. This helps identify misconfigurations.Option B: Check if a UDR overrides system routes for peered VNets is correct because user-defined routes (UDRs) allow customrouting for traffic within a VNet, including traffic to peered VNets. However, a misconfigured UDR can override the system route thatdirects traffic to a peered VNet. For instance, if a UDR is configured to route traffic for the target VNet’s address space to an invalidnext hop (e.g., a non-existent virtual appliance), communication will fail. You need to validate the route table associated with thesource subnet and ensure that the route for the peered VNet has "Virtual Network" as its next hop. Azure’s effective routes feature canbe used to inspect the routes applied to a VM’s NIC.A. Confirm NSG rules allow traffic between the VNetsrightB. Check if a UDR overrides system routes for peered VNetsrightC. Enable gateway transit on the peered VNetsD. Verify DNS resolution for the web app’s hostnameE. Associate the VM's NIC with a public IP address
10/26/25, 10:14LMS | Whizlabs
Page 5 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
Incorrect
Option C: Enable gateway transit on the peered VNets is incorrect because gateway transit is used to share a virtual networkgateway across peered VNets for connecting to on-premises resources or other VNets. It is not required for direct communicationbetween resources in peered VNets within the same region. Enabling gateway transit would have no impact on resolving thecommunication issue described in this scenario.Option D: Verify DNS resolution for the web app’s hostname is incorrect because DNS resolution is necessary for resolving hostnamesto IP addresses. However, the issue described is about the inability to communicate between VNets, not an inability to resolve DNS.Even if DNS is not configured, direct communication using IP addresses should still be possible if the routing and NSG rules arecorrectly configured.Option E: Associate the VM's NIC with a public IP address is incorrect because a public IP address is not required for communicationbetween peered VNets. Peered VNets use Azure's backbone network for connectivity, which is private and does not involve the publicInternet. Associating a public IP with the VM is unnecessary and does not address the root cause of the problem.References: 
Ask our ExpertsDid you like this Question?Question 3https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overviewhttps://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview
10/26/25, 10:14LMS | Whizlabs
Page 6 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
Domain: Implement and manage virtual networkingYou are configuring a complex set of rules for an Application Security Group (ASG) to restrict inbound access to multiple Azure virtualmachines (VMs). The VMs reside in different subnets of the same virtual network. Each VM is configured to belong to a unique ASGbased on its function (e.g., web, application, database). While testing connectivity, you notice that the web VMs cannot access theapplication VMs, even though the ASG rules should allow the traffic. What is the most likely issue?
Explanation:Correct Answer: DOption D: The NSG rules for the application VMs override the ASG rules, blocking communication is correct. Network Security Groups(NSGs) are processed before Application Security Groups (ASGs). An NSG applied to a subnet or network interface controls traffic at agranular level. If an NSG rule on the application VMs' subnet or network interface explicitly denies traffic from the web VMs, that rulewill take precedence and block the traffic, regardless of any ASG rules that might be configured to allow it. This is the most commonreason for this type of misconfiguration.
Option A: The NSG associated with the web VMs is missing an outbound rule to permit traffic to the application VMs is incorrect. Theproblem described is that web VMs cannot access the application VMs, which points to an inbound access issue on the destinationA. The NSG associated with the web VMs is missing an outbound rule to permit traffic to the application VMsB. The ASG is not correctly configured to allow cross-subnet communication between the web and application tierswrongC. The application VMs have conflicting DNS settings that prevent them from resolving the web VM IP addressesD. The NSG rules for the application VMs override the ASG rules, blocking communicationright
10/26/25, 10:14LMS | Whizlabs
Page 7 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
Incorrect(application) VMs. The outbound rules on the source (web) VMs would only prevent them from initiating the traffic, not receiving aresponse, which is a different issue.Option B: The ASG is not correctly configured to allow cross-subnet communication between the web and application tiers isincorrect. ASGs are designed to simplify security management and do not, by themselves, restrict communication across subnets.The default behavior in a virtual network is to allow communication between subnets unless an NSG explicitly blocks it.Option C: The application VMs have conflicting DNS settings that prevent them from resolving the web VM IP addresses is incorrect.DNS issues relate to name resolution, not the blocking of network traffic itself. If the VMs were using IP addresses for communication,DNS would not be a factor, yet the traffic would still be blocked. The issue is with traffic flow, not name resolution.References: 
Ask our ExpertsDid you like this Question?Question 4Domain: Implement and manage virtual networkingYou are managing a virtual network (VNet) named “ProdVNet” with three subnets: “WebSubnet”, “AppSubnet”, and “DbSubnet”. The“WebSubnet” needs to route all outbound traffic to the internet via a Network Virtual Appliance (NVA) with an IP address of 10.0.1.4. The“AppSubnet” should route traffic destined for “DbSubnet” directly without any intermediary devices. You must configure user-definedroutes (UDRs) to implement this design. Which actions should you take to achieve the configuration? (Select three)
Explanation:Correct Answers: A, B and EOption A: Create a route table named “NvaRouteTable”, add a route with the destination prefix 0.0.0.0/0, and set the next hop type toVirtual Appliance with the next hop address 10.0.1.4 is correct.This step correctly defines a User-Defined Route (UDR) to force allhttps://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overviewhttps://learn.microsoft.com/en-us/azure/virtual-network/application-security-groups
A. Create a route table named “NvaRouteTable”, add a route with the destination prefix 0.0.0.0/0, and set the next hop type toVirtual Appliance with the next hop address 10.0.1.4rightB. Associate “NvaRouteTable” with the “WebSubnet”rightC. Create a route table named “AppToDbRouteTable”, add a route with the destination prefix 10.0.3.0/24, and set the next hop typeto VNet PeeringD. Associate “AppToDbRouteTable” with the “AppSubnet”wrongE. Ensure that the NVA is configured with IP forwarding enabled and placed in the same subnet as “WebSubnet”right
10/26/25, 10:14LMS | Whizlabs
Page 8 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
outbound internet traffic from the "WebSubnet" through a specific network appliance. The 0.0.0.0/0 prefix represents the default routefor all traffic not covered by other routes, and specifying the next hop as a Virtual Appliance with its private IP address ensures thattraffic is directed to the NVA for inspection.Option B: Associate “NvaRouteTable” with the “WebSubnet” is correct. A route table's rules only take effect when it is associated witha specific subnet. By linking "NvaRouteTable" to the "WebSubnet," all resources within that subnet will use the defined UDR to route theirinternet-bound traffic through the NVA, as required.Option E: Ensure that the NVA is configured with IP forwarding enabled and placed in the same subnet as “WebSubnet” is correct. Forthe NVA to function as a router, IP forwarding must be enabled. This allows it to forward traffic not addressed to its own IP. Additionally,the NVA must be in the same subnet as the "WebSubnet" to be a valid next hop for the UDR. Without this configuration, traffic would bedropped at the NVA, and the routing would fail.
Option C: Create a route table named “AppToDbRouteTable”, add a route with the destination prefix 10.0.3.0/24, and set the next hoptype to VNet Peering is incorrect. This is unnecessary and incorrect. Both "AppSubnet" and "DbSubnet" are in the same VNet("ProdVNet"). Azure's default routing behavior allows direct communication between subnets within the same VNet, so no UDR isneeded. VNet Peering is only used for communication between different VNets.Option D: Associate “AppToDbRouteTable” with the “AppSubnet” is incorrect. This action is not needed because the requiredcommunication between "AppSubnet" and "DbSubnet" is handled by Azure's default routing. Creating and associating a UDR for thispurpose would be redundant and potentially cause routing conflicts.Reference: Ask our Expertshttps://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview
10/26/25, 10:14LMS | Whizlabs
Page 9 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
IncorrectDid you like this Question?Question 5Domain: Implement and manage virtual networkingYou are tasked with configuring DNS settings for a multi-region Azure deployment. The organization has two Azure regions: East US andWest US. A global application with backend services spread across both regions requires internal name resolution between theregions. What feature of Azure DNS should you configure to ensure consistent and accurate name resolution across both regions?
Explanation:Correct Answer: BOption B: Azure DNS Private Zones with VNet linking is correct because Azure DNS Private Zones allow you to manage DNS records foryour private domains within your Azure environment. By linking Azure DNS Private Zones to multiple VNets, you enable internal DNSresolution across regions. This configuration allows resources in different Azure regions, like East US and West US, to resolve eachother's names accurately and consistently, ensuring proper internal communication between services spread across regions. Linkingprivate DNS zones to multiple VNets means that each VNet (whether in East US or West US) can use the same DNS zone for nameresolution, providing a seamless experience for internal resources. This solution is ideal for multi-region deployments where you needprivate name resolution between services without relying on external DNS solutions.A. Azure DNS with Geo-location based routingwrongB. Azure DNS Private Zones with VNet linkingrightC. Azure DNS Public Zones for regional endpointsD. Azure Load Balancer with DNS resolution configuration
10/26/25, 10:14LMS | Whizlabs
Page 10 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
Option A: Azure DNS with Geo-location based routing is incorrect because Azure DNS does not directly support Geo-location basedrouting for internal DNS resolution between regions. Geo-location routing is typically a feature provided by Azure Traffic Manager forglobal traffic routing, not Azure DNS. It helps route traffic based on geographic location, but it is not designed for internal nameresolution across multiple Azure regions. Geo-location based routing would be relevant for public traffic that needs to be directed tothe nearest region, but internal DNS resolution for resources in different regions is typically handled through Private DNS Zones inAzure. Hence, this option does not fit the requirement of internal name resolution across regions in the context of Azure DNS.Option C: Azure DNS Public Zones for regional endpoints is incorrect because Azure DNS Public Zones are intended for public DNSresolution, meaning they handle domain name resolution for resources that are accessible from the internet. In the case of multi-region deployments, public zones are used for services exposed to the public internet, such as web apps or APIs. Since therequirement is for internal name resolution between regions (East US and West US), using public DNS zones is not appropriate. PrivateDNS Zones are designed for this exact purpose, providing DNS resolution within the Azure environment without exposing internalservices to the public internet.Option D: Azure Load Balancer with DNS resolution configuration is incorrect because while Azure Load Balancer can help distributetraffic between backend resources, it does not provide the DNS resolution required for internal communication between resources indifferent regions. Azure Load Balancer operates within a single region and does not offer DNS-based routing for multiple regions.Although Load Balancer can be used in conjunction with DNS settings for public-facing services (for example, resolving the domain tothe correct Load Balancer IP), it is not the correct solution for internal DNS resolution between Azure regions. DNS resolution for multi-region internal traffic must be handled by Azure DNS Private Zones, not Azure Load Balancer.References: https://learn.microsoft.com/en-us/azure/dns/private-dns-overviewhttps://learn.microsoft.com/en-us/azure/dns/private-dns-virtual-network-links
10/26/25, 10:14LMS | Whizlabs
Page 11 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
CorrectAsk our ExpertsDid you like this Question?Question 6Domain: Implement and manage virtual networkingA company deployed an Azure virtual machine scale set (VMSS) behind an Azure Load Balancer to distribute HTTP traffic. Users reportintermittent connection failures when accessing the application. Upon inspection, it is found that health probes intermittently fail insome instances. The configuration shows that the probe interval is set to 5 seconds, and the unhealthy threshold is set to 2.Proposed Solution: Increase the probe interval to 15 seconds and the unhealthy threshold to 5, ensuring longer timeouts for healthchecks. This will stabilize the connection and resolve the issue. Is this proposed solution correct? (Select Yes or No)
Explanation:Correct Answer: BThe proposed solution is incorrect because increasing the probe interval and unhealthy threshold does not address the root cause ofthe intermittent connection failures. Instead, it only delays the detection of unhealthy instances. This can lead to a degraded userexperience as the load balancer continues to send traffic to instances that are not responding correctly.Intermittent failures are often caused by underlying application issues such as:A. YesB. Noright
Misconfigured health probe endpointsInsufficient resource allocationPerformance bottlenecks
10/26/25, 10:14LMS | Whizlabs
Page 12 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566
The correct approach is to identify and fix these underlying problems. A more effective solution would be to ensure the health probeendpoint is lightweight and reliable. If a change to the probe settings is necessary, a moderate adjustment would be better than anexcessive one, which would sacrifice the load balancer's responsiveness.Reference: Ask our ExpertsDid you like this Question?Finish ReviewAzure Load Balancer health probes | Microsoft Learn
Hands-on LabsSandboxSubscriptionFor BusinessLibrary
10/26/25, 10:14LMS | Whizlabs
Page 13 of 13https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70458/report/8460566CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

←Back to Study Hub
Personalized Review: W eak Spot Focus
Your Next Steps Tracker
Next Step: Deploy & Manage Compute (~37% Mastery)
Next Flashcard:
→VM Creation vs Migration Steps
Next Lab:
→VM Migration & Disk Snapshot Lab  (40 min) • Deploy VM & App Service  (35 min)
• Create Users, Groups, Assign Roles  (25 min)
Current Performance Snapshot
Your AZ-104 Study Breakdown
Overall Quiz Score: 49%
Domain Mastery: (Based on your conﬁdence ratings below)
Identities &
Governance5 7 % 25/4
Storage 4 3 % 17/4This section guides you to your next priority ﬂashcard and lab. Mark items as 'Strong' to
progress!
Scores ▾10/19/25, 6:18 PM Personalized Review: Weak Spot Focus (AZ-104)
ﬁle:///Users/mike1macbook/Documents/MY STUFF DOCS AND ALL/EBOOK/azure_personalized_review_guide.html#idgov-lab-1 1/9
Compute 3 7 % 14/3
Networking 5 8 % 18/3
Monitoring 5 4 % 14/2
Domain 1: Manage Azure Identities and Governance
Recent Quiz Focus:  Entra Kerberos integration for Azure Files, Hybrid AD DS
authentication, RBAC vs Share-Level permissions, User proﬁle updates (Job Info
blade), Group-based licensing & roles, Guest/B2B invites and external-to-internal
conversion, SSPR methods per group, and Entra portal navigation awareness.
(25/44 correct, 57%)
Snapshot & Personalized Review
Weak Spot Focus: Group-based licensing & roles, Guest/B2B invites & conversions, Self-service
password reset (methods & per-group targeting), Entra portal navigation, RBAC vs Entra DS
distinctions.
Action: Drill into the following ﬂashcards and labs to reinforce these topics.
Next Steps Tracker (Identities)
Next Flashcard:
→ RBAC vs Entra ID/DS Permissions
Next Lab:
→ Lab: Create Users, Groups, Assign Roles
Flashcards⭐Focus on the "Storage" domain ﬁrst, as it's identiﬁed as your major weak spot. Use the
ﬂashcards and labs below! Mark your conﬁdence level for each item.10/19/25, 6:18 PM Personalized Review: Weak Spot Focus (AZ-104)
ﬁle:///Users/mike1macbook/Documents/MY STUFF DOCS AND ALL/EBOOK/azure_personalized_review_guide.html#idgov-lab-1 2/9
RBAC vs Entra ID/DS Permissions Identities Rate Confidence
Role Assignment CLI vs Portal Identities Rate Confidence
RBAC vs Entra DS (AD DS) Deep Dive Identities Rate Confidence
CLI vs Microsoft Graph Identities Rate Confidence
RBAC Scope Levels (Sub, RG, Resource) Identities Rate Confidence
Azure Files with Entra DS Authentication Identities Rate Confidence
Lab Tracker
1. Manage Azure subscriptions and governance
Create Users, Groups, Assign Roles(25 min)
Guest/B2B Invite Flow Lab(20 min)
Domain 2: Implement and Manage Storage
 10/19/25, 6:18 PM Personalized Review: Weak Spot Focus (AZ-104)
ﬁle:///Users/mike1macbook/Documents/MY STUFF DOCS AND ALL/EBOOK/azure_personalized_review_guide.html#idgov-lab-1 3/9
Recent Quiz Focus:  Azure Files identity-based access, Soft Delete retention (365
days), Snapshots before deletion, Blob V ersioning, Object replication preﬁx ﬁlters,
Private Endpoints, TLS supported versions (1.0–1.2), SAS for temporary access,
Customer-managed keys, Firewall restrictions with VNets, endpoint selection for secure
SMB access
(17/40 correct, 43%)
Snapshot & Personalized Review
Weak Spot Focus: Azure Files auth, immutability, soft delete, replication tiers, SMB ports.
Action: Use the ﬂashcards and labs below to reinforce your storage skills.
Next Steps Tracker (Storage)
Next Flashcard:
→ RBAC vs NTFS Permissions on Azure Files
Next Lab:
→ Lab: Conﬁgure Azure Files Auth & Recovery
Flashcards
RBAC vs NTFS Permissions on Azure Files Storage Rate Confidence
Soft Delete vs Snapshot Storage Rate Confidence
Replication Tiers (LRS, ZRS, GRS, RA-GRS) Storage Rate Confidence
10/19/25, 6:18 PM Personalized Review: Weak Spot Focus (AZ-104)
ﬁle:///Users/mike1macbook/Documents/MY STUFF DOCS AND ALL/EBOOK/azure_personalized_review_guide.html#idgov-lab-1 4/9
SMB Ports for Azure Files Storage Rate Confidence
Azure Files Access in VNets (Endpoints & Firewalls) Storage Rate Confidence
Immutable Storage Policies (WORM) Storage Rate Confidence
Lab Tracker
3. Conﬁgure Azure Files and Azure Blob Storage
Conﬁgure Azure Files Auth & Recovery(30 min)
Challenge #1 Blob Storage Tiering & Snapshots(25 min)
Domain 3: Deploy and Manage Azure Compute Resources
(14/38 correct, 37%)
Snapshot & Personalized Review
Weak Spot Focus: App Service runtimes, ACI scaling, VM migration and deployment.
Action: Use the following ﬂashcards and labs to reinforce compute management.
Next Steps Tracker (Compute)
Next Flashcard:
→ VM Creation vs Migration Steps
Next Lab:
10/19/25, 6:18 PM Personalized Review: Weak Spot Focus (AZ-104)
ﬁle:///Users/mike1macbook/Documents/MY STUFF DOCS AND ALL/EBOOK/azure_personalized_review_guide.html#idgov-lab-1 5/9
→ Lab: Deploy VM & App Service
Flashcards
VM Creation vs Migration Steps Compute Rate Confidence
App Service Runtime Options Compute Rate Confidence
VM Migration Order & Encryption Compute Rate Confidence
Azure Container Instances (ACI) Scaling Compute Rate Confidence
Lab Tracker
5. Create and conﬁgure VMs
Deploy VM & App Service(35 min)
VM Migration & Disk Snapshot Lab(40 min)
Domain 4: Conﬁgure and Manage Virtual Networking
Recent Quiz Focus:  Azure Storage Firewalls & VNets, restricting access to corporate
IP ranges and VNets, Azure Files private endpoints vs service endpoints, on-prem SMB
10/19/25, 6:18 PM Personalized Review: Weak Spot Focus (AZ-104)
ﬁle:///Users/mike1macbook/Documents/MY STUFF DOCS AND ALL/EBOOK/azure_personalized_review_guide.html#idgov-lab-1 6/9
access over VPN/ExpressRoute
(18/31 correct, 58%)
Snapshot & Personalized Review
Weak Spot Focus: LB SKUs, NAT vs LB rules, subnets, routes, NSGs, peering, hub-spoke.
Action: Use these ﬂashcards and labs to reinforce networking concepts.
Next Steps Tracker (Networking)
Next Flashcard:
→ LB SKU Differences
Next Lab:
→ Lab: Conﬁgure VNet, Subnets, NSGs
Flashcards
LB SKU Differences Networking Rate Confidence
NAT vs LB Rules Networking Rate Confidence
NAT vs LB Rules
LB Rule: Distributes incoming trafﬁc to all VMs in backend pool (many-to-many).
NAT Rule: Maps a speciﬁc external port to a single VM (one-to-one), typically for
management (RDP/SSH).
LB Rule = load balancing; NAT Rule = direct access.
Mnemonic: "NAT = One-to-One, LB = Many"
3-Tier Subnet Design Networking Rate Confidence
10/19/25, 6:18 PM Personalized Review: Weak Spot Focus (AZ-104)
ﬁle:///Users/mike1macbook/Documents/MY STUFF DOCS AND ALL/EBOOK/azure_personalized_review_guide.html#idgov-lab-1 7/9
Route Tables & Forced Tunneling Networking Rate Confidence
Lab Tracker
8. Conﬁgure virtual networks
Conﬁgure VNet, Subnets, NSGs(40 min)
9. Conﬁgure load balancing
Challenge #2 Load Balancer & NAT Rules Lab(30 min)
Domain 5: Monitor and Maintain Azure Resources
Recent Quiz Focus:  Metrics & Alerts, Log Analytics queries, VM Insights, Dashboards,
Workbooks, Recovery V ault backup and retention.
(14/26 correct, 54%)
Snapshot & Personalized Review
Weak Spot Focus: Metrics, Workbooks, Log Analytics, Dashboards, Alerts.
Action: Review these ﬂashcards and labs to strengthen monitoring skills.
Next Steps Tracker (Monitoring)
Next Flashcard:
→ Conﬁguring Metrics & Alerts
Next Lab:
10/19/25, 6:18 PM Personalized Review: Weak Spot Focus (AZ-104)
ﬁle:///Users/mike1macbook/Documents/MY STUFF DOCS AND ALL/EBOOK/azure_personalized_review_guide.html#idgov-lab-1 8/9
→ Lab: Create Dashboard & Alerts
Flashcards
Conﬁguring Metrics & Alerts Monitoring Rate Confidence
Log Analytics Query Basics Monitoring Rate Confidence
VM Insights Layers Monitoring Rate Confidence
Log Analytics vs Metrics vs Workbooks Monitoring Rate Confidence
Recovery Vault: Backup & Retention Monitoring Rate Confidence
Lab Tracker
11. Monitor resources by using Azure Monitor
Create Alerts and Workbooks(30 min)
KQL Basics & Log Analytics(25 min)
10/19/25, 6:18 PM Personalized Review: Weak Spot Focus (AZ-104)
ﬁle:///Users/mike1macbook/Documents/MY STUFF DOCS AND ALL/EBOOK/azure_personalized_review_guide.html#idgov-lab-1 9/9
10/18/25, 23:57LMS | Whizlabs
Page 1 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
Correct
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationAzure Monitoring - Practice ModeCompleted on Sat, 18 Oct 20251stAttempt2/5Marks Obtained40.00%Your ScoreFAILResultDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Monitor and maintain Azureresources52300TotalAll Domains52300Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Monitor and maintain Azure resourcesAn organization wants to optimize the cost of its Azure resources by analyzing usage patterns. An Azure administrator decides tointerpret Network Out Total and Network In Total metrics for their Virtual Machine Scale Set (VMSS) over the past 30 days using theAzure Monitor Metrics workspace. The administrator uses the default aggregation method, "Average," to identify patterns in networktraffic over time.Proposed Solution: The administrator should switch to the "Total" aggregation method instead of "Average" to evaluate the cumulativenetwork usage of the VMSS effectively. Is this proposed solution correct? (Select Yes or No)Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Azure Monitoring/ReportBack to the Courseh
Download Report
A. Yesright
10/18/25, 23:57LMS | Whizlabs
Page 2 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
Explanation:Correct Answer: AThe proposed solution is valid and correct. When the goal is to analyze usage patterns for cost optimization, the "Total" aggregationmethod is more suitable for cumulative metrics like "Network Out Total" and "Network In Total."
The "Average" aggregation method, while useful for understanding general trends and patterns, does not provide an accurate pictureof the total data transfer volume over a long period. Using "Average" can underestimate resource consumption by averaging outtraffic spikes and dips.By contrast, the "Total" aggregation method sums up the metric values over the selected time range, providing a precisemeasurement of the cumulative data usage. This allows the administrator to accurately identify peak usage periods, determinewhether the current configuration is cost-effective, and make informed decisions about network bandwidth or resource scalingadjustments to reduce costs.Reference: Ask our ExpertsDid you like this Question?B. No
Azure Monitor metrics aggregation and display explained
10/18/25, 23:57LMS | Whizlabs
Page 3 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
IncorrectView Case StudyQuestion 2Domain: Monitor and maintain Azure resourcesYou need to ensure that logs from all production subscriptions (Prod-A, Prod-B, and Prod-C) are centralized in a single Log Analyticsworkspace named CentralWorkspace. Logs must have a 365-day retention policy, and the setup should minimize redundant datatransfer costs. Which of the following step should you perform?
Explanation:Correct Answer: COption C: Use Azure Policy to enforce the diagnostic settings across all subscriptions and connect them to CentralWorkspace iscorrect because Azure Policy is the most effective way to enforce diagnostic log settings across multiple subscriptions. By defining apolicy that applies to all the subscriptions (Prod-A, Prod-B, and Prod-C), Contoso can automate the process of ensuring that all logsare sent to a single centralized Log Analytics workspace, named CentralWorkspace. This approach removes the need to manuallyconfigure each resource or subscription. Once the policy is in place, it will automatically align any non-compliant resources byensuring they direct logs to the appropriate workspace. Applying the policy at the management group level ensures that itautomatically applies to all associated subscriptions. This not only helps streamline log management but also reduces the risk ofunnecessary data transfers, thus lowering costs. Additionally, the retention period of 365 days can be set in the Log Analyticsworkspace to meet regulatory and compliance standards. Overall, using Azure Policy to manage log settings improves operationalefficiency while ensuring consistent adherence to best practices across the entire organization.A. Enable the diagnostic settings for each subscription and direct all logs to CentralWorkspaceB. Configure data collection rules (DCR) in each subscription and route logs to CentralWorkspacewrongC. Use Azure Policy to enforce the diagnostic settings across all subscriptions and connect them to CentralWorkspacerightD. Set up cross-resource query capabilities across existing Log Analytics workspaces instead of centralizing
10/18/25, 23:57LMS | Whizlabs
Page 4 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
Option A: Enable the diagnostic settings for each subscription and direct all logs to CentralWorkspace is incorrect because whileenabling diagnostic settings and directing logs to CentralWorkspace could centralize logs, this option requires configuring settingsindividually for each resource or subscription. This manual approach is error-prone, inefficient for a large-scale environment, and failsto enforce consistent logging policies. Additionally, it does not ensure compliance with the requirement to minimize redundant datatransfer costs, as manual configurations could lead to duplications or misconfigurations.Option B: Configure data collection rules (DCR) in each subscription and route logs to CentralWorkspace is incorrect because DataCollection Rules (DCR) are primarily used to configure and manage telemetry collection for Azure Monitor metrics and custom logdata. While they offer flexibility for data ingestion, they are not the recommended approach for enforcing diagnostic settings at asubscription level. Moreover, DCRs are more suitable for custom scenarios, not for the centralized, automated enforcement neededacross multiple subscriptions as described in the case study.Option D: Set up cross-resource query capabilities across existing Log Analytics workspaces instead of centralizing is incorrectbecause cross-resource queries allow you to analyze data from multiple Log Analytics workspaces without centralizing logs into asingle workspace. While this can be useful for querying distributed data, it does not address the requirement for centralized logcollection and a unified retention policy. Additionally, querying across multiple workspaces can result in increased latency andcomplexity, making it unsuitable for scenarios requiring streamlined, centralized monitoring and compliance.Reference: Ask our ExpertsDid you like this Question?https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/diagnostic-settings-policy
10/18/25, 23:57LMS | Whizlabs
Page 5 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
IncorrectView Case StudyQuestion 3Domain: Monitor and maintain Azure resourcesA network administrator suspects that intermittent connectivity issues between on-premises and Azure VNETs are caused by an IPconfiguration mismatch on one of the VPN tunnels. Which KQL query should you use in Log Analytics to identify the issue?
Explanation:Correct Answer: AOption A is correct because the query is designed to detect potential IP configuration problems within a Virtual Network Gateway. Itspecifically looks at data in the AzureDiagnostics table, which contains logs for various Azure resources, including network-relatedevents. By filtering for ResourceType = "VirtualNetworkGateway", the query focuses only on logs related to the Virtual Network Gateway,ensuring that the analysis remains relevant without being overwhelmed by data from other resources. The query also searches forthe term "IPMismatch" within the log messages, which helps identify entries related to IP configuration issues that could be causingintermittent connectivity problems. Additionally, the use of the project operator retrieves only the essential fields TimeGenerated,ResourceId, and Message making the results more concise and easier to interpret. Overall, this query effectively targets the specificproblem described in the scenario, offering a streamlined approach to identifying and troubleshooting the issue.A. AzureDiagnostics | where ResourceType == "VirtualNetworkGateway" | where Message contains "IPMismatch" | projectTimeGenerated, ResourceId, Message rightB. NetworkConnections | where Protocol == "TCP" | where Direction == "Inbound" and Port == 443 | summarize count() by RemoteIP,ResourceId wrongC. AzureNetworkLogs | where Category == "GatewayDiagnosticLogs" | where Message contains "Latency" | summarize AvgLatency= avg(ResponseTime) by ResourceIdD. VMConnection | where Status == "Failed" | summarize FailureCount = count() by ResourceId
10/18/25, 23:57LMS | Whizlabs
Page 6 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
Option B is incorrect because this query inspects TCP connections to resources, filtering for inbound connections on port 443(typically HTTPS). While this might help analyze general network activity, it does not focus on Virtual Network Gateways or IPmismatches, which are the primary concern here. Additionally, it summarizes connection counts, which does not provide detailedinsights into intermittent connectivity issues caused by configuration mismatches. This query is better suited for analyzing connectiontrends or traffic patterns.Option C is incorrect because this query analyzes logs for latency-related metrics using the AzureNetworkLogs table and theGatewayDiagnosticLogs category. While it provides information about response times and latency for gateways, it does not addressIP mismatches. Focusing on latency metrics would be irrelevant in this context because the issue is likely caused by configurationerrors, not performance bottlenecks.Option D is incorrect because this query investigates failed connections to virtual machines by analyzing the VMConnection table.Although connection failures could indicate potential issues, the scenario is specific to a Virtual Network Gateway and involves an IPmismatch, not VM connectivity. This query is unrelated to the described problem and would not yield any actionable insights for thenetwork administrator.References: 
Ask our Expertshttps://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/azurediagnosticshttps://learn.microsoft.com/en-us/azure/azure-monitor/logs/log-query-overviewhttps://learn.microsoft.com/en-us/azure/azure-monitor/essentials/diagnostic-settings
boDashboardMy CoursesHands-on LabsSandboxSupport

10/18/25, 23:57LMS | Whizlabs
Page 7 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
CorrectView Case StudyDid you like this Question?Question 4Domain: Monitor and maintain Azure resourcesContoso needs to create an alert rule that triggers when the average CPU usage of any production VM exceeds 85% for 5 minutes.Notifications should be sent to both the DevOps team via email and the Operations team via SMS.  What is the most efficientconfiguration to achieve this?
Explanation:Correct Answer: COption C: Configure a metric alert rule at the subscription level, define the CPU usage threshold, and link it to a unified action groupwith email and SMS contacts is correct because this is the most efficient and scalable solution. Metric alert rules at the subscriptionlevel enable monitoring of all VMs across the subscription and automatically include new VMs that meet the defined criteria (e.g.,tagging or resource type). By defining a threshold for average CPU usage (e.g., exceeding 85% for 5 minutes), the rule ensuresproactive monitoring. Linking the alert rule to a unified action group ensures that notifications are sent simultaneously via email to theDevOps team and via SMS to the Operations team. Automatically includes all current and future VMs under the subscription. Reducescomplexity compared to configuring multiple rules or scoping to a resource group. Using a single action group simplifies notificationconfiguration and ensures that all recipients (DevOps and Operations teams) are informed simultaneously. Metric alerts areoptimized for performance and scalability compared to log-based alerts, especially for high-frequency signals like CPU usage.A. Create an alert rule scoped to the VM resource group, define a CPU usage condition, and assign an action group with emailand SMS contactsB. Create separate alert rules for each VM, define a CPU threshold condition, and link them to individual action groups for emailand SMS notificationsC. Configure a metric alert rule at the subscription level, define the CPU usage threshold, and link it to a unified action group withemail and SMS contactsrightD. Use Log Analytics to query CPU metrics and set up a log alert with integrated action groups for email and SMS notifications
10/18/25, 23:57LMS | Whizlabs
Page 8 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
Option A: Create an alert rule scoped to the VM resource group, define a CPU usage condition, and assign an action group withemail and SMS contacts is incorrect because while creating an alert rule scoped to the resource group is possible, it is less efficientfor scenarios involving multiple VMs in production. Resource group-level scoping is limited because it does not dynamically apply toall VMs if new resources are added to the group after the alert is configured. Moreover, resource group scoping is less precisecompared to subscription-level metric alert rules that can inherently apply to all relevant VMs.Option B: Create separate alert rules for each VM, define a CPU threshold condition, and link them to individual action groups foremail and SMS notifications is incorrect because creating separate alert rules for each VM is an inefficient approach, especially inenvironments with multiple or dynamically scaled VMs. This method introduces high administrative overhead and makes themanagement of alerts more complex. Additionally, it increases the risk of inconsistency in configuration across VMs. Subscription-level alert rules combined with unified action groups are more scalable and easier to maintain.Option D: Use Log Analytics to query CPU metrics and set up a log alert with integrated action groups for email and SMSnotifications is incorrect because log-based alerts can provide detailed and flexible analysis, but they are less efficient than metric-based alerts for monitoring resource-specific metrics like CPU usage. Log alerts rely on custom queries and may incur additionallatency due to the ingestion of data into the Log Analytics workspace. For real-time scenarios like CPU monitoring, metric alerts aremore suitable as they directly pull data from the Azure Monitor metrics pipeline, providing faster and more reliable triggering.References: 
Ask our Expertshttps://learn.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-create-metric-alert-rulehttps://learn.microsoft.com/en-us/azure/azure-monitor/alerts/action-groupshttps://learn.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-overview
10/18/25, 23:57LMS | Whizlabs
Page 9 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
IncorrectView Case StudyDid you like this Question?Question 5Domain: Monitor and maintain Azure resourcesYou need to monitor end-to-end connectivity between your on-premises network and Azure resources.  Contoso’s IT team hasconfigured Connection Monitor in Azure Network Watcher. However, they need to test latency across VPN tunnels proactively. Whichadditional configuration should you implement to meet this requirement?
Explanation:Correct Answer: DOption D: Enable packet capture in Azure Network Watcher and analyze captured packets for latency patterns is correct becausePacket capture allows for a detailed analysis of network traffic. By capturing packets as they traverse the VPN tunnels, you canexamine timestamps and response delays within the captured data to identify specific latency issues. This method is highly effectivefor troubleshooting complex network problems where granular, packet-level details are necessary.A. Add a network topology map to visualize VPN latency metrics in real-time using Network WatcherB. Set up Traffic Analytics in Azure Network Watcher to analyze real-time data flow and detect latency issuesC. Use the IP Flow Verify tool in Azure Network Watcher to validate the IP path and measure latencywrongD. Enable packet capture in Azure Network Watcher and analyze captured packets for latency patternsright
10/18/25, 23:57LMS | Whizlabs
Page 10 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573
Option A: Add a network topology map to visualize VPN latency metrics in real-time using Network Watcher is incorrect becauseNetwork topology map is a visualization tool that shows the connections between network resources. It does not provide real-timeperformance metrics like latency and cannot be used for proactive testing.Option B: Set up Traffic Analytics in Azure Network Watcher to analyze real-time data flow and detect latency issues is incorrectbecause Traffic Analytics provides a high-level overview of network traffic patterns and flow. It does not offer the granular, packet-level details needed to measure specific latency across a VPN tunnel.Option C: Use the IP Flow Verify tool in Azure Network Watcher to validate the IP path and measure latency is incorrect because IPFlow Verify tool is used to check if an IP packet is allowed to or from a specific source/destination and to diagnose connectivityfailures. It does not measure or monitor performance metrics such as latency.References: 
Ask our ExpertsDid you like this Question?https://learn.microsoft.com/en-us/azure/network-watcher/packet-capture-overviewhttps://learn.microsoft.com/en-us/azure/network-watcher/packet-capture-inspecthttps://learn.microsoft.com/en-us/azure/network-watcher/connection-troubleshoot-overviewhttps://learn.microsoft.com/en-us/azure/network-watcher/network-watcher-overview
10/18/25, 23:57LMS | Whizlabs
Page 11 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70459/report/8455573Finish Review
CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdHands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/18/25, 23:47LMS | Whizlabs
Page 1 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
IncorrectView Case Study
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationAzure Backup and Recovery - Practice ModeCompleted on Sat, 18 Oct 20251stAttempt1/5Marks Obtained20.00%Your ScoreFAILResultDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Monitor and maintain Azureresources51400TotalAll Domains51400Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Monitor and maintain Azure resourcesYou are tasked with creating a Recovery Services vault in the East US region and configuring it to back up an existing Windows virtualmachine named TestVM1. You need to ensure the vault is created under the existing resource group FabrikamRG and is namedFabrikamBackupVault. Once the vault is created, validate its configuration for backup. Arrange the steps in the correct order.Note: To achieve the above requirement drag the correct options and then drop them in the correct order into the answer areaHome/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Azure Backup and Recovery/ReportBack to the Courseh
Download Report
10/18/25, 23:47LMS | Whizlabs
Page 2 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
Explanation:Correct Answers: F, E, C, D, B and  ANavigate to the Azure portal and select "Create a resource":  You start by logging into the Azure portal. Once logged in, click on the"Create a resource" option available on the home page or the left-hand menu. This action is the entry point for provisioning any newresource in Azure. By selecting this, you access the Azure Marketplace where various resource types can be searched and deployed.Search for and select "Recovery Services vault": In the Marketplace search bar, type "Recovery Services vault" and select it from thelist of results. The Recovery Services vault is a specialized Azure resource designed to manage and store backup data for VMs,databases, and other workloads. Selecting it opens the vault creation page where you configure its details.Choose the subscription and resource group FabrikamRG: Once the Recovery Services vault creation page opens, select thesubscription under which the resource will be billed. Then, choose the resource group where the vault will be created. In this case,select the pre-existing resource group FabrikamRG. Resource groups help organize and manage related resources.Specify the vault name as FabrikamBackupVault: Enter a unique name for the Recovery Services vault in the name field, such asFabrikamBackupVault. This name will be used to identify the vault in your Azure environment and should reflect its purpose, making iteasy to distinguish from other vaults.Select the region as East US:  Choose the East US region as the location for the Recovery Services vault. This ensures the vault isgeographically close to the resources it will back up (e.g., TestVM1), minimizing latency and potentially reducing costs associated withdata transfers.Click "Review + Create", then click "Create":  After configuring all the required fields, click on the "Review + Create" button. This stepallows you to verify all the entered details for correctness. Once confirmed, click "Create" to deploy the Recovery Services vault. Azurewill validate your inputs and begin the resource deployment process.Your Answer1.F. Navigate to the Azure portal and select"Create a resource"2.C. Choose the subscription and resourcegroup FabrikamRG3.B. Select the region as East US4.D. Specify the vault name asFabrikamBackupVault5.A. Click "Review + Create", then click "Create"6.E. Search for and select "Recovery Servicesvault"Correct Answer1.F. Navigate to the Azure portal and select"Create a resource"2.E. Search for and select "Recovery Servicesvault"3.C. Choose the subscription and resourcegroup FabrikamRG4.D. Specify the vault name asFabrikamBackupVault5.B. Select the region as East US6.A. Click "Review + Create", then click "Create"
10/18/25, 23:47LMS | Whizlabs
Page 3 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
IncorrectView Case Study
This sequence ensures you follow the logical flow required by the Azure portal to successfully create a Recovery Services vault in thespecified region and resource group. The vault will then be ready to configure backup for resources like TestVM1.Reference:Ask our ExpertsDid you like this Question?Question 2Domain: Monitor and maintain Azure resourcesWhat are the three necessary steps to create an Azure Backup vault for Fabrikam, Inc. as part of their backup and disaster recoverystrategy? (Select three)https://learn.microsoft.com/en-us/azure/backup/backup-create-recovery-services-vault
A. Create a Recovery Services vault in the East US regionrightB. Enable backup for individual resources before creating the vaultwrongC. Assign access policies for the vault to relevant usersrightD. Configure backup jobs after creating the vaultright
10/18/25, 23:47LMS | Whizlabs
Page 4 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
Explanation:Correct Answers: A, C and D The necessary steps for creating and setting up an Azure Backup vault involve creating the vault itself, assigning access policies, andconfiguring backup jobs. Following steps are required - Option A: Create a Recovery Services vault in the East US region is correct.This step is necessary as the first part of setting up backup management for Fabrikam's resources. The Recovery Services vault willcentralize the management of backup and restore operations, making it essential for implementing a backup strategy. It explicitlysatisfies the requirement to manage backups for TestVM1, FinanceDB, and SharedDocs. The vault should be created in the sameregion as the primary resources for optimal performance and compliance.Option C: Assign access policies for the vault to relevant users is correct.This step is important because ensuring that the appropriate users have access to the Recovery Services vault is critical formanaging backups securely. Access policies define who can perform backup and restore operations and help in maintainingcompliance and security, particularly in environments like Fabrikam’s, where they may have multiple users accessing sensitivefinancial data. Properly configured access ensures that only authorized personnel can change backup configurations or initiaterestores.Option D: Configure backup jobs after creating the vault is correct.After creating the Recovery Services vault, the next logical step is to configure backup jobs for the individual resources. This involvesspecifying what resources to back up, setting retention periods, and determining backup frequencies. This step is crucial to ensurethat the data for TestVM1, FinanceDB, and SharedDocs is backed up according to the established policies that meet Fabrikam’s RTOand RPO requirements.E. Establish alerts for backup job failures during vault creation
10/18/25, 23:47LMS | Whizlabs
Page 5 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
IncorrectView Case Study
Option B: Enable backup for individual resources before creating the vault is incorrect because you must first create the RecoveryServices vault to manage the backups of individual resources. Without the vault, there is no system in place to organize and handlethe backups. After the vault is created, you can proceed to enable backup for TestVM1, FinanceDB, and SharedDocs. Therefore, thisoption does not follow the logical sequence required for setting up Azure Backup.Option E: Establish alerts for backup job failures during vault creation is incorrect because while establishing alerts is an essentialpart of a comprehensive backup strategy, this step cannot occur during the vault's creation. Alerts need to be configured after theRecovery Services vault has been created and backup jobs have been set up. Alerts monitor the health of backup jobs and notifyadministrators of any failures or issues; thus, they are a post-creation task rather than part of the vault creation process itself.Reference:Ask our ExpertsDid you like this Question?Question 3Domain: Monitor and maintain Azure resourcesYou have configured a backup policy for TestVM1 in the FabrikamBackupVault. The VM encountered a ransomware attack, and youneed to restore it to the state from the last backup. Which steps should you perform?https://learn.microsoft.com/en-us/azure/backup/create-manage-backup-vault
10/18/25, 23:47LMS | Whizlabs
Page 6 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
Explanation:Correct Answer: BOption B: Use the "Restore VM" option in the Recovery Services vault and select the latest recovery point is correct because the"Restore VM" option in the Recovery Services vault is the appropriate method for restoring a full virtual machine. It allows you to selecta recovery point from the backups configured in the vault and restore the VM to its last known healthy state. This method ensures thatall VM configurations, disks, and data are reverted to a ransomware-free recovery point.
Option A: Delete the compromised TestVM1 and create a new VM using the recovery point is incorrect because while creating a newVM from a recovery point is a valid approach in some scenarios, it is not necessary for this use case. The "Restore VM" option alreadyhandles the restoration without requiring manual deletion or recreation of the VM, making it the more efficient and straightforwardsolution.Option C: Use PowerShell to run the Restore-AzRecoveryServicesBackupItem cmdlet is incorrect because the Restore-AzRecoveryServicesBackupItem cmdlet is not designed for restoring full virtual machines. Instead, it is used to restore individual items,such as files or application data. This cmdlet cannot perform the full VM restoration required to recover from a ransomware attackOption D: Perform a file-level recovery of TestVM1 and replace the affected files is incorrect because File-level recovery only restoresindividual files or folders and does not address system-level compromises that are typical of ransomware attacks. Simply replacingA. Delete the compromised TestVM1 and create a new VM using the recovery pointB. Use the "Restore VM" option in the Recovery Services vault and select the latest recovery pointrightC. Use PowerShell to run the Restore-AzRecoveryServicesBackupItem cmdletD. Perform a file-level recovery of TestVM1 and replace the affected fileswrong
boDashboardMy CoursesHands-on LabsSandboxSupport

10/18/25, 23:47LMS | Whizlabs
Page 7 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
IncorrectView Case Studyfiles will not guarantee the removal of the ransomware, and it does not restore the entire VM to a clean state.Reference:Ask our ExpertsDid you like this Question?Question 4Domain: Monitor and maintain Azure resourcesFabrikam, Inc. has configured Azure Site Recovery for TestVM1. During a regional outage in the East US, you need to initiate a failover tothe West US. What steps should you follow in Azure Site Recovery?
Explanation:Correct Answer: DOption D: Navigate to the Recovery Services vault, select the replicated item TestVM1, and click "Failover" is correct becauseinitiating a failover for a replicated virtual machine (TestVM1) requires navigating to the Recovery Services vault where replication ismanaged. By selecting the replicated item and clicking "Failover," Azure Site Recovery initiates the process to bring the VM online in thesecondary region (West US). This is the primary and necessary step to execute a failover. Failover ensures continuity of services duringregional outages by switching to the target region where the replica is stored.https://learn.microsoft.com/en-us/azure/backup/backup-azure-arm-restore-vms#choose-a-vm-restore-configuration
A. Run a test failover before initiating a full failover to ensure the secondary region is readywrongB. Perform a "Planned Failover" to avoid data loss in the target regionC. Stop all workloads on TestVM1 before initiating the failoverD. Navigate to the Recovery Services vault, select the replicated item TestVM1, and click "Failover"right
10/18/25, 23:47LMS | Whizlabs
Page 8 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
Correct
Option A: Run a test failover before initiating a full failover to ensure the secondary region is ready is incorrect because while a TestFailover is a best practice to verify readiness during regular operations, it is not feasible during an actual outage. In this case, the EastUS region is down, and performing a test failover would not ensure service continuity. The correct approach is to initiate a full failoverimmediately to bring TestVM1 online in the West US.Option B: Perform a "Planned Failover" to avoid data loss in the target region is incorrect because a Planned Failover requires bothsource and target regions to be operational, as it replicates any pending changes before the failover. Since the East US region isexperiencing a regional outage, a Planned Failover cannot be executed. Instead, an Unplanned Failover is appropriate during anoutage to immediately switch to the secondary region, accepting the possibility of some data loss.Option C: Stop all workloads on TestVM1 before initiating the failover is incorrect because during a regional outage, the source VM(TestVM1) is already inaccessible, making it impossible to stop workloads on it. The failover process in Azure Site Recoveryautomatically handles the switch to the replica VM in the target region. Stopping workloads is not a necessary step and cannot beperformed in this scenario.Reference: Ask our ExpertsDid you like this Question?Question 5Tutorial: Run a disaster recovery drill for Azure VMs
10/18/25, 23:47LMS | Whizlabs
Page 9 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
View Case StudyDomain: Monitor and maintain Azure resourcesYou want to configure backup reports and alerts for all protected resources in FabrikamBackupVault. Which of the following threeactions must you take? Note: Drag the correct options and then drop them into the answer area
Explanation:Correct Answers: A, B and DThe following actions are a must to configure backup reports and alerts for all protected resources in FabrikamBackupVault:Option A: Enable Azure Monitor diagnostics and route logs to Log Analytics is correct because - Enabling Azure Monitor diagnosticsand routing logs to Log Analytics allows you to gather detailed monitoring and alerting data for all protected resources in theRecovery Services vault. Logs from the backup operations, such as success or failure events, will be available in Log Analytics, makingit easier to create customized alerts and reports using Azure Monitor.Option B: Configure an Action Group in Azure Monitor for backup alerts is correct because - Configuring an Action Group in AzureMonitor for backup alerts is the appropriate step to receive notifications for backup job failures, successes, and other significantevents. You can define specific actions, such as sending an email, text message, or invoking a webhook, to alert the appropriate usersor administrators when backup jobs fail or encounter issues.Option D: Enable email notifications for failed backup jobs in the Recovery Services vault settings is correct because - Enablingemail notifications for failed backup jobs in the Recovery Services vault settings is the most straightforward method to get alerts forbackup failures. This setting provides automated email notifications directly from the Recovery Services vault when a backup job fails,ensuring that the team is promptly informed of any issues with backups.Your AnswerA. Enable Azure Monitor diagnostics and route logsto Log AnalyticsB. Configure an Action Group in Azure Monitor forbackup alertsD. Enable email notifications for failed backup jobsin the Recovery Services vault settingsCorrect AnswerA. Enable Azure Monitor diagnostics and route logsto Log AnalyticsB. Configure an Action Group in Azure Monitor forbackup alertsD. Enable email notifications for failed backup jobsin the Recovery Services vault settings
10/18/25, 23:47LMS | Whizlabs
Page 10 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571
Option C: Use Power BI to visualize backup trends and failures is incorrect because while Power BI is a powerful tool for datavisualization, it is not directly involved in configuring backup reports and alerts for Recovery Services vaults. Power BI can be used tovisualize data from Log Analytics (after logs are routed there), but it is not a primary tool for configuring alerts or reporting within AzureBackup services.References:
Ask our ExpertsDid you like this Question?Finish Reviewhttps://learn.microsoft.com/en-us/azure/backup/backup-azure-monitoring-built-in-monitor?tabs=recovery-services-vaultshttps://learn.microsoft.com/en-us/azure/azure-monitor/alerts/action-groupshttps://learn.microsoft.com/en-us/azure/backup/guidance-best-practices
Hands-on LabsSandboxSubscriptionFor BusinessLibrary
10/18/25, 23:47LMS | Whizlabs
Page 11 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70460/report/8455571CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/13/25, 13:43LMS | Whizlabs
Page 1 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927
CorrectView Case Study
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationAzure Files and Azure Blob Storage - Practice ModeCompleted on Mon, 13 Oct 20251stAttempt5/5Marks Obtained100.00%Your ScorePASSResultDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Implement and manage storage55000TotalAll Domains55000Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Implement and manage storageYou are tasked with creating a new Blob container in the tailwindstorage1 storage account to securely store incoming applicationlogs. The container must block public access and only accept authenticated requests from managed identities. What should you doto meet these requirements? What do you need to do to meet these needs?Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Azure Files and Azure Blob Storage/ReportBack to the Courseh
Download Report
A. Enable public read access for the container and assign the Reader role to managed identitiesB. Set the container’s access level to Private and assign the Storage Blob Data Contributor role to managed identitiesrightC. Configure shared access signatures (SAS) for the container and allow public access
boDashboardMy CoursesHands-on LabsSandboxSupport

10/13/25, 13:43LMS | Whizlabs
Page 2 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927
Explanation:Correct Answer: BOption B: Set the container’s access level to Private and assign the Storage Blob Data Contributor role to managed identities iscorrect because setting the container’s access level to Private ensures that public access is completely blocked, meeting the firstrequirement. By default, a Private access level allows only authenticated requests to access the container. Assigning the Storage BlobData Contributor role to managed identities enables them to perform both read and write operations on blobs within the container.This role is specifically designed for scenarios where managed identities require full access to blob data. Furthermore, Microsoft EntraID integration ensures that requests are authenticated securely, and the use of managed identities eliminates the need forcredentials to be stored in application code, enhancing security. This configuration meets all the requirements for secure storage andaccess
Option A: Enable public read access for the container and assign the Reader role to managed identities is incorrect becauseenabling public read access contradicts the requirement to block public access to the container. Public read access allows anyonewith the container URL to view its content without authentication, which does not meet the security requirement. Additionally, theReader role only provides read-only access to data and does not allow users to write or upload logs to the container. Managedidentities need a role that grants both read and write permissions for this scenario.Option C: Configure shared access signatures (SAS) for the container and allow public access is incorrect because while sharedaccess signatures (SAS) can restrict access based on permissions and expiration, allowing public access would violate therequirement to block public access entirely. SAS tokens are useful for temporary, granular access to storage resources but do notinherently enforce managed identity-based authentication. This option does not align to enable secure, role-based access controlusing Microsoft Entra ID and managed identities.D. Set the container’s access level to Blob and disable encryption
10/13/25, 13:43LMS | Whizlabs
Page 3 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927
CorrectView Case StudyOption D: Set the container’s access level to Blob and disable encryption is incorrect because setting the container access level toBlob allows public read access to blobs within the container, which fails to block public access as required. Disabling encryptioncontradicts best practices for securing data in Azure Storage. Encryption at rest is automatically enabled by Azure Storage andcannot be disabled for compliance and data security reasons. This option is technically infeasible and does not satisfy any of thestated requirements.References:
Ask our ExpertsDid you like this Question?Question 2Domain: Implement and manage storageThe IT team has requested that you configure Azure Files in the tailwindstorage2 storage account to allow recovery of deleted files for30 days. What should you do first to implement this requirement?
Explanation:Correct Answer: DOption D: Enable soft delete for file shares in the storage account is correct because enabling soft delete for Azure file shares allowsyou to recover files that are deleted or overwritten, as long as the soft delete retention period is configured. By enabling this feature inthe tailwindstorage2 storage account and setting the retention period to 30 days, any deleted files in the Azure Files shares can berestored during that time frame. Soft delete ensures that the recovery process is seamless, without requiring additional backupinfrastructure or manual intervention. This is a built-in feature in Azure Files and aligns directly with the requirement to recover deletedfiles for 30 days. Furthermore, soft delete protects against accidental deletions or malicious activities, offering an additional layer ofresilience without introducing extra costs for infrastructure like Azure Backup.https://learn.microsoft.com/en-us/azure/storage/blobs/anonymous-read-access-configure?tabs=portalhttps://learn.microsoft.com/en-us/azure/storage/blobs/assign-azure-role-data-access?tabs=portal
A. Create file share snapshots and store them in the Archive tierB. Configure Azure Backup for the file shares and set the retention period to 30 daysC. Enable versioning for the file sharesD. Enable soft delete for file shares in the storage accountright
10/13/25, 13:43LMS | Whizlabs
Page 4 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927
Option A: Create file share snapshots and store them in the Archive tier is incorrect because while snapshots allow point-in-timerecovery of file shares, they do not provide the ability to automatically recover deleted files without manual intervention. Additionally,snapshots are stored in the same tier as the file share and cannot be moved to the Archive tier, as Azure Files does not support tieringlike Azure Blob Storage. This option introduces unnecessary complexity and does not fulfill the requirement to enable automaticrecovery of deleted files within a 30-day retention period.Option B:Configure Azure Backup for the file shares and set the retention period to 30 days is incorrect because while Azure Backupsupports backing up file shares and provides a retention period, it is not the most efficient solution for recovering deleted files in thisscenario. Azure Backup is designed for more comprehensive backup and restore operations, often involving longer-term retentionand more complex recovery requirements. Configuring Azure Backup for this task would introduce additional costs and complexity,such as setting up backup policies and recovery points, which are unnecessary for a simple 30-day soft delete requirement.Furthermore, Azure Backup is not required for enabling or utilizing the soft delete feature.Option C: Enable versioning for the file shares is incorrect because file versioning is not a feature available for Azure Files. While AzureBlob Storage supports versioning for tracking and restoring previous versions of blobs, Azure Files relies on snapshots and soft deletefor data protection. Choosing this option demonstrates a misunderstanding of Azure Files capabilities, as enabling versioning is notapplicable in this context.Reference: Ask our ExpertsDid you like this Question?https://learn.microsoft.com/en-us/azure/storage/files/storage-files-enable-soft-delete?tabs=azure-portal
10/13/25, 13:43LMS | Whizlabs
Page 5 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927
CorrectView Case StudyQuestion 3Domain: Implement and manage storageYou need to implement a lifecycle policy on the tailwindstorage3 storage account to transition logs from the Hot tier to the Cool tierafter 45 days and then to the Archive tier after 90 days.  What is the first step to achieve this?
Explanation:Correct Answer: BOption B: Define a JSON policy with rules specifying age-based transitions and upload it to the storage account is correct - This isthe correct approach to implement automated lifecycle management in Azure Blob Storage. You must define a JSON-based lifecyclepolicy that specifies rules to transition blobs from the Hot tier to Cool after 45 days, and then to Archive after 90 days. This policy isthen uploaded via the Azure portal under the Lifecycle Management section of the storage account. JSON policies give fine-grainedcontrol using filters (e.g., blob prefix, type) and remove the need for manual intervention. This method aligns with cost optimizationand Azure’s built-in automation features for storage tiering.
A. Configure monitoring for blob storage tier changes in the Azure portalB. Define a JSON policy with rules specifying age-based transitions and upload it to the storage accountrightC. Enable blob versioning for all containers in the storage accountD. Modify the replication type of the storage account to LRS
10/13/25, 13:43LMS | Whizlabs
Page 6 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927
CorrectView Case StudyOption A: Configure monitoring for blob storage tier changes in the Azure portal is incorrect - Monitoring is useful for trackingchanges and alerts, but it does not help implement lifecycle policies. It provides insights, not control mechanisms. Lifecycle rules arenot configured through monitoring but through explicit policy definitions.Option C: Enable blob versioning for all containers in the storage account is incorrect - Blob versioning is used for data protection —it allows recovery of previous blob versions in case of accidental overwrite or deletion. It does not support or affect tier transitions orlifecycle automation, which is the core requirement here.Option D: Modify the replication type of the storage account to LRS is incorrect - LRS (Locally Redundant Storage) defines how manyand where copies of the data are kept, for durability purposes. It has no role in lifecycle management or in transitioning blob tiersbased on age.Reference: Ask our ExpertsDid you like this Question?Question 4Domain: Implement and manage storageThe IT team wants to store images in tailwindstorage1 that are accessed frequently for 30 days and rarely thereafter. The imagesmust remain available with minimal latency even after the first 30 days. Which storage tier configuration should you use?
Explanation:Correct Answer: DOption D: Use the Hot tier for the first 30 days and transition to the Cool tier afterward is correct because the Hot tier in Azure BlobStorage is designed for data that needs frequent access, making it suitable for the first 30 days when image access is high. After thisperiod, the Cool tier becomes a cost-efficient choice for less frequently accessed data, as it still supports low-latency access. Thisstrategy ensures a balance between cost and performance. The Hot tier guarantees fast access during the initial period of frequentuse, while the Cool tier reduces costs for infrequent use without compromising performance. Automating the transition using AzureBlob Storage lifecycle policies simplifies cost management while maintaining data accessibility. This approach aligns with the ITteam’s goals of frequent initial access and lower costs for rare access later.https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-overview
A. Keep the images permanently in the Hot tier to ensure low-latency accessB. Store the images directly in the Archive tier to minimize costsC. Use the Cool tier for the first 30 days and transition to the Hot tier afterwardD. Use the Hot tier for the first 30 days and transition to the Cool tier afterwardright
10/13/25, 13:43LMS | Whizlabs
Page 7 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927
Option A: Keep the images permanently in the Hot tier to ensure low-latency access is incorrect because while the Hot tier offers lowlatency and optimal performance, it is the most expensive tier. Keeping the images permanently in the Hot tier is not cost-efficient,especially after the first 30 days when access frequency decreases. The IT team's requirement specifies rare access after the initial 30days, making the Cool tier a better choice for the latter period. By not transitioning to a lower-cost tier, this approach disregards thecost-saving potential while still meeting the performance requirements.Option B: Store the images directly in the Archive tier to minimize costs is incorrect because the Archive tier is the most cost-effective storage option but is unsuitable for data that requires frequent or low-latency access. Data in the Archive tier is offline andmust be rehydrated before access, leading to significant delays and operational overhead. This makes it impractical for scenarioswhere images need to be accessed frequently during the first 30 days. The Archive tier does not meet the requirement of ensuringavailability with minimal latency, even for rarely accessed images.Option C:Use the Cool tier for the first 30 days and transition to the Hot tier afterward is incorrect because the Cool tier is designedfor data that is infrequently accessed, and using it during the first 30 days when images are accessed frequently is not optimal. Thiswould result in unnecessary latency and potential performance issues during the period of high access demand. Transitioning to theHot tier afterward also increases costs without any justification, as the access frequency decreases after the first 30 days. Thisconfiguration fails to align with the cost and performance requirements described in the scenario.Reference: Ask our ExpertsDid you like this Question?https://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview
10/13/25, 13:43LMS | Whizlabs
Page 8 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927
CorrectView Case StudyQuestion 5Domain: Implement and manage storageA developer accidentally deleted a critical blob in the tailwindstorage3 storage account where blob versioning is enabled. Whichaction should you take to recover the deleted blob?
Explanation:Correct Answer: BOption B: Use the List Blob Versions API to identify and copy the required blob version is correct because since blob versioning isalready enabled, Azure automatically preserves earlier versions of blobs, even if they are deleted. By using the List Blob Versions API,you can locate the previous version of the deleted blob. Then, you can recover it using the Copy Blob operation to either the same or anew blob path. This method allows for precise, non-disruptive recovery without restoring the entire container or relying on othermechanisms like snapshots or lifecycle policies.
Option A: Enable soft delete for blobs and restore the blob from the deleted items is incorrect - while soft delete is a recoveryA. Enable soft delete for blobs and restore the blob from the deleted itemsB. Use the List Blob Versions API to identify and copy the required blob versionrightC. Restore the entire container from a backup snapshotD. Configure blob lifecycle management to retrieve the archived version of the blob
10/13/25, 13:43LMS | Whizlabs
Page 9 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927
mechanism, it must be enabled before the deletion occurs. Enabling it afterward does not help. Additionally, since versioning isalready enabled, recovery should be performed using versioning features, not soft delete.Option C: Restore the entire container from a backup snapshot is incorrect - This is a broad and disruptive action. There’s noindication a snapshot exists, and recovering a full container for one deleted blob is excessive. Blob versioning offers granular recovery— the appropriate method in this case.Option D: Configure blob lifecycle management to retrieve the archived version of the blob is incorrect - Lifecycle management isused for tier transitions or deletion automation, not recovery. It does not retrieve deleted blobs or versions and operatesindependently of versioning. It’s irrelevant to this recovery scenario.Reference: Ask our ExpertsDid you like this Question?Finish Review
CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
https://learn.microsoft.com/en-us/azure/storage/blobs/versioning-overview
Hands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/13/25, 13:43LMS | Whizlabs
Page 10 of 10https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70306/report/8451927©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cd
10/12/25, 18:39LMS | Whizlabs
Page 1 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
IncorrectView Case Study
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationAzure Subscriptions & Governance - Practice ModeCompleted on Sun, 12 Oct 20251stAttempt2/5Marks Obtained40.00%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Manage Azure identities andgovernance52300TotalAll Domains52300Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Manage Azure identities and governanceFabrikam must ensure that resource creation in all subscriptions is restricted to East US and West Europe regions. The solution mustalso remediate existing resources that violate this policy. What should you do?Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Azure Subscriptions & Governance/ReportBack to the Courseh
Download Report
A. Assign the Allowed locations policy with a Deny effect at the FabrikamRoot management group levelB. Create a custom policy definition to restrict regions, set the Modify effect, and assign it at the subscription level.wrongC. Apply the built-in Allowed locations policy at the management group level with the deployIfNotExists effect.right
10/12/25, 18:39LMS | Whizlabs
Page 2 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
Explanation:Correct Answer: COption C: Apply the built-in Allowed locations policy at the management group level with the deployIfNotExists effect is correctbecause the Allowed locations policy can limit resource creation to the specified regions (East US and West Europe). ThedeployIfNotExists effect ensures that any existing resources outside the allowed locations can be remediated. For example, it can flagand correct non-compliant resources by moving them to compliant regions or applying remediation logic as defined by the policy.Applying the policy at the management group level ensures consistent governance across all subscriptions, eliminating the need forrepeated assignments and ensuring scalability for future subscriptions under the hierarchy. Simplified governance by centralizingpolicy management at the management group level. Built-in policies reduce operational overhead compared to creating andmanaging custom policies. Ensures compliance with corporate standards across all existing and future subscriptions.
Option A: Assign the Allowed locations policy with a Deny effect at the FabrikamRoot management group level is incorrect becausewhile the Deny effect ensures that new resources cannot be created outside the specified regions, it does not address therequirement to remediate existing non-compliant resources. A Deny effect only prevents new violations but does not apply correctiveactions to existing resources. Fabrikam explicitly requires remediation of already non-compliant resources, which this approach doesnot fulfill.Option B: Create a custom policy definition to restrict regions, set the Modify effect, and assign it at the subscription level isincorrect because the Modify effect is primarily used to enforce or update specific resource configurations (e.g., adding tags orsetting parameters). It is not suitable for restricting resource creation to specific regions. Additionally, the effort to create and managea custom policy is unnecessary when a built-in policy, such as Allowed locations, already exists and can meet the requirements.Assigning it only at the subscription level also lacks scalability for enforcing organization-wide governance.D. Add the Allowed locations policy to a new initiative and assign it at the subscription level with the Audit effect
10/12/25, 18:39LMS | Whizlabs
Page 3 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
CorrectView Case StudyOption D: Add the Allowed locations policy to a new initiative and assign it at the subscription level with the Audit effect is incorrectbecause the Audit effect only monitors and logs non-compliant resources but does not prevent new violations or remediate existingissues. While assigning the policy as part of an initiative could improve the organization, using the Audit effect fails to enforcecompliance or take corrective action, making it insufficient to meet Fabrikam's requirements.References: 
Ask our ExpertsDid you like this Question?Question 2Domain: Manage Azure identities and governanceFabrikam requires all resources to include the tags Environment and BusinessUnit, both for existing and newly created resources. Howshould this requirement be implemented?
Explanation:Correct Answer: DOption D: Use the Modify effect in Azure Policy to append tags and assign them to each subscription is correct because the Modifyeffect in Azure Policy is capable of both enforcing tags for new resources and retroactively applying tags to existing resourcesthrough remediation tasks. The Modify effect ensures that tags are added automatically during resource creation, even if they are notexplicitly defined by the resource creator. Azure Policy allows remediation tasks to bring existing resources into compliance. By usingthe Modify effect, Fabrikam can append the required tags (Environment and BusinessUnit) to all existing resources in the scope.Assigning the policy to each subscription ensures that all resources within those subscriptions are compliant. While assigning at themanagement group level might simplify governance, assigning directly at the subscription level provides flexibility to target specificsubscriptions if needed. Ensures full compliance with tagging requirements for both existing and future resources. Utilizes AzurePolicy’s built-in capabilities, minimizing manual effort. Provides visibility and control over resources for better cost and operationalmanagement.https://learn.microsoft.com/en-us/azure/governance/policy/concepts/effect-basicshttps://learn.microsoft.com/en-us/azure/governance/policy/samples/built-in-policies#general
A. Assign the Append tag and its value policy at the root management group to enforce tagging for all new resourcesB. Manually apply the required tags to existing resources and create a policy to enforce tags for future resourcesC. Assign the Modify effect at the management group level without remediation for existing resourcesD. Use the Modify effect in Azure Policy to append tags and assign them to each subscriptionright
10/12/25, 18:39LMS | Whizlabs
Page 4 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
Option A: Assign the Append tag and its value policy at the root management group to enforce tagging for all new resources isincorrect because the Append effect ensures that a tag and its value are added during the creation of new resources. However, itdoes not address the requirement to tag existing resources, which is a critical part of Fabrikam's requirements. Assigning the policy atthe root management group level ensures coverage across all subscriptions, but it falls short of meeting the requirement for existingresources.Option B: Manually apply the required tags to existing resources and create a policy to enforce tags for future resources is incorrectbecause it relies on a manual approach to tag existing resources. Manual tagging is time-consuming, prone to errors, and difficult toscale, especially for organizations with a large number of resources. Moreover, this approach does not take advantage of AzurePolicy’s automated remediation capabilities, which can efficiently tag resources without manual intervention. While creating a policyfor future resources is valid, the manual tagging step does not align with best practices for automation and governance.Option C: Assign the Modify effect at the management group level without remediation for existing resources is incorrect becauseassigning the Modify effect at the management group level without remediation for existing resources would only apply the taggingpolicy to newly created resources. The requirement specified in the case study is to ensure that both existing and new resources aretagged with Environment and BusinessUnit. Without remediation for existing resources, this policy would not address the existing non-compliant resources, failing to meet the full tagging requirement. Therefore, this option does not fully satisfy the needs outlined in thecase study.Reference: https://learn.microsoft.com/en-us/azure/governance/policy/concepts/effect-modifyAsk our Experts
10/12/25, 18:39LMS | Whizlabs
Page 5 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
IncorrectView Case StudyDid you like this Question?Question 3Domain: Manage Azure identities and governanceThe finance team at Fabrikam requires an email alert when spending on the Research subscription exceeds 75% of its $15,000 monthlybudget.  What steps should the IT team take?
Explanation:Correct Answer: BOption B: Set up a budget in Azure Cost Management, configure a 75% threshold, and assign an action group for email notificationsis correct because Azure Cost Management allows you to create budgets for subscriptions, resource groups, or services. The stepsinclude:1. Creating a Budget: Define a budget of $15,000 for the Research subscription within Azure Cost Management.2. Setting Alerts: Configure a threshold of 75% of the budget. This means an alert will trigger when spending reaches $11,250.3. Notification Configuration: Assign an action group to the budget alert to send an email notification to the finance team.Action groups allow multi-channel notifications, including email, SMS, and webhook.A. Configure a cost alert in Azure Advisor and create an action group for email notificationswrongB. Set up a budget in Azure Cost Management, configure a 75% threshold, and assign an action group for emailnotificationsrightC. Use Azure Monitor to create a custom alert rule and configure email notifications for cost thresholdsD. Implement a Logic App to monitor subscription spending and trigger an email when the threshold is exceeded
10/12/25, 18:39LMS | Whizlabs
Page 6 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
Azure Cost Management budgets are specifically designed for monitoring and alerting spending thresholds, making this the mostappropriate and efficient solution. Additionally, this approach aligns with Azure's built-in capabilities for cost governance, reducingthe need for custom solutions.Option A: Configure a cost alert in Azure Advisor and create an action group for email notifications is incorrect because AzureAdvisor provides cost optimization recommendations but does not have a feature to configure cost alerts directly. While AzureAdvisor integrates with recommendations for reducing expenses and improving cost efficiency, it cannot be used to set thresholdsfor budget monitoring or trigger alerts when spending crosses a specific percentage. Action groups can indeed be used fornotifications, but they cannot be triggered by Advisor directly for budget-related scenarios.Option C: Use Azure Monitor to create a custom alert rule and configure email notifications for cost thresholds is incorrect becauseAzure Monitor is primarily used for tracking metrics, logs, and telemetry data from Azure resources and applications. While customalert rules can be created in Azure Monitor for various conditions, it is not the recommended solution for monitoring cost thresholds.Azure Cost Management is explicitly designed for this purpose, making it a more efficient and straightforward approach. Using AzureMonitor for cost alerts would introduce unnecessary complexity and require additional setup for tracking cost data.Option D: Implement a Logic App to monitor subscription spending and trigger an email when the threshold is exceeded is incorrectbecause using a Logic App to monitor spending and trigger email notifications involves significant manual effort and customimplementation. While Logic Apps can be used to automate workflows, Azure Cost Management already provides a built-in solutionfor cost monitoring and alerting, making the use of Logic Apps redundant and inefficient for this scenario. Additionally, this approachwould require integrating with cost APIs and managing the workflow logic, which is unnecessary given the availability of out-of-the-box features in Azure Cost Management.Reference: https://learn.microsoft.com/en-us/azure/cost-management-billing/costs/tutorial-acm-create-budgets?tabs=psbudget
boDashboardMy CoursesHands-on LabsSandboxSupport

10/12/25, 18:39LMS | Whizlabs
Page 7 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
CorrectView Case StudyAsk our ExpertsDid you like this Question?Question 4Domain: Manage Azure identities and governanceTo ensure that Azure Advisor cost recommendations are not overlooked, Fabrikam wants an automated process to notify the IT teamwhenever new recommendations are available.  What is the best solution?
Explanation:Correct Answer: COption C: Deploy a Logic App to query Azure Advisor periodically and send email notifications for new recommendations is correctbecause Azure Logic Apps provide a flexible platform to automate workflows by interacting with various Azure services, includingAzure Advisor through its REST API. By configuring the Logic App to make periodic calls to the Azure Advisor API, Fabrikam can retrieverecommendations programmatically. The workflow can parse the API response to identify new recommendations and useconnectors like email or Teams to notify the IT team. This approach ensures a fully automated process that eliminates manual effortand ensures recommendations are not overlooked. Although Azure Advisor lacks a direct Logic Apps connector, the HTTP connector inLogic Apps enables seamless integration with the REST API. This solution aligns with Fabrikam’s requirement for automation, scalability,and proactive notifications, ensuring cost recommendations are addressed promptly. A. Use Azure Event Grid to trigger notifications for new cost recommendations, but only if they meet specific cost thresholdsB. Set up an alert in Azure Monitor to track Advisor changes and notify the IT teamC. Deploy a Logic App to query Azure Advisor periodically and send email notifications for new recommendationsrightD. Assign the Reader role to IT staff and instruct them to check Advisor recommendations manually
10/12/25, 18:39LMS | Whizlabs
Page 8 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
Option A: Use Azure Event Grid to trigger notifications for new cost recommendations, but only if they meet specific cost thresholdsis incorrect because Azure Event Grid is designed to handle event-driven architectures by delivering notifications for specific Azureservices and custom events. However, Azure Event Grid does not natively support Azure Advisor as an event source. This means itcannot directly trigger notifications for new cost recommendations from Azure Advisor. Additionally, while Event Grid can filter eventsbased on specific thresholds or criteria, the lack of direct integration with Azure Advisor makes it unsuitable for this requirement.Therefore, relying on Event Grid would not fulfill Fabrikam’s need for an automated and reliable process to notify the IT team aboutnew Advisor recommendations.Option B: Set up an alert in Azure Monitor to track Advisor changes and notify the IT team is incorrect because Azure Monitor doesnot provide built-in capabilities to track changes in Azure Advisor recommendations. Azure Monitor focuses on collecting andanalyzing telemetry data and metrics from Azure resources, but it lacks integration with Advisor for monitoring updates. While AzureMonitor can generate alerts for performance or log-based conditions, it cannot directly monitor Advisor’s cost recommendations,making this approach infeasible for Fabrikam's requirements.Option D: Assign the Reader role to IT staff and instruct them to check Advisor recommendations manually is incorrect because itintroduces manual effort and is prone to errors. Assigning the Reader role to the IT team enables them to view Azure Advisorrecommendations, but relying on team members to check for updates is neither efficient nor scalable. This approach does not alignwith Fabrikam's requirement for automation and proactive notifications, making it a suboptimal choice.References: 
Ask our Expertshttps://learn.microsoft.com/en-us/rest/api/advisor/recommendations/list?view=rest-advisor-2023-01-01&tabs=HTTPhttps://learn.microsoft.com/en-us/azure/logic-apps/logic-apps-workflow-actions-triggers#http-request-actions
10/12/25, 18:39LMS | Whizlabs
Page 9 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
IncorrectView Case StudyDid you like this Question?Question 5Domain: Manage Azure identities and governanceFabrikam plans to create a multi-tier hierarchy where each subscription (Operations, Research, Sales, and Marketing) is placed undera dedicated management group. These management groups will roll up under the root FabrikamRoot group. How should the IT teamproceed?
Explanation:Correct Answer: AOption A: Create child management groups under FabrikamRoot for each subscription and move subscriptions accordingly iscorrect because it aligns with Azure’s best practices for organizing resources using management groups. In this case, Fabrikam wantsto create a multi-tier hierarchy, where each subscription (Operations, Research, Sales, and Marketing) is placed under itsmanagement group, and these management groups will roll up under the root group, FabrikamRoot. Azure management groupssupport this structure by enabling a hierarchical model where each management group can contain subscriptions, policies, accesscontrol, and compliance requirements that can be applied at the management group level. This solution ensures proper delegation,centralized management, and the ability to apply policies at different levels within the organization. It also maintains scalability,allowing the organization to expand by adding more management groups as needed.A. Create child management groups under FabrikamRoot for each subscription and move subscriptions accordinglyrightB. Assign all subscriptions directly under FabrikamRoot and manage policies at the root levelC. Consolidate subscriptions into a single group named BusinessUnits under the root groupD. Use tags to distinguish subscriptions within the existing single management group structurewrong
10/12/25, 18:39LMS | Whizlabs
Page 10 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
Option B: Assign all subscriptions directly under FabrikamRoot and manage policies at the root level is incorrect because while youcan assign subscriptions directly under the root management group (FabrikamRoot), it does not meet the requirement of creating amulti-tier hierarchy where each subscription has its dedicated management group. If all subscriptions are placed directly under theroot group, it would make policy management and resource organization more difficult as there would be no granular control for theindividual business units (Operations, Research, Sales, Marketing). Additionally, having everything under the root group limits flexibilityin organizing and managing access, policies, and compliance separately for each department or subscription.Option C: Consolidate subscriptions into a single group named BusinessUnits under the root group is incorrect because while itcreates a management group under the root, it consolidates all subscriptions under a single management group (BusinessUnits). Thisapproach does not adhere to the requirement of creating a multi-tier hierarchy with each department (Operations, Research, Sales,Marketing) having its dedicated management group. Consolidating subscriptions under a single management group would limit theability to apply specific policies and access control tailored to each department, leading to potential conflicts in policy application ordifficulty in tracking compliance at a granular level.Option D: Use tags to distinguish subscriptions within the existing single management group structure is incorrect because tagsare not a suitable tool for managing and organizing subscriptions at the level described in the question. Tags can be useful forresource-level organizations (such as VMs or storage accounts) but are not designed to manage subscriptions or implement ahierarchical structure for management groups. Tags do not provide the same level of governance, control, or policy managementcapabilities as management groups. While tags can help categorize resources, they cannot be used to manage subscriptions ordelegate control at a higher level, making them inappropriate for this use case.References: https://learn.microsoft.com/en-us/azure/governance/management-groups/overviewhttps://learn.microsoft.com/en-us/azure/governance/management-groups/manage#move-management-groups-and-subscriptions
10/12/25, 18:39LMS | Whizlabs
Page 11 of 11https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70304/report/8451262
Ask our ExpertsDid you like this Question?Finish Review
CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdHands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/12/25, 12:14LMS | Whizlabs
Page 1 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298Microsoft Azure Exam AZ-104 Certification6%
Download Cheat Sheet Quick Exam Reference - Hand-Picked for youHome/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification
JPractice Test22 Quizzes Available
.Video Course108 Video Available9+ Total Hours
GLabs165 Labs Available
Sandbox1 Sandbox Available
[My Bookmarked LabsExpand
GCreating Azure resourcelocks]45mAttemptsStartGWorking with resource tags]30mAttemptsStartGCreating Azure Policies]30mAttemptsStartGWorking with Alerts]1h 0mAttemptsStart
1. Manage Azure subscriptions andgovernance]2h 45m4 Labs
2. Configure, Manage and Access StorageAccounts]9h 30m11 Labs
10/12/25, 12:14LMS | Whizlabs
Page 2 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GCreate a Storage Account]30mAttemptsStartGNetwork Access to StorageAccounts]1h 0mAttemptsStartGCreate a Storage Accountusing Terraform]1h 0mAttemptsStartGMigrate data to cloud withAzCopy]45mAttemptsStartGUnderstanding Azure BlobStorage Tiers]30mAttemptsStartGRoute storage events toweb endpoint withPowerShell]45mAttemptsStartGConnect your Azure StorageExplorer to a storageaccount]1h 0mAttemptsStartGMonitor and TroubleshootAzure Storage with LogAnalytics]1h 0mAttemptsStartGAnalyze and TroubleshootStorage Issues Using AzureMetrics]45mAttemptsStartGE-Commerce AnalyticsPlatform]1h 30mAttemptsStartGCreate Queue storage andmessaging using Python]45mAttemptsStart
3. Configure Azure Files and Azure BlobStorage]2h 15m3 Labs
10/12/25, 12:14LMS | Whizlabs
Page 3 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GWorking with Blob Storage]30mAttemptsStartGWorking with Azure FileShares]45mAttemptsStartGCreate an SMB Azure fileshare and connect it to aWindows VM using theAzure portal]1h 0mAttemptsStart
GCreate a Windows VM usingan ARM template]30mAttemptsStartGCreate an internal loadbalancer to load balanceVMs by using an ARMtemplate]45mAttemptsStartGPublish Azure Static WebApps using an ARMTemplate]1h 0mAttemptsStartGCreate a Batch account byusing ARM template]30mAttemptsStartGCreating an Azure DNS zoneand record using an ARMtemplate]30mAttemptsStartGCreate a Windows virtualmachine using a Bicep file]30mAttemptsStartGCreating an Azure DNS zoneand record using Bicep]30mAttemptsStartGImplement DNS nameresolution in Azure]30mAttemptsStart
4. Automate deployment of resources byusing templates]4h 45m8 Labs
5. Create and configure VMs]8h 30m11 Labs
10/12/25, 12:14LMS | Whizlabs
Page 4 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GCreate a VM with CLI]30mAttemptsStartGAdding Data Disks to the VMUsing CLI]30mAttemptsStartGCreating a linux VM]30mAttemptsStartGDeploying Software with VMExtensions]45mAttemptsStartGDeploy an NVA and Set UpVirtual Machines]45mAttemptsStartGResizing of Virtual Machine]1h 0mAttemptsStartGCreating Availability Set]1h 0mAttemptsStartGInstalling and Configuringan SSH Server on Linux]1h 0mAttemptsStartGVirtual Machine Scale Sets -Custom Script Extensions]1h 0mAttemptsStartGCreate and manage aVirtual Machine Scale SetUsing Azure CLI]45mAttemptsStartGCreate SQL Server on AzureVM with PowerShell]45mAttemptsStart
6. Create and configure containers]4h 30m6 Labs
10/12/25, 12:14LMS | Whizlabs
Page 5 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GDeploy your first containerapp using the Azure portal]30mAttemptsStartGCreate a container registryby using a Bicep file]30mAttemptsStartGConfidential ContainerDeployment Using AzurePortal]45mAttemptsStartGDeploying a containerinstance using ARMtemplate]30mAttemptsStartGContainerizing Web Appson Azure App Service]1h 30mAttemptsStartGDeploy container app usingAzure CLI]45mAttemptsStart
GCreate an Azure Web AppUsing CLI]30mAttemptsStartGIntegrate Azure ContentDelivery Network with anAzure App Service Web App]1h 0mAttemptsStartGAzure Web AppDevelopment with RESTfulAPIs Using Node.js and SQLDatabase]1h 30mAttemptsStart
7. Create and configure an Azure AppService]3h3 Labs
8. Configure virtual networks]6h 45m7 Labs
10/12/25, 12:14LMS | Whizlabs
Page 6 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GImplementing VirtualNetwork Peering]1h 30mAttemptsStartGConfigure virtual networkpeering connections byusing Azure CLI commands]1h 30mAttemptsStartGCreate an Azure VirtualNetwork with Terraform]30mAttemptsStartGUnderstand NetworkSecurity Group rules]1h 0mAttemptsStartGSetting Up Global VNetPeering in Azure withTerraform]1h 0mAttemptsStartGAdding a network interface]30mAttemptsStartGEnd-to-End Azure VNetArchitecture with Public andPrivate access VMs]45mAttemptsStart
GCreating an ApplicationGateway]1h 0mAttemptsStartGCreating a Basic LoadBalancer]1h 0mAttemptsStartGCreate an internal loadbalancer to load balanceVMs]1h 30mAttemptsStartGCreate a gateway Loadbalancer using Azure Portal]1h 0mAttemptsStartGTroubleshoot routing, trafficcontrol and load balancingin Microsoft Azure]2h 0mAttemptsStart
9. Configure load balancing]6h 30m5 Labs

10/12/25, 12:14LMS | Whizlabs
Page 7 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GDeploy a Highly AvailableWeb Application withDocker and Nginx LoadBalancer on Azure Linux VMs]1h 0mAttemptsStart
10. Monitor virtual networking]1h1 Labs
GAlert on events within yourAzure infrastructure usingActivity Log Alerts]45mAttemptsStart
11. Monitor resources by using AzureMonitor]45m1 Labs
GCreate a SQL database]1h 0mAttemptsStartGImplement Azure Functions]1h 0mAttemptsStartGInstall NGINX Webserverusing Custom ScriptExtensions]45mAttemptsStartGInstalling NGINX on Linuxusing Cloud Init]45mAttemptsStartGUnderstanding AzureDatabase Services]1h 30mAttemptsStartGWorking with CustomImages]45mAttemptsStartGWorking with ApplicationInsights]30mAttemptsStartGCreating Azure Firewall]1h 30mAttemptsStartGCreate a Linux VM usingTerraform]45mAttemptsStart
12. Miscellaneous Labs]60h50 Labs
10/12/25, 12:14LMS | Whizlabs
Page 8 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GAzure Blob Storage PhotoUploader]2h 0mAttemptsStartGManage Windows VirtualMachines with AzureBastion]45mAttemptsStartGSubscribe to AzureKubernetes Service (AKS)events with Azure Event Grid]30mAttemptsStartGCreate a C# function inAzure from the commandline]1h 0mAttemptsStartGConnect Azure Functions toAzure Storage usingcommand line tools]2h 0mAttemptsStartGCreate a C# function inAzure using Visual StudioCode]1h 30mAttemptsStartGBuild a Consumption LogicApp Workflow in AzurePortal]2h 0mAttemptsStartGUse Azure Event Grid toroute Blob storage eventsto web endpoint]1h 0mAttemptsStartGRoute custom events to anAzure function by usingEvent Grid in Visual Studio]1h 30mAttemptsStartGConfiguring a Private DNSZone Using the Azure Portal]1h 30mAttemptsStartGUse Azure CLI to routecustom events to a webendpoint]45mAttemptsStartGSecure Azure Functions withPrivate Site Access]2h 0mAttemptsStart
10/12/25, 12:14LMS | Whizlabs
Page 9 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GRoute storage events toweb endpoint with Azure CLI]45mAttemptsStartGControl Azure FunctionsOutbound IP using NATGateway]1h 30mAttemptsStartGSend events from privatecontainer registry to EventGrid]45mAttemptsStartGMigrate Event Hubs Datafrom Azure Storage toSynapse Analytics withEvent Grid and Functions]2h 0mAttemptsStartGCreate an applicationgateway with path-basedrouting rules using theAzure portal]1h 30mAttemptsStartGConfiguring TLS Terminationwith Azure ApplicationGateway]1h 30mAttemptsStartGCreate and configure anapplication gateway tohost multiple web sitesusing the Azure portal]1h 30mAttemptsStartGConfigure ApplicationGateway with a frontendpublic IPv6 address usingthe Azure portal]1h 30mAttemptsStartGCreate an applicationgateway with HTTP to HTTPSredirection using the AzureCLI]1h 30mAttemptsStartGCreate an applicationgateway that improvesweb application accessusing PowerShell]1h 30mAttemptsStart
10/12/25, 12:14LMS | Whizlabs
Page 10 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GConfigure ApplicationGateway with a frontendpublic IPv6 address usingAzure PowerShell]1h 30mAttemptsStartGCreate a PowerShellfunction in Azure from theVisual Studio Code]1h 0mAttemptsStartGRoute custom events toweb endpoint withPowerShell and Event Grid]45mAttemptsStartGCreate an Azure Front Doorusing Azure PowerShell]1h 0mAttemptsStartGCreate an applicationgateway with path-basedredirection using the AzureCLI]1h 30mAttemptsStartGCreate an applicationgateway with path-basedredirection using the AzurePowerShell]1h 30mAttemptsStartGCreate a Python function inAzure from the commandline]1h 0mAttemptsStartGCreate a function in Azurewith Python using VisualStudio Code]1h 0mAttemptsStartGCreate a JavaScriptfunction in Azure from thecommand line]1h 0mAttemptsStartGCreate an Azure WindowsVM with Alerts usingTerraform]45mAttemptsStart
10/12/25, 12:14LMS | Whizlabs
Page 11 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GCreate an applicationgateway with HTTP to HTTPSredirection using AzurePowerShell]1h 30mAttemptsStartGCreate an applicationgateway that hosts multipleweb sites using the AzureCLI]1h 30mAttemptsStartGCreate an applicationgateway that hosts multipleweb sites using AzurePowerShell]1h 30mAttemptsStartGCreate a function in Azurewith TypeScript using VisualStudio Code]1h 0mAttemptsStartGCreate a TypeScriptfunction in Azure from thecommand line]1h 0mAttemptsStartGUsing Azure Virtual Machineas a Web Server to DeployNGINX]1h 0mAttemptsStartGDeploy a LAMP Server onAzure Using Ubuntu]30mAttemptsStartGCreate a Java function inAzure using VS Code]1h 0mAttemptsStartGFetching and ManagingData in Azure Cosmos DBwith NoSQL API]1h 0mAttemptsStart
GAzure Challenge -Deploying Software with VMExtensions]1h 0mAttemptsStart
13. Challenge Labs]37h 30m48 Labs
boDashboardMy CoursesHands-on LabsSandboxSupport

10/12/25, 12:14LMS | Whizlabs
Page 12 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GDeploying a FlaskApplication with Docker onAzure Ubuntu VM]1h 0mAttemptsStartGVNet Peering Challenge]1h 30mAttemptsStartGBasic Load BalancerChallenge]1h 0mAttemptsStartGCreating Azure Front Doorfor Your Web App]1h 0mAttemptsStartGNetwork Access to StorageAccounts Challenge]1h 0mAttemptsStartGChallenge Lab - InstallingInternet Information Service]1h 0mAttemptsStartGCreate a private link to anAzure Container App withAzure Front Door]1h 0mAttemptsStartGCreate a VNet and Subnetsin Azure Using Terraform]30mAttemptsStartGAzure Firewall Challenge]2h 0mAttemptsStartGAzure Application GatewayChallenge]1h 30mAttemptsStartGAlert on events within yourAzure infrastructure usingActivity Log Alerts challenge]1h 0mAttemptsStartGAzure VM Creation using CLIChallenge]30mAttemptsStartGAzure Web App Creationusing CLI Challenge]30mAttemptsStartGChallenge Lab - Creating aLinux VM]30mAttemptsStart
10/12/25, 12:14LMS | Whizlabs
Page 13 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GChallenge Lab - ImplementAzure Functions]1h 0mAttemptsStartGChallenge Lab - Create aSQL database]30mAttemptsStartGChallenge lab- Storageaccount creation]45mAttemptsStartGChallenge lab- CreatingAzure Resource Lock]45mAttemptsStartGChallenge Lab -Understanding AzureKubernetes Service]45mAttemptsStartGChallenge Lab - CreatingAvailability Set]1h 0mAttemptsStartGChallenge Lab -Understand NetworkSecurity Group rules]30mAttemptsStartGChallenge Lab - InstallingNGINX on Linux using CloudInit]30mAttemptsStartGChallenge Lab - InstallNGINX Webserver usingCustom Script Extensions]30mAttemptsStartGChallenge Lab - AddingData Disks to the VM UsingCLI]30mAttemptsStartGChallenge Lab -Understanding AzureDatabase Services]30mAttemptsStartGChallenge Lab - Workingwith Blob Storage]30mAttemptsStartGChallenge Lab - Workingwith Azure File Shares]30mAttemptsStart
10/12/25, 12:14LMS | Whizlabs
Page 14 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GChallenge Lab -Understanding Azure BlobStorage Tiers]30mAttemptsStartGChallenge lab- Resizing aVirtual machine]30mAttemptsStartGChallenge Lab - Workingwith Alerts]30mAttemptsStartGChallenge Lab - Workingwith resource tags]30mAttemptsStartGChallenge Lab - Adding anetwork interface]30mAttemptsStartGChallenge Lab - Workingwith Application Insights]30mAttemptsStartGChallenge lab - ImplementAzure Kubernetes Service]1h 30mAttemptsStartGChallenge lab - Create agateway Load balancerusing Azure Portal]1h 0mAttemptsStartGChallenge Lab - Create aninternal load balancer toload balance VMs by usingan ARM template]45mAttemptsStartGChallenge Lab - PublishAzure Static Web Appsusing an ARM Template]1h 0mAttemptsStartGChallenge Lab - Create anddeploy Azure Functionresources from an ARMTemplate]45mAttemptsStartGChallenge Lab - AddingData Disk via Console]30mAttemptsStart
10/12/25, 12:14LMS | Whizlabs
Page 15 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298
GChallenge lab - Workingwith Custom Images]45mAttemptsStartGChallenge lab- Create aWindows VM using an ARMtemplate]30mAttemptsStartGChallenge Lab - VirtualMachine Scale Sets: CustomScript Extensions]1h 0mAttemptsStartGChallenge Lab - ImplementDNS name resolution inAzure]30mAttemptsStartGChallenge Lab - ManageWindows Virtual Machineswith Azure Bastion]45mAttemptsStartGChallenge Lab -Containerizing Web Appson Azure App Service]45mAttemptsStartGChallenge Lab - Create anSMB Azure file share andconnect it to a Windows VMusing the Azure portal]1h 0mAttemptsStartGChallenge Lab - Resizing ofVirtual Machine]30mAttemptsStart
14. Lab Projects]12h6 Labs
10/12/25, 12:14LMS | Whizlabs
Page 16 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298CategoriesPopular CoursesCompanyLegalSupport
GBuilding and Hosting aPortfolio using Azure AppService]1h 30mAttemptsStartGAzure APIM Integration withApp Service]1h 30mAttemptsStartGIntegrate Azure Services forWeb Solutions]2h 0mAttemptsStartGMonitor, Diagnose, and FixIoT Solutions]2h 0mAttemptsStartGCreating a Secure Site-to-Site VPN ConnectionBetween Two Azure VirtualNetworks]3h 0mAttemptsFreeGAzure VM Auto-Shutdownand Startup Using AzureFunctions]2h 0mAttemptsStart
Hands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs
10/12/25, 12:14LMS | Whizlabs
Page 17 of 17https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cd

10/11/25, 17:58LMS | Whizlabs
Page 1 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
Incorrect
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationAzure Storage Access Management - Practice ModeCompleted on Sat, 11 Oct 20251stAttempt2/5Marks Obtained40.00%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Implement and manage storage52300TotalAll Domains52300Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Implement and manage storageYou are responsible for securing access to a critical Azure Storage account used for processing regulatory data. The account mustallow access from specific public IPs for auditing purposes, enable trusted Microsoft services for operations, and ensure that all otheraccess, including from unknown networks, is denied. Additionally, only predefined Virtual Network subnets should interact with thestorage account. Match the required configurations with their technical implementation steps by dragging and dropping the optionsinto the corresponding answer areaHome/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Azure Storage Access Management/ReportBack to the Courseh
Download Report
10/11/25, 17:58LMS | Whizlabs
Page 2 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
Explanation:Correct Answers: 1-B, 2-A, 3-C and 4-DConfigurationImplementationSet AllowBlobPublicAccess to FalseDeny all traffic not explicitly allowedEnable “Trusted Microsoft Services” in the firewallEnable exceptions for specific Azure servicesDefine rules under “Networking > Firewall”Configure access for trusted IPsAdd subnet rules to the Virtual NetworkRestrict access to predefined VNetsYour AnswersA. Set AllowBlobPublicAccess to FalseDeny all traffic not explicitly allowed
B. Enable "Trusted Microsoft Services" in the firewallConfigure access for trusted IPs
C. Define rules under "Networking > Firewall"Enable exceptions for specific Azure services
D. Add subnet rules to the Virtual NetworkRestrict access to predefined VNetsCorrect AnswersA. Set AllowBlobPublicAccess to FalseDeny all traffic not explicitly allowedB. Enable "Trusted Microsoft Services" in the firewallEnable exceptions for specific Azure servicesC. Define rules under "Networking > Firewall"Configure access for trusted IPsD. Add subnet rules to the Virtual NetworkRestrict access to predefined VNets
10/11/25, 17:58LMS | Whizlabs
Page 3 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
Set AllowBlobPublicAccess to False - Deny all traffic not explicitly allowed: Setting AllowBlobPublicAccess to False ensures that noblob containers in the storage account are accessible to anonymous users, even if public access is inadvertently configured for acontainer. This is a critical setting to enforce a default-deny policy, which restricts all unauthorized traffic unless explicitly allowed. Thisconfiguration aligns with best practices for regulatory compliance and secures data against accidental exposure to the internet. It isparticularly important for scenarios where sensitive data must be tightly controlled. Administrators can configure this setting usingthe Azure portal, PowerShell, or Azure CLI.Enable "Trusted Microsoft Services" in the firewall - Enable exceptions for specific Azure services: Enabling trusted Microsoft servicesin the storage account firewall settings ensures that Azure services like Azure Backup, Azure Monitor, and Azure DevOps can securelyinteract with the storage account without being blocked by the firewall rules. This configuration is essential for operational scenarioswhere certain Azure services require uninterrupted access to the storage account for backups, logging, or other essential workflows.By enabling this option, you simplify connectivity while maintaining a secure boundary, as only trusted services under Microsoft'scontrol are granted access. This setting is configured in the Azure portal under the "Firewall and virtual networks" section of thestorage account.Define rules under "Networking > Firewall" - Configure access for trusted IPs: Defining rules under the "Networking > Firewall" sectionallows you to specify public IP addresses or IP ranges (in CIDR notation) that are permitted to access the storage account. Thisconfiguration is crucial for scenarios where access must be granted to on-premises systems, remote administrators, or specificservices with known IPs for tasks such as auditing or management. By explicitly defining trusted IP rules, you ensure that onlyauthorized external sources can interact with the storage account while all other traffic remains blocked. This granular control is keyto maintaining a secure and compliant environment.Add subnet rules to Virtual Network - Restrict access to predefined VNets: Adding subnet rules to a Virtual Network restricts access tothe storage account so that only resources within the specified VNets can communicate with it. This setup ensures that internal trafficbetween Azure resources remains secure and isolated, preventing any direct exposure to the public internet. For example, a databaseor application hosted within an authorized subnet can access the storage account while all other networks are blocked. Thisconfiguration is particularly important for scenarios involving sensitive or regulated workloads that require strict data access policies.
10/11/25, 17:58LMS | Whizlabs
Page 4 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
IncorrectAdministrators can define these rules in the Azure portal by linking the storage account to the appropriate VNet and subnets.References:
Ask our ExpertsDid you like this Question?Question 2Domain: Implement and manage storageAn application requires temporary access to download and upload blobs within a container in Azure Storage. To ensure security, theaccess must be restricted by a SAS token with a validity of 15 minutes and limited to Read and Write operations. Arrange the steps tocreate and validate the SAS token for this purpose.
Explanation:Correct Answers: E, D, C, B and Ahttps://learn.microsoft.com/en-us/azure/storage/blobs/anonymous-read-access-configure?tabs=portal#disable-anonymous-public-access-to-all-blob-datahttps://learn.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal#trusted-microsoft-serviceshttps://learn.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal#grant-access-from-an-internet-ip-rangehttps://learn.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal#grant-access-to-trusted-azure-virtual-networks
Your Answer1.C. Set the container as the resource type andspecify the Read and Write permissions2.E. Obtain the account key or configure a userdelegation key for token generation3.D. Define the token’s start and expiry timeswith a 15-minute validity4.B. Use the az storage container generate-sascommand to create the SAS token5.A. Verify the token by performing a test uploadand download using the SAS URLCorrect Answer1.E. Obtain the account key or configure a userdelegation key for token generation2.D. Define the token’s start and expiry timeswith a 15-minute validity3.C. Set the container as the resource type andspecify the Read and Write permissions4.B. Use the az storage container generate-sascommand to create the SAS token5.A. Verify the token by performing a test uploadand download using the SAS URL
10/11/25, 17:58LMS | Whizlabs
Page 5 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
1. (E) Obtain the account key or configure a user delegation key - Required for signing the SAS token securely.2. (D) Define the token’s start and expiry times with a 15-minute validity - This sets the limited access window for enhancedsecurity.3. (C) Set the container as the resource type and specify Read and Write permissions - Ensures only necessary actions areallowed on the container.4. (B) Use the az storage container generate-sas command to create the SAS token - Generates the actual token using CLI andthe specified parameters.5. (A) Verify the token by performing a test upload and download using the SAS URL - Ensures the token works correctly withthe intended permissions and validity.
Step 1 - Option E: Obtain the account key or configure a user delegation key for token generation is correct. To generate a SAS token,authentication with the Azure Storage account is required. This can be achieved either by using the account key or through MicrosoftEntra ID integration to obtain a user delegation key. Using a user delegation key is recommended when enhanced security and fine-grained access control are needed, especially for scenarios involving Microsoft Entra ID. For this scenario, obtaining the account keyor user delegation key is the foundational step, as it is required for signing the SAS token, ensuring that the token can enforce thedefined access policies.Step2 - Option D: Define the token’s start and expiry times with a 15-minute validity is correct. After establishing the authenticationcredentials, the next step is to configure the SAS token's time-based validity. Defining both the start time and the expiry time ensuresthe token adheres to the temporary access requirements specified in the scenario. By setting a 15-minute validity period, you not onlylimit exposure but also align with security best practices, as shorter token lifespans reduce the risk of misuse if the token iscompromised.Step3 - Option C: Set the container as the resource type and specify the Read and Write permissions is correct. Once the token'svalidity is defined, the next step is to specify the resource to that the SAS token will apply, which, in this case, is the container.Configuring the permissions Read and Write ensures that the token allows only the necessary actions for downloading and uploading
10/11/25, 17:58LMS | Whizlabs
Page 6 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
Correctblobs within the container. This step is crucial for maintaining the principle of least privilege, as it restricts access to just the operationsneeded for the application’s functionality.Step4 - Option B: Use the az storage container generate-sas command to create the SAS token is correct. With the permissions,resource type, and validity times defined, the next step is to generate the SAS token. The Azure CLI command az storage containergenerate-sas provides a streamlined way to create the token. This command uses the provided inputs resource type, permissions,time constraints, and authentication mechanism (account key or delegation key) to generate a valid SAS token. The resulting token isa URL string that incorporates all defined configurations, ready for use.Step5 - Option A: Verify the token by performing a test upload and download using the SAS URL is correct. Validation is the final stepto ensure the generated SAS token operates as intended. By appending the token to the container URL, the application can use it toperform test operations downloading and uploading blobs within the container. Successful execution confirms that the token hasbeen correctly configured, while any failure may indicate a misconfiguration (e.g., incorrect permissions or validity period). Testingensures the token meets security and operational requirements before deployment.References:
Ask our ExpertsDid you like this Question?Question 3Domain: Implement and manage storageA development team in your organization needs to store project files in an Azure Files share hosted in the storage accountDevStorage1. They require access using Microsoft Entra ID credentials. The solution must enforce role-based access control (RBAC) atthe storage account level and granular NTFS permissions at the file share level. Developers must be able to map the file share directlyto their workstations without any manual configuration changes. Which three of the following actions should be taken to meet therequirements for access, permissions, and mapping the Azure Files share? (Select three)
Explanation:https://learn.microsoft.com/en-us/rest/api/storageservices/create-user-delegation-sashttps://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overviewhttps://learn.microsoft.com/en-us/cli/azure/storage/container?view=azure-cli-latest#az-storage-container-generate-sas
Your AnswerA. Enable identity-based accessB. Assign SMB Contributor roleC. Configure NTFS permissionsCorrect AnswerA. Enable identity-based accessB. Assign SMB Contributor roleC. Configure NTFS permissions
10/11/25, 17:58LMS | Whizlabs
Page 7 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
Correct Answers: A, B and C Option A is correct because enabling identity-based access allows the storage account to integrate with Microsoft Entra ID forauthentication. This step is critical because the developers require access to the Azure Files share using their Entra ID credentials. Byenabling this feature, the storage account can enforce security policies aligned with the organization’s identity management andaccess control mechanisms. This ensures seamless authentication and eliminates the need for manual key management or storageaccount keys. Without enabling this feature, the RBAC and NTFS permissions at the file level cannot be applied effectively.Option B is correct because the SMB Contributor role is essential for granting the development team the necessary permissions toaccess and interact with the file share. Assigning this role enables role-based access control (RBAC) at the Azure storage accountlevel, allowing developers to read, write, and delete files in the share. RBAC operates at the service level, which works alongside NTFSpermissions to provide more granular control over file access. Without this role, users may be authenticated but will lack the requiredpermissions to access or modify the files within the share.Option C is correct because configuring NTFS permissions is essential for providing granular access control at the file level. Whilethe SMB Contributor role grants access at the Azure level, NTFS permissions define what users can do at the individual file and folderlevel within the file share. This is a critical step to ensure that only authorized users can modify or view specific files. For example,different folders within the file share may require varying levels of access based on the developers’ roles.
Option D is incorrect because while mapping a share using Entra ID credentials is part of the process for users to access the fileshare, it is not an action required to configure access or permissions for the Azure Files share. Mapping is a client-side operationperformed by users to connect to the file share. This step assumes that identity-based access and appropriate permissions (RBACand NTFS) are already configured.Option E is incorrect because enabling Advanced Threat Protection (ATP) for Azure Storage is a security feature that detects andresponds to anomalous activity, such as unusual access patterns or potential attacks. While ATP is a valuable security enhancement,it does not directly address the requirements for configuring access, permissions, or mapping the Azure Files share.References: 
10/11/25, 17:58LMS | Whizlabs
Page 8 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
CorrectAsk our ExpertsDid you like this Question?Question 4Domain: Implement and manage storageAn organization needs to provide time-limited access to a specific blob container for an external partner to upload files.Proposed Solution: To achieve this, the administrator creates a stored access policy with write permissions and sets the expiry time to24 hours. The associated shared access signature (SAS) is then generated and shared with the partner. Subsequently, the storedaccess policy is deleted before the partner attempts to upload files. Is this proposed solution correct? (Select Yes or No)
Explanation:Correct Answer: BThe proposed solution is incorrect because deleting the stored access policy immediately renders any shared access signature(SAS) tokens generated from that policy invalid. A SAS token, when tied to a stored access policy, depends on the existence andconfiguration of the policy to maintain its validity. Once the policy is deleted, all associated SAS tokens are no longer functional, even iftheir expiration time has not yet been reached. Stored access policies are a crucial feature in Azure Storage, as they enablecentralized management of permissions and expiration times for SAS tokens. This allows administrators to update or revoke accesspermissions without needing to modify or regenerate the SAS tokens themselves. However, if the stored access policy is deleted, itrevokes the underlying permissions of any SAS token associated with it. Consequently, the token holder, in this case, the externalpartner, will not be able to access the blob container, regardless of the token's expiration time.https://learn.microsoft.com/en-us/azure/storage/files/storage-files-identity-ad-ds-overviewhttps://learn.microsoft.com/en-us/azure/storage/files/storage-files-active-directory-overview#azure-rbac-for-azure-fileshttps://learn.microsoft.com/en-us/azure/storage/files/storage-files-identity-configure-file-level-permissions
A. YesB. Noright
10/11/25, 17:58LMS | Whizlabs
Page 9 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
Incorrect
This scenario emphasizes the need for a clear understanding of how stored access policies function in Azure Storage. If there is aneed to adjust or revoke permissions for specific SAS tokens, administrators should modify the stored access policy or generate newtokens rather than deleting the policy altogether. Deleting a stored access policy should be done with the understanding that it willaffect all SAS tokens linked to it.Reference:  Ask our ExpertsDid you like this Question?Question 5Domain: Implement and manage storageYou are working as an Azure Administrator for a large enterprise that utilizes Azure Blob Storage for storing sensitive financial data. Thecompany requires the implementation of strict security measures for accessing this data. As part of your task, you need to managethe access keys for a storage account used by the financial application. Which of the following actions should you perform to ensurethat the access keys remain secure and accessible only when necessary? (Select three options)Grant limited access to data with shared access signatures (SAS)
A. Create and use Azure Managed Identity for accessing the storage account programmatically, without the need to use accesskeysright
10/11/25, 17:58LMS | Whizlabs
Page 10 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
Explanation:Correct Answers: A, C and EOption A is correct because Azure Managed Identity is the most secure method for authenticating applications without using accesskeys or secrets. By enabling Managed Identity, you avoid the need to manually manage access keys, significantly reducing thesecurity risk associated with their exposure. Managed Identity is an identity automatically assigned to resources in Azure and is usedfor Azure services to authenticate without using credentials. By using Managed Identity, your application can authenticate to thestorage account without requiring access keys. This provides enhanced security since it eliminates the need to store keys inconfiguration files or hard-code them in code, reducing the risk of accidental exposure.Option C is correct because storing access keys in Azure Key Vault provides enhanced security for managing and safeguarding keys.Azure Key Vault is specifically designed for securely storing secrets such as API keys, passwords, and access keys. When you store yourstorage account access keys in Key Vault, they are encrypted and managed centrally. The access is governed by Azure role-basedaccess control (RBAC), meaning only authorized users or applications can retrieve them. Additionally, Key Vault facilitates keymanagement by enabling the easy rotation, disabling, or regeneration of keys without needing to update your applicationconfigurations. Key Vault also offers audit capabilities, keeping track of who accessed the keys and when improving visibility andtraceability. This approach reduces the risk of key exposure that might occur if they were stored directly in application code orconfiguration files.Option E is correct because Microsoft Entra Authentication provides a secure method of managing access to storage accounts byreplacing access keys with identity-based authentication. With this approach, applications and users are authenticated using theirMicrosoft Entra identities, eliminating the need for direct key usage. This enhances security by enforcing the principle of least privilege,allowing administrators to define precise access permissions for users, groups, or applications through role-based access control(RBAC). Administrators can specify roles such as read or write access, ensuring resources are accessed only by authorized entities.Additionally, identity-based authentication negates the need for key rotation, reducing the risk of key exposure. The method alsosupports detailed activity monitoring, offering insights into who accessed resources and when. By relying on identities, this solutionprevents the exposure of access keys, ensuring that only authorized identities can interact with the storage account, therebystrengthening both security and compliance.B. Configure the storage account to allow only one active access key at a time for better security managementwrongC. Enable Azure Key Vault integration and store the access keys in Key Vault, using a Key Vault-backed secret to authenticateapplicationsrightD. Configure the "Access keys" option to generate new keys every 30 days, while keeping the old keys active during the transitionE. Restrict access to storage account keys by using Microsoft Entra Authentication  for users and applications instead of directkey usageright
boDashboardMy CoursesHands-on LabsSandboxSupport

10/11/25, 17:58LMS | Whizlabs
Page 11 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
Option B is incorrect because while restricting the number of active keys can improve security, this option does not provide a robustsolution on its own. Managing access keys manually (especially if you still use them for authentication) introduces risks related to keyexposure. Storing and handling access keys, even with only one active key, still leaves the possibility of accidental exposure,unauthorized access, or mishandling. Additionally, rotating keys manually with this configuration can still cause disruptions in serviceif the applications do not retrieve the new keys correctly or in time. Using managed identities or Key Vault is a more secure approachthat eliminates the risks associated with direct access key management.Option D is incorrect because configuring the "Access keys" option to regenerate keys every 30 days while keeping old keys activeduring the transition introduces both security and operational challenges. Although the periodic regeneration of keys is intended toenhance security, this practice still relies on access keys for authentication, which is inherently less secure than using identity-basedmethods such as Microsoft Entra ID or Managed Identity. The 30-day interval leaves a prolonged window in which keys couldpotentially be compromised. Furthermore, retaining old keys during the transition period increases the risk of exposure, as both oldand new keys could be accessed simultaneously, potentially by unauthorized users. This dual-key approach adds complexity to theprocess of securely updating applications, as administrators must ensure all applications switch to the new key within the allottedtime frame. Delays or errors in this update process could result in downtime or continued reliance on insecure keys. By contrast,identity-based methods eliminate the need for key regeneration altogether, providing a more secure and streamlined solution.References: 
Ask our Expertshttps://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overviewhttps://learn.microsoft.com/en-us/azure/key-vault/general/overviewhttps://learn.microsoft.com/en-us/rest/api/storageservices/authorize-with-azure-active-directory
10/11/25, 17:58LMS | Whizlabs
Page 12 of 12https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70305/report/8450590
Did you like this Question?Finish Review
CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdHands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/7/25, 19:41LMS | Whizlabs
Page 1 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
Correct
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationMicrosoft Entra - Practice ModeCompleted on Tue, 07 Oct 20251stAttempt3/7Marks Obtained42.86%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Manage Azure identities andgovernance73400TotalAll Domains73400Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Manage Azure identities and governanceA tenant administrator wants to ensure that guest users added to a Microsoft Entra ID tenant cannot invite additional guest users.Proposed Solution: Restrict the "Guest inviter role" in the tenant settings under External Collaboration Settings in the Microsoft Entraadmin center to disable guests' ability to invite other users. Is this proposed solution correct? (Select Yes or No)Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Microsoft Entra/ReportBack to the Courseh
Download Report
A. Yesright
10/7/25, 19:41LMS | Whizlabs
Page 2 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
IncorrectExplanation:Correct Answer: AThe proposed solution is correct because restricting the "Guest inviter role" in the Microsoft Entra ID tenant settings under ExternalCollaboration Settings is a valid and effective approach to ensure that guest users cannot invite additional users into the directory. 
This ensures that only authorized roles, like Global Admins or User Admins, can add new guests. It helps organizations maintainstronger security by reducing the risk of unauthorized access or accidental over-permissioning.  This setting supports the principle ofleast privilege, where users only get the permissions they truly need. Admins can configure this directly in the Microsoft Entra admincenter by turning off the “Allow guests to invite” option with no custom scripts or third-party tools required.References: 
Ask our ExpertsDid you like this Question?Question 2B. No
Limit who can invite guestsConfigure external collaboration settings for B2B in Microsoft Entra External ID
10/7/25, 19:41LMS | Whizlabs
Page 3 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
Domain: Manage Azure identities and governanceA multinational corporation plans to manage license assignments in Microsoft Entra ID for its global teams. You are tasked withimplementing region-specific license assignments while adhering to the following constraints:
Arrange the steps in the correct sequence to meet the above constraints.
Explanation:Correct Answers : D, A, B, E and C1. Identify available license quotas for each region.2. Create dynamic groups for users based on their geographical location.3. Assign licenses to region-specific dynamic groups.4. Adjust license assignments to avoid exceeding quotas.5. Use Microsoft Entra ID monitoring to generate compliance reports by regionDynamic user management must be enabled.Excess license usage or underutilization must be prevented.Region-based compliance reports must be generated post-implementation.Your Answer1.A. Create dynamic groups for users based ontheir geographical location2.D. Identify available license quotas for eachregion3.B. Assign licenses to region-specific dynamicgroups4.E. Adjust license assignments to avoidexceeding quotas5.C. Use Microsoft Entra ID monitoring togenerate compliance reports by regionCorrect Answer1.D. Identify available license quotas for eachregion2.A. Create dynamic groups for users based ontheir geographical location3.B. Assign licenses to region-specific dynamicgroups4.E. Adjust license assignments to avoidexceeding quotas5.C. Use Microsoft Entra ID monitoring togenerate compliance reports by region
10/7/25, 19:41LMS | Whizlabs
Page 4 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
Step1 - Identify available license quotas for each region: The first step is understanding the available licensing quotas per region to ensure proper allocation. This involves analyzing the totalnumber of licenses purchased and comparing them with the active users in each geographical location. By doing so, theorganization can prevent oversubscription or underutilization, a critical compliance requirement. This ensures that the foundation forassigning licenses is set accurately.Step2 - Create dynamic groups for users based on their geographical location: Dynamic groups in Microsoft Entra ID enableautomatic user assignments based on predefined rules. For this step, create groups that filter users based on attributes like country,city, or department. For example, a rule like (user.department -eq "Europe Sales") can be applied to segregate users in Europe. Thisautomation ensures that license management is scalable and eliminates manual effort.Step3 - Assign licenses to region-specific dynamic groups: After creating the groups, licenses must be assigned to these dynamic groups. Group-based licensing in Microsoft Entra ID simplifiesthe assignment of licenses to all users within a group. By assigning licenses at the group level, the organization ensures that all groupmembers receive appropriate access based on their region, reducing the risk of missed assignments or duplications.Step4 - Adjust license assignments to avoid exceeding quotas: At this stage, adjust license assignments to align with the quotas identified in Step 1. This involves reviewing dynamic groupmembership to ensure compliance with regional limits. If necessary, reallocate licenses to ensure that no group exceeds itsallocation. Microsoft Entra provides notifications about license conflicts or insufficient quantities, allowing the administrator to resolveissues before finalizing assignments.Step5 - Use Microsoft Entra ID monitoring to generate compliance reports by region: Finally, generate compliance and usage reportsusing Microsoft Entra ID insights. These reports help validate that the assigned licenses meet regional needs and comply with theorganization's policies.References:
10/7/25, 19:41LMS | Whizlabs
Page 5 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
IncorrectAsk our ExpertsDid you like this Question?Question 3Domain: Manage Azure identities and governanceYour organization requires external users to be periodically reviewed for access to shared resources. These reviews mustautomatically trigger access removal if reviewers do not approve them. Additionally, users must be reminded before each reviewcycle to take necessary action. Which three of the following services would best meet the requirements for managing these accessreviews and reminders? (Select three)
Explanation:Correct Answers: A, E and F Option A: Microsoft Entra ID Governance - Access reviews is correct because this feature is specifically designed to periodicallyreview and validate access for internal and external users. This service allows organizations to automate the review process, ensuringthat access is retained only for users whose access is approved by designated reviewers. If access is not approved, it canautomatically trigger removal, satisfying the requirement to enforce compliance. This functionality is critical for managing externalusers, as it prevents unnecessary or overprivileged access to sensitive resources. The ability to integrate these reviews with othergovernance workflows, such as entitlement management, makes this feature indispensable for the given scenario. Access reviewshelp maintain security and operational efficiency by automating an otherwise manual and error-prone process.Option E: Privileged Identity Management (PIM) is because it is essential for controlling access to privileged roles, including thoseassigned to external users. While primarily focused on privileged accounts, PIM supports the review of role assignments andimplements just-in-time (JIT) access for critical resources. This aligns with the scenario’s need for periodic access reviews, ensuringexternal users are granted temporary access that expires if not renewed or reapproved. PIM’s integration with notification andexpiration workflows further enhances governance, making it possible to enforce stricter access policies while maintainingView Microsoft 365 account license and service details with PowerShellManage rules for dynamic membership groups in Microsoft Entra IDAssign or unassign licenses for users in the Microsoft 365 admin center What is the Usage and insights report in Microsoft Entra ID?
Your AnswerA. Microsoft Entra ID Governance - Access reviewsB. Conditional Access authentication contextD. Guest invitation managementCorrect AnswerA. Microsoft Entra ID Governance - Access reviewsE. Privileged Identity Management (PIM)F. Microsoft Entra entitlement management
boDashboardMy CoursesHands-on LabsSandboxSupport

10/7/25, 19:41LMS | Whizlabs
Page 6 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
compliance. Though not limited to external users, PIM adds an extra layer of security and governance, making it relevant in thecontext of periodic reviews for sensitive roles.Option F: Microsoft Entra entitlement management is correct because it is an effective tool for automating the management ofexternal user access throughout its lifecycle. It facilitates workflows for access requests, approvals, and notifications, and it integratesseamlessly with access review processes. This includes automated reminders that notify external users before a review cycle begins,prompting them to take the necessary steps to maintain their access. Entitlement management plays a crucial role in supportingcollaboration with external users while ensuring control and compliance. By aligning with access reviews, it enables a morecomprehensive approach to access governance, making it an essential component in managing external user access. Its ability toautomate and simplify complex governance workflows is key to effective external user management.
Option B: Conditional Access authentication context is incorrect because it focuses on securing access to resources throughpolicies that enforce conditions such as multi-factor authentication (MFA) or device compliance. While it is valuable for ensuringsecure access in real time, it does not support periodic reviews or the automation of access removal. Conditional Access is gearedtoward managing and enforcing access policies dynamically based on user context, but it does not address the governance aspectsof reviewing or notifying external users about access. Thus, it does not meet the requirements of this scenario.Option C: Microsoft Entra ID Protection is incorrect because it is designed to identify and mitigate identity-related risks, such asdetecting compromised accounts or suspicious login behavior. It leverages risk-based policies to enforce conditional accesscontrols, ensuring that only legitimate users can access resources. However, it does not include functionality for periodic accessreviews, automated notifications, or access removal workflows. While crucial for securing identities, it is not relevant to governancetasks like reviewing and managing external user access as described in the scenario.Option D: Guest invitation management is incorrect because it is primarily used to invite, approve, and monitor external users’ initialaccess to organizational resources. While it ensures that external users are onboarded securely, it does not provide functionality forperiodic access reviews or automated removal of access if not approved. Its role ends after the external user is granted access, and itdoes not handle ongoing governance tasks like reviews or notifications. As a result, this feature does not address the requirements ofthis scenario.
10/7/25, 19:41LMS | Whizlabs
Page 7 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
CorrectReferences: 
Ask our ExpertsDid you like this Question?Question 4Domain: Manage Azure identities and governanceYou are managing a Microsoft Entra ID tenant for a global organization with several subsidiaries. As part of the shift to a remote-firstworkforce, you’ve already enabled Self-Service Password Reset (SSPR) across the tenant.However, specific departments have unique compliance requirements:What should you configure to meet these department-specific requirements while ensuring the overall SSPR configuration remainssecure and efficient? (Select three)
Explanation:Correct Answers: B, C and DOption B is correct because by creating group-based policies, you can tailor the authentication requirements for specific groupswithin the organization. For example, the Marketing department can be assigned to a group that allows them to use only onehttps://learn.microsoft.com/en-us/entra/id-governance/access-reviews-overviewhttps://learn.microsoft.com/en-us/entra/id-governance/privileged-identity-management/pim-configurehttps://learn.microsoft.com/en-us/entra/id-governance/entitlement-management-overview
The Marketing team only needs one authentication method to reset their passwords.The Legal and Finance teams handle sensitive data and must use two authentication methods for additional security.A. Configure SSPR for the entire organization with phone and email as authentication methods, but allow the Legal and Financedepartments to add security questions for further verificationB. Create group-based SSPR policies to apply different authentication methods based on group membershiprightC. Configure SSPR to require only one authentication method for the Marketing department and two methods for Legal andFinancerightD. Configure MFA as a global requirement for all users, with exceptions only for the Marketing department using a conditionalaccess policyrightE. Implement a rule for SSPR that blocks access to password reset for users from high-risk geographical locations unless theyperform MFA
10/7/25, 19:41LMS | Whizlabs
Page 8 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
authentication method, while the Legal and Finance departments can be assigned to a separate group that requires two-factorauthentication (such as phone and email, or email and security questions). Group-based policies allow for granular control over thesecurity settings for different groups of users, ensuring that you can balance convenience and security. Using Microsoft Entra IDgroups to manage these policies is a scalable solution, especially in large organizations with diverse compliance needs. This methodensures that you meet specific compliance and security standards for each department without unnecessarily complicating theSSPR setup for the entire organization.Option C is correct because configuring SSPR policies to enforce one authentication method for the Marketing department (e.g.,email verification) and two authentication methods for the Legal and Finance departments (e.g., phone verification and emailverification) addresses both the security and convenience needs of each department. This configuration ensures that the Marketingdepartment, which does not have strict security requirements, can reset their passwords efficiently with fewer steps, minimizingfriction. On the other hand, the Legal and Finance departments, which manage sensitive information, can be required to use moresecure methods like multi-factor authentication (MFA). This strategy is flexible and aligns with Microsoft's security guidelines, ensuringthat each department's security needs are met without compromising the user experience for those in less sensitive roles.Option D is correct because MFA as a global requirement for all users ensures a higher level of security, especially in a remote-firstorganization where users may be accessing the environment from different locations and devices. By applying a global MFA policyand making exceptions for the Marketing department using a conditional access policy, you can ensure that more sensitivedepartments like Legal and Finance are always required to use MFA, while Marketing users can be exempted from this requirement.Conditional access policies can be fine-tuned to apply or exempt MFA requirements based on user roles, locations, or devicecompliance. This makes MFA a strong, organization-wide security policy while allowing flexibility for less critical departments. Applyingthis strategy at the global level strengthens overall security, reduces the attack surface, and ensures compliance with organizationalsecurity standards for all users except those in the Marketing department.
Option A is incorrect because security questions are not considered a secure authentication method, particularly for departmentslike Legal and Finance that handle sensitive information. Security questions can be susceptible to social engineering attacks or easilyguessed answers. Additionally, SSPR configurations should prioritize stronger methods, such as phone and email verification, which
10/7/25, 19:41LMS | Whizlabs
Page 9 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
Correctare commonly used in multi-factor authentication (MFA) scenarios. According to Microsoft’s best practices, relying on securityquestions as the primary supplementary method for sensitive departments fails to meet modern security standards. As a result, thisapproach does not align with the security requirements for the Legal and Finance departments.Option E is correct because it focuses on blocking access to SSPR for users based on their geographical location, which could beproblematic in a remote-first workforce. Many employees will be working from various locations worldwide, and restricting SSPRbased on geographic location could create unnecessary friction. Additionally, MFA would already be enforced through otherconfigurations such as conditional access policies, so it may be redundant to introduce geographic restrictions specifically for SSPRaccess. The need for geographic restrictions should be evaluated carefully, as remote work may involve users from a wide range oflocations, and enforcing such restrictions could potentially create more complexity than necessary.References: 
Ask our ExpertsDid you like this Question?Question 5Domain: Manage Azure identities and governanceYour organization has implemented a compliance-driven access policy requiring precise role assignments to Azure resources. Youare tasked with analyzing operational scenarios and assigning the appropriate Azure built-in roles to meet specific, nuancedrequirements. Failure to assign the correct roles could compromise system integrity or operational efficiency. Match the followingAzure built-in roles to their corresponding description.Note: To match roles with the correct scenario, you need to drag and drop the appropriate role into the corresponding answer area.Carefully consider the constraints and permissions described.https://learn.microsoft.com/en-us/entra/identity/authentication/tutorial-enable-ssprhttps://learn.microsoft.com/en-us/entra/identity/authentication/concept-sspr-howitworkshttps://learn.microsoft.com/en-us/entra/identity/conditional-access/policy-all-users-mfa-strength#create-a-conditional-access-policy
10/7/25, 19:41LMS | Whizlabs
Page 10 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
Explanation:Correct Answers: 1-C, 2-A, 3-B and 4-DYour AnswersA. Virtual Machine ContributorRole responsible for enabling application lifecycle tasks such asscaling compute resources, performing system diagnostics, andapplying security updates for deployed services, excludingadministrative controls over data access policiesB. Network ContributorRole is essential for configuring and managing subnetarchitectures, enforcing network security through rules, andoverseeing communication flows within Azure infrastructure, but itcannot influence cross-resource dependenciesC. Storage Blob Data ContributorRole granting permissions to facilitate granular object-leveloperations within storage accounts, allowing restrictedmanagement of blob containers and SAS tokens, yet prohibitingchanges to encryption or replication configurationsD. User Access AdministratorRole mandated to oversee delegation of resource-level permissionsfor teams, allowing boundary-specific access controls whilerestricting the ability to make any direct resource alterationsCorrect AnswersA. Virtual Machine ContributorRole responsible for enabling application lifecycle tasks such as scalingcompute resources, performing system diagnostics, and applyingsecurity updates for deployed services, excluding administrative controlsover data access policiesB. Network ContributorRole is essential for configuring and managing subnet architectures,enforcing network security through rules, and overseeing communicationflows within Azure infrastructure, but it cannot influence cross-resourcedependenciesC. Storage Blob Data ContributorRole granting permissions to facilitate granular object-level operationswithin storage accounts, allowing restricted management of blobcontainers and SAS tokens, yet prohibiting changes to encryption orreplication configurationsD. User Access AdministratorRole mandated to oversee delegation of resource-level permissions forteams, allowing boundary-specific access controls while restricting theability to make any direct resource alterations
Virtual Machine ContributorRole responsible for enabling application lifecycle tasks such as scaling compute resources, performing system diagnostics,and applying security updates for deployed services, excluding administrative controls over data access policiesNetwork ContributorRole is essential for configuring and managing subnet architectures, enforcing network security through rules, andoverseeing communication flows within Azure infrastructure, but it cannot influence cross-resource dependenciesStorage Blob Data ContributorRole granting permissions to facilitate granular object-level operations within storage accounts, allowing restrictedmanagement of blob containers and SAS tokens, yet prohibiting changes to encryption or replication configurationsUser Access AdministratorRole mandated to oversee delegation of resource-level permissions for teams, allowing boundary-specific access controlswhile restricting the ability to make any direct resource alterations
10/7/25, 19:41LMS | Whizlabs
Page 11 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
The Virtual Machine Contributor role is designed to grant users permissions to manage virtual machines (VMs) without providingadministrative access to the underlying resource group or subscription. This includes starting, stopping, resizing, and updatingvirtual machines, as well as attaching or detaching disks. However, this role does not allow users to modify RBAC settings or manageother Azure resources associated with the VM, such as networks or storage accounts. This role is ideal for application teams who needto manage compute resources within predefined boundaries, ensuring operational flexibility without compromising security.
10/7/25, 19:41LMS | Whizlabs
Page 12 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
IncorrectThe Network Contributor role is specifically designed to enable users to manage all networking-related resources within an Azuresubscription. This includes creating, modifying, and deleting virtual networks, subnets, network security groups, and configuringrouting rules. However, it does not grant permission to modify or access non-network resources such as virtual machines or storageaccounts. This separation ensures that network administrators can work within their domain without impacting other operationalcomponents. This role is critical for managing communication flows and ensuring secure connectivity between Azure resources whileadhering to the principle of least privilege.The Storage Blob Data Contributor role provides granular permissions to manage Azure Storage blob containers and objects. Usersassigned this role can create, delete, and update blob containers, upload files, and manage access policies through SAS tokens.However, this role does not extend to broader storage account management tasks, such as configuring encryption, firewalls, oraccess keys. This role is ideal for scenarios where users require fine-grained access to object storage without administrative controlover the underlying storage account, ensuring operational security and compliance.The User Access Administrator role is designed to manage access to Azure resources by assigning or removing role-based accesscontrol (RBAC) permissions, without allowing modifications or management of the resources themselves. This ensures a separationbetween managing access and handling resources, which is crucial for maintaining organizational policies and compliance. The roleis particularly beneficial in situations where teams need to delegate access rights across a large scale, ensuring that resourcemanagement responsibilities are kept distinct from access control functions. This approach helps mitigate risks associated withunauthorized changes to resources.Reference:Ask our ExpertsDid you like this Question?Question 6Domain: Manage Azure identities and governanceYou are setting up access control in a large enterprise environment. A user, “UserX”, needs to manage only the storage accounts in the“MarketingRG” resource group but should not have permissions on other types of resources such as virtual machines or databases inthe same group. Additionally, “UserX” should have read-only access to all resources in the “HRRG” resource group. What is the mostappropriate way to assign roles for UserX to meet these requirements?https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
A. Assign Storage Account Contributor role at the “MarketingRG” level and Reader role at the “HRRG” levelrightB. Assign a Contributor role at the “MarketingRG” level and a Reader role at the “HRRG” levelC. Assign the Owner role at the “MarketingRG” level and a Reader role at the “HRRG” levelD. Assign Storage Blob Data Contributor role at the “MarketingRG” level and Reader role at the “HRRG” levelwrong
10/7/25, 19:41LMS | Whizlabs
Page 13 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
Explanation:Correct Answer: AOption A is CORRECT because: Storage Account Contributor role allows the user to create, manage, and delete storage accountswithin a scope, without giving access to other resource types like virtual machines or databases. Assigning this role at theMarketingRG level ensures that UserX’s permissions are restricted only to storage services, satisfying the principle of least privilege.Assigning the Reader role at the HRRG level enables read-only access to all resources in that resource group, fulfilling the secondaryrequirement of visibility without modification rights.
Option B is INCORRECT because The Contributor role at the “MarketingRG” level would grant “UserX” broad access to manage alltypes of resources within the “MarketingRG” resource group, including virtual machines, databases, and networking components.This is not in line with the requirement to restrict access to only the storage accounts within “MarketingRG”. The Reader role at the“HRRG” level is appropriate, but combining it with the Contributor role for the entire “MarketingRG” resource group would violate theintent of restricting “UserX’s” permissions to just storage accounts.Option C is INCORRECT because The Owner role grants full administrative permissions, including the ability to delete or modify anyresources, not just storage accounts. “UserX” would be able to modify any resource type within the “MarketingRG” resource group,including virtual machines, databases, and networking resources, which is not required in this case. This violates the principle of leastprivilege, where users should only have the minimum permissions necessary for their tasks. While the Reader role at the “HRRG” level iscorrect, the Owner role at the “MarketingRG” level goes beyond the required permissions and grants unnecessary access.Option D is INCORRECT because The Storage Blob Data Contributor role is more restrictive than the Storage Account Contributorrole. It specifically allows the user to manage blob data (containers, blobs, etc.) but does not provide the necessary permissions tomanage the storage account itself (such as creating or deleting storage accounts). “UserX” needs to manage the storage accountsthemselves, not just blob data within those accounts. Thus, this role does not fully meet the requirement to manage all aspects ofstorage accounts. The Reader role at the “HRRG” level is correct, but the Storage Blob Data Contributor role does not provide sufficient
10/7/25, 19:41LMS | Whizlabs
Page 14 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
Incorrectpermissions for managing the storage accounts themselves.References: 
Ask our ExpertsDid you like this Question?Question 7Domain: Manage Azure identities and governanceYou are an Azure Administrator reviewing access permissions for an enterprise application (AppUser) that needs to read data from allstorage accounts in a specific resource group named ResourceGroupA. However, individual storage accounts within this resourcegroup have custom roles and deny assignments. You must apply the principle of least privilege and evaluate what the user can andcannot do.Here is the access configuration for AppUser:
Which TWO statements below are true about AppUser’s effective access permissions? ( Select 2 )
Explanation:Correct Answers: B and Ehttps://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#storage-account-contributorhttps://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#reader
Assigned Reader role at the subscription levelAssigned Contributor role at the ResourceGroupA levelAssigned a custom role with only “read” permissions on StorageAccountB within ResourceGroupAA Deny assignment exists on StorageAccountB, scoped directly to AppUserA. AppUser will be able to read data from all storage accounts within Resource Group A, regardless of individual roleassignmentswrongB. The deny assignment on Storage Account B will override any role-based access assignments for AppUserrightC. AppUser's access to Storage Account B is governed by the custom role and is not affected by the deny assignmentD. AppUser will have full access to Resource Group A due to the Contributor role assignmentE. AppUser will not be able to read data from Storage Account B due to the presence of a deny assignment, even though thecustom role grants read accessright
10/7/25, 19:41LMS | Whizlabs
Page 15 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
Option B is CORRECT because Azure RBAC has a well-defined priority: deny assignments take precedence over role-based access(RBAC assignments).  This means that even though AppUser has been assigned the Reader role at the subscription level and acustom read role on Storage Account B, the deny assignment on Storage Account B will prevent any access to that storage account.Deny assignments cannot be overridden by role assignments at lower scopes, ensuring that the principle of least privilege is enforcedby denying access explicitly.Option E is CORRECT because deny assignments take precedence over role-based access assignments in Azure. Even thoughAppUser is assigned a custom role that grants read permissions on Storage Account B, the deny assignment explicitly blocks anyaccess to that storage account. Azure enforces this to prevent conflicts and ensures that deny overrides any role-based permission,regardless of what roles or assignments are in place.
Option A is INCORRECT because AppUser's ability to access resources is not solely determined by their Reader role at thesubscription level. The Reader role allows read access to most resources, but role assignments and deny assignments at lowerscopes (resource groups or individual resources like storage accounts) override this global access. The deny assignment on StorageAccount B will prevent AppUser from accessing that particular storage account, regardless of the global Reader role.Option C is INCORRECT because of the aforementioned priority of denying assignments. Even though the custom role grants readaccess to Storage Account B, the deny assignment on that specific resource will take precedence. Deny assignments effectivelyblock any permissions, even if the user has roles that would typically allow access. Therefore, AppUser's access to Storage Account Bis indeed affected by the deny assignment, and the custom role cannot grant read access in this case.Option D is INCORRECT because the Contributor role does grant permissions to modify resources at the Resource Group A level, butit does not inherently provide full access. The Contributor role allows for creating and managing resources, but it does not grant theability to read resources (since Reader would be needed for that). Furthermore, Contributor role access applies at the Resource GroupA level and does not extend to individual resources like Storage Account B, especially considering the deny assignment at the storageaccount level. Thus, AppUser will have management capabilities within Resource Group A but will not have access to the specificresources (like Storage Account B) if there is a deny assignment.
10/7/25, 19:41LMS | Whizlabs
Page 16 of 16https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/70303/report/8446202
References: 
Ask our ExpertsDid you like this Question?Finish Review
CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdWhat is Azure role-based access control (Azure RBAC)?Azure deny assignments
Hands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/5/25, 15:24LMS | Whizlabs
Page 1 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Correct
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationMonitor and maintain Azure resources - Practice ModeCompleted on Sat, 04 Oct 20251stAttempt9/14Marks Obtained64.29%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Monitor and maintain Azureresources149500TotalAll Domains149500Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Monitor and maintain Azure resourcesYou configure an alert rule at the subscription scope that triggers on all administrative operations and uses an action group to sendemail notifications to admin@contoso.com. You also configure an alert processing rule that suppresses all notifications for the entiresubscription from May 24, 2025, to May 27, 2025. If a new resource group is created in this subscription on May 25, 2025, will thenotification email be sent? (Select Yes/No)Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Monitor and maintain Azure resources/ReportBack to the Courseh
Download Report
A. YesB. Noright
boDashboardMy CoursesHands-on LabsSandboxSupport

10/5/25, 15:24LMS | Whizlabs
Page 2 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
CorrectExplanation:Correct Answer: BOption B: No is correct because the alert processing rule is actively in effect during the specified date range (May 24-27, 2025). Eventhough the underlying alert rule for administrative operations is triggered by the creation of a resource group, the alert processingrule's primary function is to suppress notifications. Therefore, the associated action group will not execute its email sending actionduring this window.Option A: Yes is incorrect because the alert processing rule takes precedence over the alert rule's action within its defined scope andtime period. The notification will be suppressed, preventing the email from being sent.
References: 
Ask our ExpertsDid you like this Question?Question 2Domain: Monitor and maintain Azure resourceshttps://learn.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-processing-rules?tabs=portal https://learn.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-processing-rules?tabs=portal#what-should-this-rule-do
10/5/25, 15:24LMS | Whizlabs
Page 3 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
You have the same Azure Monitor configuration as in the previous question, including an alert rule for all administrative operationsand an alert processing rule that suppresses notifications from May 24, 2025, to May 27, 2025. You add a tag to an existing resourcegroup on May 29, 2025. Will you receive an email notification for this action? (Select Yes/No)
Explanation:Correct Answer: AOption A: Yes is correct because the administrative action (adding a tag) is performed on May 29, 2025. This date falls outside theactive period of the alert processing rule's suppression window (May 24-27, 2025). Therefore, the suppression rule no longer applies,and the alert rule for administrative operations will trigger its action group, successfully sending the email notification as expected.Option B: No is incorrect because the alert processing rule's suppression period has ended. The alert will be processed and thenotification sent.
References: 
Ask our ExpertsA. YesrightB. No
https://learn.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-processing-rules?tabs=portal https://learn.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-processing-rules?tabs=portal#what-should-this-rule-do
10/5/25, 15:24LMS | Whizlabs
Page 4 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
CorrectDid you like this Question?Question 3Domain: Monitor and maintain Azure resourcesYour company's IT department needs to continuously monitor the network connectivity, latency, and availability between virtualmachines belonging to different departments, which are located on separate subnets within an Azure Virtual Network. Which AzureNetwork Watcher feature should you recommend for this requirement?
Explanation:Correct Answer: AOption A: Connection Monitor is correct because it is specifically designed for actively and continuously monitoring connectivitybetween endpoints, such as virtual machines, across Azure regions, subscriptions, or even on-premises. It provides rich data onnetwork availability, latency, and packet loss, which directly addresses the need for continuous monitoring between VMs in differentsubnets.A. Connection MonitorrightB. Network Security Group Flow LogsC. Network TopologyD. Traffic Analytics
10/5/25, 15:24LMS | Whizlabs
Page 5 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Incorrect
Option B: Network Security Group Flow Logs are incorrect because - as they capture information about IP traffic flowing through anNSG (allowed or denied). While useful for security auditing and traffic analysis, they do not actively monitor or report on real-timeconnectivity status or performance between endpoints.Option C: Network Topology is incorrect because this feature provides a graphical representation of your network resources andtheir relationships. It is a visualization tool for understanding network architecture but does not offer active, real-time monitoring ofconnectivity status or performance metrics.Option D: Traffic Analytics is incorrect because it processes Network Watcher flow logs to provide insights into network trafficpatterns. It's useful for identifying hotspots, security threats, and optimizing network performance at a macro level, but it does notoffer the granular, active connectivity monitoring between specific VMs that Connection Monitor provides.Reference: Ask our ExpertsDid you like this Question?Question 4Domain: Monitor and maintain Azure resourcesYou are tasked with configuring Azure Network Watcher's Connection Monitor for a new set of Azure Virtual Machines to assess theirnetwork performance and connectivity. What is the correct sequence of steps to configure Connection Monitor for a newAzure Network Watcher – Connection Monitor
10/5/25, 15:24LMS | Whizlabs
Page 6 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
deployment?
Explanation:Correct Answers: E, B, D, A and CThe correct sequence for configuring Connection Monitor ensures that the foundational services are in place before defining specificmonitoring tasks.1. Enable Network Watcher in the relevant Azure region.2. Create a Connection Monitor resource.3. Define the monitoring settings (e.g., test groups, protocols, frequency).4. Configure the source and destination endpoints.5. Review the monitoring results and performance metrics.Step E: Enable Network Watcher in the relevant Azure region. This is the foundational first step. Network Watcher is a regional service,and it must be enabled in the Azure region(s) where your monitored resources reside before any of its features, including ConnectionMonitor, can be used.Step B: Create a Connection Monitor resource. Once Network Watcher is enabled in the region, you create an instance of theConnection Monitor resource itself, which will house your monitoring configurations.Step D: Define the monitoring settings (e.g., test groups, protocols, frequency). Within the Connection Monitor resource, you definehow the monitoring will be performed. This includes specifying test groups, choosing protocols (TCP, ICMP), setting testing frequency,and configuring thresholds.Step A: Configure the source and destination endpoints. Next, you identify the specific virtual machines or endpoints that will act asthe sources (where the tests originate) and destinations (where the tests are directed).Step C: Review the monitoring results and performance metrics. Once the Connection Monitor is fully set up and has beguncollecting data, you can access its dashboard to review real-time and historical data on connectivity status, latency, and packet loss.Your Answer1.E. Enable Network Watcher in the relevantAzure region2.B. Create a Connection Monitor resource3.A. Configure the source and destinationendpoints4.D. Define the monitoring settings (e.g., testgroups, protocols, frequency)5.C. Review the monitoring results andperformance metricsCorrect Answer1.E. Enable Network Watcher in the relevantAzure region2.B. Create a Connection Monitor resource3.D. Define the monitoring settings (e.g., testgroups, protocols, frequency)4.A. Configure the source and destinationendpoints5.C. Review the monitoring results andperformance metrics
10/5/25, 15:24LMS | Whizlabs
Page 7 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Correct
Reference: Ask our ExpertsDid you like this Question?Question 5Domain: Monitor and maintain Azure resourcesA company needs to gain comprehensive visibility into the operational health and performance bottlenecks of its Azure VirtualMachines and Virtual Machine Scale Sets. You are tasked with recommending a solution that provides detailed insights into resourceutilization, active processes, and network dependencies. What is the primary purpose of Azure VM Insights?https://learn.microsoft.com/en-us/azure/network-watcher/connection-monitor-create-using-portal
A. To automate Azure virtual machine provisioning and lifecycle managementB. To monitor and analyze the performance, health, and dependencies of Azure VMsrightC. To configure and enforce security policies and compliance for Azure VMsD. To create, manage, and optimize virtual networks for Azure VMs
10/5/25, 15:24LMS | Whizlabs
Page 8 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Explanation:Correct Answer: BOption B: To monitor and analyze the performance, health, and dependencies of Azure VMs is correct because Azure VM Insights is afeature of Azure Monitor specifically designed to provide a comprehensive, unified solution for monitoring the performance, health,and application dependencies of Azure virtual machines and Virtual Machine Scale Sets. It collects metrics and logs, visualizesperformance trends (CPU, memory, disk, network), and maps active processes and network connections to help identify anddiagnose issues.
Option A: To automate Azure virtual machine provisioning and lifecycle management is incorrect because automation tasks areprimarily handled by services like Azure Automation, Azure Resource Manager templates, or Azure DevOps, not Azure VM Insights. VMInsights is a monitoring tool.Option C: To configure and enforce security policies and compliance for Azure VMs is incorrect because security policies andcompliance are managed by services such as Microsoft Defender for Cloud and Azure Policy. VM Insights provides operationalinsights, not security posture management.Option D: To create, manage, and optimize virtual networks for Azure VMs is incorrect because virtual network management ishandled by the Azure Virtual Network service, Azure Load Balancer, and Network Watcher. VM Insights reports on networkdependencies but does not manage the underlying network infrastructure.Reference:Azure VM Insights Overview
10/5/25, 15:24LMS | Whizlabs
Page 9 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
CorrectAsk our ExpertsDid you like this Question?Question 6Domain: Monitor and maintain Azure resourcesYour team needs a centralized tool within Azure Monitor to gain a consolidated view of the performance, capacity utilization, andoverall availability status across all your Azure Storage accounts. This tool should offer proactive insights and facilitate quickidentification of issues. Which of the following Azure Monitor features should you recommend?
Explanation:Correct Answer: COption C: Azure Monitor Storage Insights is correct because it is a feature within Azure Monitor specifically tailored to provide aunified and centralized view of performance, capacity, and availability for all your Azure Storage accounts. It aggregates key metrics(e.g., transactions, latency, capacity usage) and presents them in pre-built dashboards, enabling quick identification of issues andproactive monitoring.A. Azure Log AnalyticsB. Azure Activity LogC. Azure Monitor Storage InsightsrightD. Microsoft Defender for Cloud
10/5/25, 15:24LMS | Whizlabs
Page 10 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Correct
Option A: Azure Log Analytics is incorrect because while Azure Log Analytics is a powerful service for collecting and querying varioustypes of log data (including some storage logs), it is a general-purpose logging solution. It does not natively provide the dedicated,unified dashboard for storage performance and capacity that Storage Insights offers without significant custom configuration.Option B: Azure Activity Log is incorrect because the Azure Activity Log records resource-level control-plane operations (e.g., create,update, delete resources, role assignments). It is an audit log for "who did what, when," not a source for performance, capacity, oravailability metrics of a running service like Azure Storage.Option D: Microsoft Defender for Cloud is incorrect because Microsoft Defender for Cloud is focused on security posturemanagement, vulnerability assessments, and threat protection across your Azure environment, including Storage accounts. While itprovides security recommendations for storage, it is not designed to monitor operational metrics like performance, capacity, oravailability.Reference:Ask our ExpertsDid you like this Question?Question 7Domain: Monitor and maintain Azure resourcesAn IT operations team needs a tool within Azure Monitor that allows them to interactively explore and visualize numerical metric data Azure Monitor Storage insights Overview
10/5/25, 15:24LMS | Whizlabs
Page 11 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
from various Azure resources. They require the ability to create custom charts, apply filters, and analyze performance trends overspecific time ranges without writing complex queries. Which Azure Monitor tool should you suggest for this purpose?
Explanation:Correct Answer: BOption B: Metrics Explorer is correct because it is the dedicated tool within Azure Monitor for interactively analyzing and chartingmetric data. It provides a graphical interface to select metrics, apply aggregations, filters, and splits, and visualize the data in variouschart types. This allows operations teams to easily monitor resource performance and diagnose issues by interacting directly with themetric data.
Option A: Log Analytics is incorrect because Log Analytics is primarily used for collecting, storing, and querying log data, using theKusto Query Language (KQL). While some metrics can be ingested as logs, Metrics Explorer is the purpose-built tool for direct,interactive analysis of numerical metric data.Option C: Application Insights is incorrect because Application Insights is an Application Performance Management (APM) servicethat specializes in monitoring live web applications. While it collects metrics, its focus is on application-specific performance,availability, and usage, rather than a general-purpose interactive metric exploration tool for all Azure resources.A. Log AnalyticsB. Metrics ExplorerrightC. Application InsightsD. Azure Monitor Workbooks
10/5/25, 15:24LMS | Whizlabs
Page 12 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
CorrectOption D: Azure Monitor Workbooks is incorrect because Workbooks are flexible canvases for creating interactive reports anddashboards from various data sources (logs, metrics, alerts). While they can display metric charts, they are more about creatingcurated views rather than being the primary tool for interactive exploration and ad-hoc analysis of raw metric data.Reference:Ask our ExpertsDid you like this Question?Question 8Domain: Monitor and maintain Azure resourcesAn Azure administrator receives an "Upcoming Purge" alert from Azure Backup for a SQL Server instance running on an Azure VirtualMachine. What does this alert indicate, and what is the appropriate immediate action the administrator should consider?
Explanation:Correct Answer: AOption A: The alert indicates that backup data is nearing permanent deletion due to retention policy, and the administrator shouldreview and potentially extend the retention policy is correct because an "Upcoming Purge" alert from Azure Backup is a criticalnotification. It explicitly warns that one or more recovery points (backup data) for the specified protected item (the SQL Server VM inthis case) are approaching the end of their defined retention period and will soon be permanently deleted. To prevent unintendeddata loss, the administrator's immediate and appropriate action is to review the existing backup retention policy and extend it if thedata needs to be kept for a longer duration.Get started with Azure Monitor Metrics Explorer
A. The alert indicates that backup data is nearing permanent deletion due to retention policy, and the administrator shouldreview and potentially extend the retention policyrightB. The alert signifies that the SQL Server VM is running low on disk space, and the administrator should allocate more storage tothe VMC. The alert warns of an upcoming planned Azure maintenance event for the SQL Server VM, and the administrator shouldschedule application downtimeD. The alert indicates a recent backup job failure for the SQL Server, and the administrator should investigate the cause of thefailure
10/5/25, 15:24LMS | Whizlabs
Page 13 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Incorrect
Option B: The alert signifies that the SQL Server VM is running low on disk space, and the administrator should allocate more storageto the VM is incorrect because this alert is generated by Azure Backup in relation to its retention policies for backup data, not inresponse to storage space issues on the actual virtual machine's operational disks. Disk space alerts would typically come from VMInsights or other monitoring tools.Option C: The alert warns of an upcoming planned Azure maintenance event for the SQL Server VM, and the administrator shouldschedule application downtime is incorrect because this alert has no relation to Azure platform maintenance events. Azure Backupalerts are specific to backup operations and data lifecycle.Option D: The alert indicates a recent backup job failure for the SQL Server, and the administrator should investigate the cause ofthe failure is incorrect because a backup job failure would trigger a distinct alert type (e.g., "Backup Job Failed"). The "Upcoming Purge"alert refers to the lifecycle management of existing backup data, not the success or failure of a new backup operation.Reference:Ask our ExpertsDid you like this Question?Question 9Domain: Monitor and maintain Azure resourcesYou are tasked with configuring Azure Backup for several existing Azure Virtual Machines within your subscription. You want to use theAzure Backup Alerts
10/5/25, 15:24LMS | Whizlabs
Page 14 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Azure Backup Center for a streamlined workflow. What is the correct sequence of steps to configure these VMs for backup?
Explanation:Correct Answers: C, B, A, D, E and FThe correct sequence ensures that the necessary foundational resources (vault) and configurations (policy) are in place beforeenabling backup for the VMs.Your Answer1.C. Search and open the Backup Center in theAzure portal2.A. Click on +Backup to initiate the backupconfiguration3.D. Create or select an existing backup policy4.B. Create or select an existing RecoveryServices vault5.E. Add the virtual machines to be protected6.F. Click on Enable backup to finalizeCorrect Answer1.C. Search and open the Backup Center in theAzure portal2.B. Create or select an existing RecoveryServices vault3.A. Click on +Backup to initiate the backupconfiguration4.D. Create or select an existing backup policy5.E. Add the virtual machines to be protected6.F. Click on Enable backup to finalize
C. Search and open the Backup Center in the Azure portal.B. Create or select an existing Recovery Services vault.A. Click on +Backup to initiate the backup configuration.D. Create or select an existing backup policy.E. Add the virtual machines to be protected.F. Click on Enable backup to finalize.
10/5/25, 15:24LMS | Whizlabs
Page 15 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Step C: Search and open the Backup Center in the Azure portal. For a streamlined experience across all backup activities, startingfrom the Azure Backup Center is the recommended approach as it provides a centralized management interface.Step B: Create or select an existing Recovery Services vault. A Recovery Services vault is the fundamental storage and managemententity required by Azure Backup. It must exist before you can configure any backup operations.Step A: Click on +Backup to initiate the backup configuration. Within the Backup Center or a specific Recovery Services vault, youstart the process of backing up new workloads by selecting the +Backup option.Step D: Create or select an existing backup policy. A backup policy defines crucial settings like backup schedule (how often) andretention range (how long backups are kept). This must be defined before you can associate VMs with a backup configuration.Step E: Add the virtual machines to be protected. After a policy is defined, you then select the specific Azure Virtual Machines that youwish to associate with this backup policy.Step F: Click on Enable backup to finalize. This final action confirms your selections, links the chosen VMs to the policy within theRecovery Services vault, and initiates the first backup job according to the policy's schedule.References:
Ask our Expertshttps://learn.microsoft.com/en-us/azure/backup/backup-center-overview https://learn.microsoft.com/en-us/azure/backup/backup-azure-vms-introduction https://learn.microsoft.com/en-us/azure/backup/quick-backup-vm-portal 
10/5/25, 15:24LMS | Whizlabs
Page 16 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
IncorrectDid you like this Question?Question 10Domain: Monitor and maintain Azure resourcesYour company uses various Azure services and needs to implement a robust backup strategy. You are responsible for choosing theappropriate vault type for different workloads.For each of the following Azure services, identify whether you would choose a Recovery Services vault or a Backup vault for its backupsolution:
Explanation:Correct Answer: ACorrect Assignments:1. Azure Database for PostgreSQL servers: Backup vault2. SQL Server running in an Azure VM: Recovery Services vault3. Azure Files shares: Recovery Services vaultAzure has two primary vault types for backup: Recovery Services vaults and Backup vaults, each supporting different workloads,though some overlap exists. Backup vaults are generally newer and designed for specific modern PaaS workloads.Azure Database for PostgreSQL serversSQL Server running in an Azure VMAzure Files sharesA. Backup vault, Recovery Services vault, Recovery Services vaultrightB. High Availability & Disaster Recovery (HADR)C. Backup vault onlywrongD. Recovery Services vault only
Azure Database for PostgreSQL servers → Backup vault: Backup vault is the correct choice because the Backup vault is therecommended and supported vault type for backing up Azure Database for PostgreSQL servers (Flexible and Single Server). Itprovides enhanced capabilities for these PaaS databases.SQL Server in Azure VM → Recovery Services vault: The Recovery Services vault is the correct choice because it is the establishedand supported vault type for protecting SQL Server instances running inside Azure Virtual Machines (IaaS SQL).Azure Files shares → Recovery Services vault: The Recovery Services vault is the correct choice because it is the supported vaulttype for backing up Azure file shares (both standard and premium).
10/5/25, 15:24LMS | Whizlabs
Page 17 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Correct
Option B: High Availability & Disaster Recovery (HADR) is incorrect because HADR refers to a strategy or set of technologies (likeAlways On Availability Groups, failover clusters, or geo-replication) for ensuring continuous operation and data accessibility, not atype of backup vault. While backup is a component of a comprehensive HADR plan, HADR itself is not an Azure Backup vault type. Thisoption is a distractor that falls into a different category of Azure services.Option C: Backup vault only is incorrect because this option implies that all three specified services (Azure Database for PostgreSQLservers, SQL Server running in an Azure VM, and Azure Files shares) would use only a Backup vault. While Azure Database for PostgreSQLservers indeed uses a Backup vault, SQL Server running in an Azure VM and Azure Files shares both use a Recovery Services vault.Therefore, this option is incomplete and inaccurate for the entire list.Option D: Recovery Services vault only is incorrect because this option implies that all three specified services would use only aRecovery Services vault. While SQL Server running in an Azure VM and Azure Files shares do use a Recovery Services vault, AzureDatabase for PostgreSQL servers uses a Backup vault. Therefore, this option is also incomplete and inaccurate for the entire list.References: 
Ask our ExpertsDid you like this Question?Question 11https://learn.microsoft.com/en-us/azure/backup/backup-vault-overview https://learn.microsoft.com/en-us/azure/backup/quick-backup-azure-files-vault-tier-portal
10/5/25, 15:24LMS | Whizlabs
Page 18 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Domain: Monitor and maintain Azure resourcesAn international IT company is experiencing budget overruns on its Azure subscriptions and needs to set up proactive alerts withinAzure Cost Management to gain better visibility and control over spending. Which of the following alert types is NOT a native, built-inalert capability directly configurable within Azure Cost Management?
Explanation:Correct Answer: CAzure Cost Management provides several built-in alert types to help organizations manage and control their spending.Option C: Department spending quota alert is correct because "department spending quota alert" is not a native, built-in alert typedirectly available in Azure Cost Management. While you can implement department-level cost tracking using management groups,resource groups, and tags, and then apply budgets to those scopes, there isn't a specific, predefined alert type called "departmentspending quota." You would typically use a standard budget alert applied to the scope representing the department.
A. Budget alertB. Credit alertC. Department spending quota alertrightD. Forecast alert
10/5/25, 15:24LMS | Whizlabs
Page 19 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Incorrect
Option A: Budget alert is incorrect because budget alerts are a core, built-in feature of Azure Cost Management. They allow you to setspending thresholds (actual or forecasted) for a subscription, resource group, or management group and receive notifications whenthese thresholds are met or exceeded.Option B: Credit alert is incorrect because credit alerts are automatically generated by Azure to notify you when your AzurePrepayment (formerly monetary commitment) credit balance is being consumed or is nearing depletion. This is a crucial built-in alertfor customers with enterprise agreements.Option D: Forecast alert is incorrect because forecast alerts are a native feature within Azure Cost Management. These alerts usemachine learning to analyze historical spending patterns and predict future costs, notifying you if your forecasted spending isprojected to exceed a specified budget or threshold.References:
Ask our ExpertsDid you like this Question?Question 12Domain: Monitor and maintain Azure resourceshttps://learn.microsoft.com/en-us/azure/cost-management-billing/costs/cost-mgt-alerts-monitor-usage-spending https://learn.microsoft.com/en-us/azure/cost-management-billing/costs/overview-cost-management 
10/5/25, 15:24LMS | Whizlabs
Page 20 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
An international IT company has deployed 200 Windows and Linux virtual machines in Azure. They plan to roll out Azure VM Insights onall of them to centralize performance and health monitoring. Which three of the following are essential prerequisites for successfullyenabling Azure VM Insights on these virtual machines? (Select 3)
Explanation:Correct Answers: A, B and DAzure VM Insights relies on specific agents and services to collect and process performance and dependency data from your virtualmachines.Option A: A direct connection from the virtual machine to the Azure Instance Metadata Service (IMDS) endpoint (169.254.169.254) iscorrect because the Dependency Agent, which is crucial for VM Insights' mapping functionality, requires access to the Azure IMDSendpoint. This endpoint provides crucial metadata about the VM to the agent.Option B: An active Log Analytics workspace linked to the subscription is correct because Azure VM Insights uses a Log Analyticsworkspace as its backend data store. All performance metrics, process data, and dependency information collected by themonitoring agents are sent to this workspace for storage, analysis, and visualization. You must have a configured workspace beforeyou can onboard VMs.Option D: The Dependency Agent installed on the virtual machines is correct because for the "Maps" feature of VM Insights (whichvisualizes processes and network dependencies) to function, the Dependency Agent must be installed on the virtual machines. Thisagent collects data about running processes and active network connections.Your AnswerB. An active Log Analytics workspace linked to thesubscriptionA. A direct connection from the virtual machine tothe Azure Instance Metadata Service (IMDS)endpoint (169.254.169.254)C. Global Administrator in Microsoft Entra ID for theuser performing the setupCorrect AnswerA. A direct connection from the virtual machine tothe Azure Instance Metadata Service (IMDS)endpoint (169.254.169.254)B. An active Log Analytics workspace linked to thesubscriptionD. The Dependency Agent installed on the virtualmachines
10/5/25, 15:24LMS | Whizlabs
Page 21 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Incorrect
Option C: Global Administrator in Microsoft Entra ID rights for the user performing the setup is incorrect because GlobalAdministrator rights are very high-level administrative permissions in Microsoft Entra and are typically not required to configure AzureVM Insights. The necessary permissions are usually at the subscription or resource group level (e.g., Log Analytics Contributor,Monitoring Contributor roles).Option E: A separate, dedicated network subnet for VM Insights agents is incorrect because VM Insights agents (Log Analytics agentand Dependency agent) communicate over the existing virtual machine's network interface. They do not require a separate ordedicated network subnet for their operation.References:
Ask our ExpertsDid you like this Question?Question 13Domain: Monitor and maintain Azure resourcesA company has 100 on-premises virtual machines protected by Azure Site Recovery for their business continuity plan. Due to a majornetwork outage at the on-premises head office, all connectivity to the local data center is lost, requiring a disaster recovery failover.What is the correct sequence of steps an administrator would take to perform a planned failover of these systems to the Azure cloud?https://learn.microsoft.com/en-us/azure/virtual-machines/instance-metadata-service?tabs=windowshttps://learn.microsoft.com/en-us/azure/azure-monitor/vm/vminsights-enable-overview
10/5/25, 15:24LMS | Whizlabs
Page 22 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Explanation:Correct Answers: C, A, D and BPerforming a failover in Azure Site Recovery involves a specific sequence of actions to ensure data integrity and successful migrationof workload operations to Azure.
Step C: Navigate to the Recovery Services Vault and select Replicated items. This is the initial step to access the managementYour Answer1.D. Choose the appropriate recovery point &ensure the on-premises source server is shutdown2.C. Navigate to the Recovery Services Vaultand select Replicated items3.A. Select the Virtual Machine to fail over andclick on Failover4.B. Commit the failover operationCorrect Answer1.C. Navigate to the Recovery Services Vault andselect Replicated items2.A. Select the Virtual Machine to fail over andclick on Failover3.D. Choose the appropriate recovery point &ensure the on-premises source server is shutdown4.B. Commit the failover operation
C. Navigate to the Recovery Services Vault and select Replicated items.A. Select the Virtual Machine to fail over and click on Failover.D. Choose the appropriate recovery point & ensure the on-premises source server is shut down.B. Commit the failover operation
10/5/25, 15:24LMS | Whizlabs
Page 23 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Correctinterface for your protected on-premises machines. All replicated items are managed within the Recovery Services vault.Step A: Select the VM(s) to fail over and click on Failover. Once you've located the replicated items, you select the specific virtualmachine(s) you wish to fail over to Azure and initiate the failover process.Step D: Choose the appropriate recovery point and ensure the on-premises source server is shut down. During the failover wizard,you will be prompted to select a specific recovery point (e.g., latest, application-consistent) to restore the VM from. Critically, toprevent data consistency issues (split-brain scenarios), it is essential to ensure that the on-premises source server corresponding tothe VM being failed over is shut down before or during this step.Step B: Commit the failover operation. After the virtual machine has successfully failed over to Azure and you have thoroughlyverified that it is running and accessible as expected (e.g., applications are working), you must perform a Commit action. Committingthe failover makes the recovery point permanent and deletes all older recovery points. This is the final step in solidifying the failover.References:
Ask our ExpertsDid you like this Question?Question 14Domain: Monitor and maintain Azure resourcesA company runs a public-facing website on three Azure Virtual Machines (VMs) located behind an Azure Load Balancer. The websiteexperiences significant traffic spikes over weekends, leading to performance degradation. The company's primary goals are toreduce cloud hosting costs during off-peak hours and maintain high availability and performance during peak traffic times withoutmanual intervention. Azure Advisor has provided recommendations related to cost optimization and operational excellence. Whichtwo of the following solutions are the most cost-effective and scalable approaches to address this usage pattern? (Select 2)
Explanation:Correct Answers: C and DThe core requirements are cost-effectiveness (reducing costs during off-peak) and scalability (handling peak traffic without manualintervention). Solutions that offer automatic scaling are best suited for this.https://learn.microsoft.com/en-us/azure/site-recovery/azure-to-azure-tutorial-failover-failback https://learn.microsoft.com/en-us/azure/site-recovery/site-recovery-test-failover-to-azure 
A. Manually change the VM series to a more powerful one during peak timesB. Manually resize the existing VMs to a larger size to accommodate peak trafficC. Deploy the website application to an Azure Virtual Machine Scale SetrightD. Migrate the website application to Azure App Serviceright
10/5/25, 15:24LMS | Whizlabs
Page 24 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Option C: Deploy the website application to an Azure Virtual Machine Scale Set is correct because Azure Virtual Machine Scale Setsare designed for deploying and managing a group of identical, load-balanced VMs. They inherently support autoscaling, meaningnew VM instances can be automatically added when traffic increases (scaling out) and removed when traffic decreases (scaling in).This directly addresses both cost-effectiveness (only pay for what's needed) and automatic scalability for fluctuating demand.Option D: Migrate the website application to Azure App Service is correct because Azure App Service is a Platform-as-a-Service(PaaS) offering that provides a fully managed environment for hosting web applications. App Service has built-in autoscalingcapabilities that can automatically adjust the number of instances based on traffic or predefined schedules. This is highly cost-effective as you pay only for the compute resources consumed, and it significantly reduces operational overhead, furthercontributing to cost savings and increased scalability.
Option A: Manually change the VM series to a more powerful one during peak times is incorrect because this is a manual operation,which goes against the "without manual intervention" requirement. It also involves downtime to change VM sizes and would not becost-effective if not scaled back down, leading to over-provisioning during off-peak hours.Option B: Manually resize the existing VMs to a larger size to accommodate peak traffic is incorrect because this is also a manualoperation and suffers from the same drawbacks as changing VM series. Resizing to a larger size permanently would lead to increasedcosts during off-peak hours, and manually resizing up and down introduces operational burden and potential downtime. It does notprovide the dynamic, automatic scalability needed.References:
Ask our Expertshttps://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-deploy-app https://learn.microsoft.com/en-us/dotnet/azure/migration/app-service
10/5/25, 15:24LMS | Whizlabs
Page 25 of 25https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67125/report/8445720
Did you like this Question?Finish Review
CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdHands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/5/25, 15:23LMS | Whizlabs
Page 1 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
Incorrect
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationImplement and manage virtual networking - Practice ModeCompleted on Sat, 04 Oct 20251stAttempt8/13Marks Obtained61.54%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Implement and manage virtualnetworking138500TotalAll Domains138500Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Implement and manage virtual networkingYou have an Azure subscription that contains a storage account named TestStorage1 and the following virtual machines: 
The subnets have the following service endpoints: Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Implement and manage virtual networking/ReportBack to the Courseh
Download Report
VirtualMachine1 has a public IP address of 13.68.158.24 and is connected to VirtualNetwork1/Subnet1VirtualMachine2 has a public IP address of 52.255.145.76 and is connected to VirtualNetwork1/Subnet1VirtualMachine3 has a public IP address of 13.68.158.50 and is connected to VirtualNetwork1/Subnet2
boDashboardMy CoursesHands-on LabsSandboxSupport

10/5/25, 15:23LMS | Whizlabs
Page 2 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
TestStorage1 has a firewall configured to allow access from the 13.68.158.0/24 IP address range only. You need to identify which virtualmachines can access TestStorage1. What should you identify? 
Explanation:Correct Answer: D
Reference: 
Ask our ExpertsDid you like this Question?Subnet1 has a Microsoft.Storage service endpointSubnet2 does not have any service endpointA. VirtualMachine1 onlywrongB. VirtualMachine3 onlyC. VirtualMachine1 and VirtualMachine2 onlyD. VirtualMachine1 and VirtualMachine3 onlyright
Option D is CORRECT because VirtualMachine1 meets both the criteria; first, it has a public IP address within the allowed range(13.68.158.0/24) of the firewall and second, it is connected to a subnet (Subnet1) with a Microsoft.Storage service endpoint, allowingit to access TestStorage1. Also, VirtualMachine3 has a public IP address within the allowed range (13.68.158.0/24) of the firewall,although it is not connected to a subnet with Microsoft.Storage service endpoint, TestStorage1 would still allow access from thespecified IP address range, enabling VirtualMachine3 to access TestStorage1 directly.Option A is INCORRECT because although VirtualMachine1 satisfies both the conditions to access TestStorage1, it is not the onlyvirtual machine to access the storage account. VirtualMachine3 can also access TestStorage1.Option B is INCORRECT because although VirtualMachine3 satisfies the condition of the IP address within the allowed range of thefirewall to access TestStorage1, it is not the only virtual machine to access the storage account. VirtualMachine1 can also accessTestStorage1.Option C is INCORRECT because VirtualMachine2 cannot access TestStorage1. Although it is connected to a subnet with aMicrosoft.Storage service endpoint, it has a public IP address outside the allowed range (52.255.145.76) of the firewall. Thus, in thiscase, the firewall would restrict access to TestStorage1 for VirtualMachine2.  https://learn.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal#grant-access-from-a-virtual-networkhttps://learn.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal#grant-access-from-an-internet-ip-range
10/5/25, 15:23LMS | Whizlabs
Page 3 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
CorrectView Case StudyQuestion 2Domain: Implement and manage virtual networkingYou need to suggest a solution to ensure that the storage account (TestStorage) can only be accessed from VNet2 and VNet3.  Thesolution must meet the technical requirements. Which service should you configure?
Explanation:Correct Answer: C
Architectural Diagram/Screenshots: A. Private LinkB. Azure FirewallC. Service EndpointsrightD. Network Security Groups
Option C is CORRECT because this solution allows you to restrict access to the Azure Storage account to specific VNets (VNet2 andVNet3), meeting the technical requirements effectively and efficiently. Service Endpoints use the Azure backbone network tooptimize a direct and secure connection to Azure services. By configuring Service Endpoints, you can ensure that the AzureStorage Account (TestStorage) is only accessible from specified VNets.Option A is INCORRECT because, although it provides a similar level of security, it is not the simplest solution for the scenariodescribed. While Private Link could be used to restrict access to the storage account to specific VNets, it is generally morecomplex to set up and manage compared to Service Endpoints. Additionally, Private Link is designed for scenarios where youneed to secure access from a specific set of private IP addresses, not necessarily from multiple VNets without significantconfiguration.Option B is INCORRECT because Azure Firewall is primarily used for network security and traffic control rather than restrictingaccess to Azure services from specific VNets. While it can help restrict access based on network rules, it is not specificallydesigned to control access to Azure PaaS services from VNets in the same way Service Endpoints are.Option D is INCORRECT because NSGs are used for traffic filtering at the network level but do not directly control access to AzurePaaS services. NSGs can control traffic to and from VM subnets and network interfaces but do not provide the capability to secureAzure PaaS services like Azure Storage in the same manner as Service Endpoints.
10/5/25, 15:23LMS | Whizlabs
Page 4 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
CorrectView Case Study
[Source: Microsoft Documentation]Reference:Ask our ExpertsDid you like this Question?Question 3Domain: Implement and manage virtual networkingYou want to configure a private endpoint for the SQLDB resource in VNet1.What is the first recommended step you need to follow? https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview
A. Create a new virtual network for the private endpointB. Configure DNS settings for the SQLDBC. Modify the network security group (NSG) settings for VNet1D. Create a private endpoint resource in the Azure portalright
10/5/25, 15:23LMS | Whizlabs
Page 5 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
Explanation:Correct Answer: D
Reference:
Ask our ExpertsDid you like this Question?Option D is CORRECT because the initial step in setting up a private endpoint is to create the private endpoint resource itself. Thisinvolves specifying the target resource (SQLDB in this case), the virtual network (VNet1), and the subnet where the private endpointwill be placed. This step is fundamental because it establishes the private link to the SQLDB, making it accessible via a private IPwithin VNet1.Steps to Create a Private Endpoint:Navigate to the Azure portal and select "Private endpoints."Select "+ Create" to start the creation process.In the Basics tab, fill in the necessary details:Resource GroupName of the private endpointRegionSelect the target resource (SQLDB in VNet1) and the specific sub-resource (e.g., SQL server).Choose the virtual network (VNet1) and subnet where the private endpoint will be deployed.Configure DNS integration settings if required.Review and create the private endpoint.Option A is INCORRECT because creating a new virtual network is not required unless there are specific isolation or organizationalrequirements. In this scenario, the private endpoint is intended for VNet1, so a new virtual network is unnecessary.Option B is INCORRECT because configuring DNS settings is necessary to ensure proper name resolution of the private endpoint.However, this step comes after the creation of the private endpoint. Once the private endpoint is created, the appropriate DNSconfigurations can be applied to resolve the SQLDB’s private endpoint correctly within the virtual network.Option C is INCORRECT because this is a subsequent step after the private endpoint is created. NSG settings might need to beadjusted to ensure that traffic to the private endpoint is allowed. This involves configuring rules to permit traffic to and from theprivate IP address assigned to the private endpoint. https://learn.microsoft.com/en-us/azure/private-link/create-private-endpoint-portal?tabs=dynamic-ip#create-a-private-endpoint
10/5/25, 15:23LMS | Whizlabs
Page 6 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
IncorrectView Case StudyQuestion 4Domain: Implement and manage virtual networkingThe IT department assigns WebAppTest with a custom user-defined domain, “www.fabriakamwebapp.net” to ensure ease ofaccessibility for non-tech users in the department.You need to ensure that WebAppTest can access the SQLDB over the private endpoint.The solution must meet the technical requirements.What DNS configuration is required to achieve the goal? 
Explanation:Correct Answer: A
Reference:A. Create an Azure DNS private zone and link it to VNet1 and VNet3rightB. Update the SQLDB’s DNS to point to the private IP addresswrongC. Configure a public DNS zone and link it to both virtual networksD. Enable public DNS resolution in VNet3
Option A is CORRECT because Azure Private DNS provides DNS resolution for private endpoints within a virtual network, ensuringthat DNS queries are resolved to private IP addresses rather than public ones. By linking the DNS private zone to both VNet1 (wherethe SQLDB is located) and VNet3 (where the WebAppTest is located), both VNets can resolve the DNS name of the SQLDB to itsprivate IP address. This setup meets the security requirement of keeping the SQLDB accessible only within the virtual networks,and it allows WebAppTest to access SQLDB over the private endpoint securely.Option B is INCORRECT because Manually updating DNS entries for SQLDB is not a standard approach and can lead tomaintenance and management issues. DNS records should be managed within a DNS zone, not by directly updating the serviceDNS settings to a private IP. This approach does not leverage Azure's DNS capabilities and fails to provide the necessary scalabilityand manageability for DNS resolution within Azure VNets.Option C is INCORRECT because linking a public DNS zone to the VNets would expose internal resources, potentially making themaccessible from the public internet, which violates the security requirements. This approach does not meet the need for private,secure access to SQLDB from WebAppTest in VNet3. Private endpoints require private DNS zones for proper resolution within AzureVNets.Option D is INCORRECT because public DNS resolution would expose SQLDB to the public internet, which contradicts the securityrequirements of keeping SQLDB accessible only within VNet1. Enabling public DNS resolution does not provide a secure method forWebAppTest to resolve SQLDB’s private endpoint. It fails to ensure that only internal resources can access SQLDB. The requirementis for private, internal DNS resolution, not public DNS. https://learn.microsoft.com/en-us/azure/private-link/private-endpoint-dnshttps://learn.microsoft.com/en-us/azure/dns/private-dns-overview
10/5/25, 15:23LMS | Whizlabs
Page 7 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
CorrectView Case StudyAsk our ExpertsDid you like this Question?Question 5Domain: Implement and manage virtual networkingYou need to ensure that the traffic between VNet1 and VNet2 flows through the Network Virtual Appliance (NVA) in VNet3. How can youachieve this?
Explanation:Correct Answer: C
Reference:A. Create a VPN gateway in each VNetB. Configure a peering connection between VNet1 and VNet2C. Set up user-defined routes in each VNet with the NVA as the next hoprightD. Enable service endpoints for all VNets
Option C is CORRECT because it effectively addresses the requirement by explicitly defining routing rules that direct trafficthrough the NVA in VNet3, ensuring inspection and control of inter-VNet traffic. User-defined routes allow customizing the routingbehavior within Azure virtual networks. By defining routes with the NVA's private IP address as the next hop, you specify that trafficdestined for other VNets should first pass through the NVA for inspection and routing. This option aligns with the requirement ofensuring traffic between VNet1 and VNet2 flows through the NVA in VNet3.Option A is INCORRECT because while VPN gateways are useful for establishing secure connections, they do not directly addressthe requirement of routing traffic through the NVA in VNet3. VPN gateways are used to establish secure connections betweenAzure virtual networks and on-premises networks or other Azure virtual networks. However, deploying VPN gateways in each VNetdoes not inherently route traffic between VNet1 and VNet2 through the NVA in VNet3. It establishes secure connections but doesn'tenforce traffic routing through a specific path.Option B is INCORRECT because while peering connections facilitate direct communication between VNets, they do not ensuretraffic routing through a specific network appliance like the NVA in VNet3.Option D is INCORRECT because enabling service endpoints does not address the requirement of routing traffic through the NVAin VNet3. It focuses on providing secure access to Azure services within VNets but does not enforce specific traffic routing paths. https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview#user-definedhttps://learn.microsoft.com/en-us/azure/virtual-network/tutorial-create-route-table-portal
10/5/25, 15:23LMS | Whizlabs
Page 8 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
CorrectView Case StudyAsk our ExpertsDid you like this Question?Question 6Domain: Implement and manage virtual networkingWhich route configuration is necessary to ensure that the traffic between VNet1, VNet2, and VNet3 is inspected by the NVA in VNet3?
Explanation:Correct Answer: C
Reference:
Ask our ExpertsA. Route tables with a next-hop type of InternetB. Route tables with a next-hop type of Virtual NetworkC. Route tables with a next-hop type of Virtual AppliancerightD. Route tables with a next-hop type of None
Option C is CORRECT because this option allows you to specify a virtual appliance, such as the Network Virtual Appliance (NVA)located in VNet3, as the next hop for the traffic between VNets. By configuring the route tables with the NVA as the next hop, youensure that traffic between VNets is directed to the NVA for inspection and potential routing based on network policies. The NVAserves as a central point for inspecting traffic between VNets, allowing you to enforce network security policies, perform networkaddress translation (NAT), and route traffic based on defined rules. This option aligns perfectly with the requirement to ensurethat traffic between VNet1, VNet2, and VNet3 flows through the NVA in VNet3 for inspection. It enables you to optimize networksecurity and performance by centrally managing and controlling inter-VNet traffic.Option A is INCORRECT because this option would direct traffic to the Internet, not through the NVA in VNet3. It doesn't align withthe requirement to route traffic between VNets through the NVA.Option B is INCORRECT because this option would route traffic within the same virtual network, not between different VNets. Itdoesn't address the requirement to route traffic between VNets through the NVA.Option D is INCORRECT because this option would effectively drop the traffic instead of routing it through the NVA. It doesn't fulfillthe requirement to route traffic between VNets through the NVA. https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview#user-definedhttps://learn.microsoft.com/en-us/azure/virtual-network/tutorial-create-route-table-portal
10/5/25, 15:23LMS | Whizlabs
Page 9 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
IncorrectDid you like this Question?Question 7Domain: Implement and manage virtual networkingYour Azure subscription includes the following virtual networks: NameLocationNo. of VMs connectedVNET1WestUS5VNET2WestUS7VNET3EastUS10VNET4EastUS4All the virtual networks are fully peered using global virtual network peering.You want to set up Azure Bastion for all the virtual machines connected to these networks.What is the minimum number of Azure Bastion host(s) you need to deploy? 
Explanation:Correct Answer: BA. 1B. 2rightC. 3D. 4wrong
Option A is INCORRECT, While global virtual network peering allows for connectivity across regions, Azure Bastion must bedeployed in each region where you want to provide secure and seamless RDP/SSH access to your VMs. Since you have virtualnetworks in two different regions (West US and East US), one Azure Bastion host is not sufficient.Option B is CORRECT, Since all the virtual networks are fully peered using global virtual network peering, you only need to deployone Azure Bastion host per region. In this case, you have virtual networks in two regions: West US and East US. Therefore, you need
10/5/25, 15:23LMS | Whizlabs
Page 10 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
CorrectReference:
Ask our ExpertsDid you like this Question?Question 8Domain: Implement and manage virtual networkingYou are configuring Azure Bastion to provide secure RDP access to virtual machines in Azure. Which of the following IP addressallocations is required for the public IP address associated with Azure Bastion?
Explanation:Correct Answer: Ba minimum of two Azure Bastion hosts, one in each region.Option C is INCORRECT because there is no need for three Azure Bastion hosts in this scenario. Global virtual network peeringallows for seamless communication between virtual networks across regions, so only one Azure Bastion host is needed to provideremote access to all the virtual machines.Option D is INCORRECT because deploying four Azure Bastion hosts would be excessive and unnecessary in this scenario. Globalvirtual network peering ensures connectivity between all the virtual networks across regions, so only one Azure Bastion host isrequired to cover all the virtual machines. https://learn.microsoft.com/en-us/azure/bastion/vnet-peeringTutorial: Deploy Azure Bastion using specified settings: Azure portal | Microsoft Learn
A. DynamicB. StaticrightC. ReservedD. Floating
Option B is CORRECT because when configuring Azure Bastion to provide secure RDP access to virtual machines in Azure, thepublic IP address associated with Azure Bastion must be allocated statically. This ensures that the public IP address remainsconstant and does not change over time, providing a reliable endpoint for securely accessing virtual machines. Using a staticpublic IP address is essential for maintaining consistent connectivity to Azure Bastion, especially in scenarios where dynamic IPaddresses might change, causing disruptions in connectivity. Therefore, a static allocation is required to ensure uninterruptedaccess to Azure Bastion and the virtual machines it protects.Option A is INCORRECT because dynamic IP addresses can change over time, leading to connectivity issues and interruptionswhen accessing virtual machines via Azure Bastion. Therefore, more than a dynamic allocation is needed to ensure consistentand reliable access to Azure Bastion.
10/5/25, 15:23LMS | Whizlabs
Page 11 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
CorrectReference:Ask our ExpertsDid you like this Question?Question 9Domain: Implement and manage virtual networkingYou've deployed Azure virtual machines across the three Azure regions, each with its virtual network. These networks feature multiplesubnets interconnected in a full mesh topology, with each subnet equipped with a network security group (NSG) defining specificrules.A user encounters connectivity issues, particularly with port 33000, when attempting to connect from a virtual machine in one regionto another in a different region. Which of the following approaches can you employ to diagnose the problem? (Select Two)
Explanation:Correct Answers: A and COption C is INCORRECT because Azure Bastion requires a static allocation for its public IP address to ensure consistent andreliable connectivity. However, reserved is not a valid allocation type for Azure public IP addresses.Option D is INCORRECT because floating is not a standard IP address allocation type in the context of Azure public IP addresses. https://learn.microsoft.com/en-us/azure/bastion/configuration-settings#public-ip
A. IP flow verifyrightB. Azure Virtual Network ManagerC. Connection troubleshootrightD. Azure Monitor Network Insights
Option A is CORRECT because IP flow verify is a feature within Azure Network Watcher designed to assist in diagnosingconnectivity issues by assessing if a packet adheres to the configured security and administrative rules. It scrutinizes the rules ofall network security groups (NSGs) assigned to a virtual machine's network interface, encompassing those linked with subnets ornetwork interfaces. This evaluation extends to rules governing traffic on specified ports, such as port 33000 in this scenario.Through IP flow verify, one can ascertain whether traffic destined for port 33000 is permitted or denied by the NSG rules, therebyoffering insights into potential connectivity problems. IP flow verify assesses various parameters, including traffic direction,protocol, local and remote IPs, as well as local and remote ports, to validate security and administrative rules. It providesfeedback on whether access is granted or denied, alongside the identification of the security rule and its associated NSG,facilitating pinpointing and potential adjustment of any rules obstructing the traffic.Option C is CORRECT because connection troubleshoot is another feature of Azure Network Watcher specifically designed todiagnose and troubleshoot network connectivity issues. It performs comprehensive checks to detect issues related to network
10/5/25, 15:23LMS | Whizlabs
Page 12 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
IncorrectReferences:
Ask our ExpertsDid you like this Question?Question 10Domain: Implement and manage virtual networkingYou are working as an Azure Administrator for Contoso where your job role is to maintain and supervise all Azure resources deployedon Contoso’s infrastructure.During a routine monitoring session, while troubleshooting an inbound connectivity issue with a standard external load balancer (ELB)on Azure, you identify that external clients are unable to establish a connection to the backend virtual machines. You need toinvestigate further to resolve the issue.What recommended action should you take to address this issue? security groups, user-defined routes, and blocked ports, which are all relevant to diagnosing connectivity problems betweenvirtual machines in different regions. Connection troubleshoot can detect issues such as misconfigured or missing routes,network security group (NSG) rules blocking traffic (including traffic on port 33000), and other factors that may be causingconnectivity problems. It provides detailed results, including insights into the root cause of the connectivity problem andactionable steps for resolution, which can help in identifying and addressing any issues preventing communication betweenvirtual machines in different regions.Option B is INCORRECT because while Azure Virtual Network Manager is useful for managing and configuring virtual networks, itdoes not provide direct diagnostic capabilities for troubleshooting connectivity issues between virtual machines in differentregions, such as those related to port 33000. Azure Virtual Network Manager does not offer specific tools or features fordiagnosing connectivity issues or troubleshooting network problems like IP flow verify or Connection troubleshoot.Option D is INCORRECT because while Azure Monitor Network Insights offers valuable insights into network performance andhealth, it is primarily focused on monitoring and analyzing network data rather than diagnosing specific connectivity issuesbetween virtual machines in different regions. Azure Monitor Network Insights may not provide the detailed information needed toidentify and troubleshoot issues related to port 33000 connectivity between virtual machines in different regions, which requiremore specific diagnostic tools like IP flow verify and Connection troubleshoot. https://learn.microsoft.com/en-us/azure/network-watcher/ip-flow-verify-overviewhttps://learn.microsoft.com/en-us/azure/network-watcher/connection-troubleshoot-overview#issues-detected-by-connection-troubleshoot
A. Adjust the backend port configuration for the existing load balancer ruleB. Verify the provisioning state of the load balancer in Azure Resource Explorer to ensure it is operationalwrongC. Update the Virtual Machine Scale Set by removing the health probe and reconfiguring it to allow inbound traffic to thebackend VMs
10/5/25, 15:23LMS | Whizlabs
Page 13 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
IncorrectExplanation:Correct Answer: D
Ask our ExpertsDid you like this Question?Question 11Domain: Implement and manage virtual networkingYou have two virtual machines, VM1 and VM2, running in the same resource group vmRG and on the same virtual network VNetVM indifferent subnets: vm1subnet and vm2subnet. You add two NSG outbound rules. The first rule allows access to Azure Storage fromboth virtual machines. The second rule — denies internet access. You provision a new storage account vmstracc28 in the vmRG andadd a file share vmfiles to the account.What steps should you take to give access to vmfiles only from VM2?D. Implement network security group (NSG) rules to permit inbound traffic on the appropriate ports for the backendVMsright
Option D is CORRECT because network security groups control traffic flow to and from network interfaces, including thoseassociated with VMs. By configuring NSG rules to permit inbound traffic on the appropriate ports, external clients should be ableto establish connections to the backend VMs through the load balancer. This action directly addresses the issue of inboundconnectivity by ensuring that the necessary ports are open for external traffic to reach the backend VMs.Option A is INCORRECT because while this might be necessary in some cases, such as if the backend VMs are listening on adifferent port, it's unlikely to resolve an inbound connectivity issue. Backend port configuration typically affects how traffic isrouted to the VMs, not whether external clients can connect to them.Option B is INCORRECT because while it's always good practice to verify the status of resources, including load balancers, itdoesn't directly address the issue of inbound connectivity. Even if the load balancer is provisioned and operational, there couldstill be configuration issues preventing external clients from connecting to the backend VMs.Option C is INCORRECT because while health probes play a role in load balancing and ensuring the availability of backend VMs,removing the health probe altogether is not recommended. Additionally, reconfiguring the health probe may not directly addressthe issue of inbound connectivity.                                                                                                                                                                                       Reference: https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-troubleshoot#problem-no-inbound-connectivity-to-standard-external-load-balancers-elb
A. Add a service endpoint for Microsoft.Storage in vm2subnetrightB. Create an NSG rule to access the storage account only from VM2wrong
10/5/25, 15:23LMS | Whizlabs
Page 14 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
Explanation:Correct Answers: A, D and GFor secure and direct connection to the Azure services, you need to use virtual network endpoints. The endpoints allow you to connectAzure resources without using a public IP address on your VNet. You can access all major Azure services using the service endpoints.To connect securely and selectively VM2 to the storage account, you need to create a service endpoint, deny all access to thestorage account, and enable access only to the subnet where VM2 is running.First, create a service endpoint for the Microsoft Storage service in your vm2subnet subnet. Here is the Azure CLI command:az network vnet subnet update --vnet-name VNetVM --resource-group vmRG \    --name vm2subnet --service-endpoints Microsoft.StorageOr you can use the Azure portal. One the Virtual Network blade, select the Service endpoints (Number 1) and then the Add button(Number 2). On the new panel to the right, select Services (Number 3) and your subnet (Number 4).
Then, you need to deny all network access to the storage account. Here is the Azure CLI command:C. Enable access to the storage account only from vm1subnetD. Deny all traffic to the storage accountrightE. Add a service endpoint for Microsoft.Storage in vm1subnetF. Enable all traffic to the storage accountG. Enable access to the storage account only from vm2subnetrightH. Create an NSG rule to deny the storage account access from VM1
10/5/25, 15:23LMS | Whizlabs
Page 15 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
az storage account update --resource-group vmRG --name vmstracc28 --default-action DenyAnd finally, you need to enable access to a storage account from the subnet that has a service endpoint:    az storage account network-rule add --resource-group vmRG \    --account-name vmstracc28 --vnet VNetVM --subnet vm2subnetYou can execute the last two steps in the portal by limiting access to storage account only to VNetVM virtual network and vm2subnetsubnet and denying any other access. Select the Networking (Number 1) on the Storage account blade. Under the “Firewalls and virtualnetworks'' tab (Number 2), select the “Selected networks” option (Number 3). Then, you can add an existing virtual network (Number 4).On the new panel, you select the network and a subnet. After you confirm your selection, the portal creates the rule for a storageaccount access (Number 5) with the Endpoint status “Enabled.”
All other options are incorrect.For more information about virtual network service endpoints, please visit the below URLs:
Ask our Expertshttps://docs.microsoft.com/en-us/learn/modules/secure-and-isolate-with-nsg-and-service-endpoints/4-vnet-service-endpointshttps://docs.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portalhttps://docs.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal#grant-access-from-a-virtual-networkhttps://docs.microsoft.com/en-us/learn/modules/secure-and-isolate-with-nsg-and-service-endpoints/5-exercise-vnet-service-endpoints
10/5/25, 15:23LMS | Whizlabs
Page 16 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
CorrectDid you like this Question?Question 12Domain: Implement and manage virtual networkingMicrosoft Azure provides a number of solutions for load balancing and secure network connections in the cloud.  Below are some ofthe networking solutions and their definitions, matching the correct solution with their definition.
Explanation:Correct Answer: 1-D, 2-A, 3-B, 4-C 1. Load balancerD. Load-balance internet and private network traffic with high performance andlow latencyYour AnswersLoad balancerLoad-balance internet and private network traffic with highperformance and low latencyNetwork Security GroupsFilter network traffic to and from Azure resources in an Azure virtualnetworkApplication Security GroupsNetwork security as a natural extension of an application's structure
Azure Application GatewayApplication-level routing and load balancing services that let youbuild a scalable and highly available web front end in AzureCorrect AnswersLoad balancerLoad-balance internet and private network traffic with high performanceand low latencyNetwork Security GroupsFilter network traffic to and from Azure resources in an Azure virtualnetworkApplication Security GroupsNetwork security as a natural extension of an application's structureAzure Application GatewayApplication-level routing and load balancing services that let you build ascalable and highly available web front end in Azure
10/5/25, 15:23LMS | Whizlabs
Page 17 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
Correct2. Network Security GroupsA. Filter network traffic to and from Azure resources in an Azure virtual network3. Application Security GroupsB.  Network security as a natural extension of an application's structure4. Azure Application GatewayC.   Application-level routing and load balancing services that let you build ascalable and highly available web front end in Azure
References:
Ask our ExpertsDid you like this Question?Question 13Domain: Implement and manage virtual networkingA small corporation  has 50 VMs (Virtual Machines) on-premises and 20 VMs in Azure. On-premises is connected to Azure using site tosite connectivity. 5 Azure VMs are having network connectivity issues. Which of the following solutions would you utilize to examine theconnectivity issues?Load balancer: Load-balance internet and private network traffic with high performance and low latency. Instantly add scale toyour applications and enable high availability. Load Balancer works across virtual machines, virtual machine scale sets, and IPaddresses.Network Security Groups: You can use an Azure network security group to filter network traffic to and from Azure resources in anAzure virtual network. A network security group contains security rules that allow or deny inbound network traffic to, or outboundnetwork traffic from, several types of Azure resources. For each rule, you can specify source and destination, port, and protocol.Application Security Groups: Application security groups enable you to configure network security as a natural extension of anapplication's structure, allowing you to group virtual machines and define network security policies based on those groups. Youcan reuse your security policy at scale without manual maintenance of explicit IP addresses. The platform handles thecomplexity of explicit IP addresses and multiple rule sets, allowing you to focus on your business logic.Azure Application Gateway: Azure Application Gateway gives you application-level routing and load balancing services that letyou build a scalable and highly-available web front end in Azure. You control the size of the gateway and scale your deploymentbased on your needs.https://azure.microsoft.com/en-us/services/application-gateway/https://azure.microsoft.com/en-us/services/load-balancer/https://docs.microsoft.com/en-us/azure/virtual-network/application-security-groupshttps://docs.microsoft.com/en-us/azure/virtual-network/network-security-group-how-it-works
A. Microsoft Management Agent
10/5/25, 15:23LMS | Whizlabs
Page 18 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572
Explanation:Correct Answer: CAzure Network Watcher provides tools to monitor, diagnose, view metrics, and enable or disable logs for resources in an Azure virtualnetwork. Network Watcher is designed to monitor and repair the network health of IaaS (Infrastructure-as-a-Service) products whichincludes Virtual Machines, Virtual Networks, Application Gateways, Load balancers, etc.
Reference:Ask our ExpertsDid you like this Question?Finish ReviewB. Dependency AgentC. Azure Network WatcherrightD. Azure Log Analytics
Option A is incorrect because the Microsoft Monitoring Agent is a service used to watch and report on application and systemhealth on a Windows computer.Option B is incorrect because the Dependency Agent discovers data about processes running on the VM and external processdependencies.Option C is correct because Network Watcher provides the ability to diagnose the most common VPN Gateway and Connectionsissues.Option D is incorrect because Log Analytics is a tool in the Azure portal to edit and run log queries from data collected by AzureMonitor logs and interactively analyze their results.https://docs.microsoft.com/en-us/azure/network-watcher/network-watcher-monitoring-overview
Hands-on LabsSandboxSubscriptionFor BusinessLibrary
10/5/25, 15:23LMS | Whizlabs
Page 19 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67124/report/8445572CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/5/25, 15:23LMS | Whizlabs
Page 1 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
Incorrect
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationManage Azure identities and governance - Practice ModeCompleted on Tue, 30 Sep 20251stAttempt8/15Marks Obtained53.33%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Manage Azure identities andgovernance158700TotalAll Domains158700Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Manage Azure identities and governanceContoso Inc. is migrating its user management system to Microsoft Entra. The IT administrator is tasked with adding and updatingemployee profile information in the Microsoft Entra admin center. The IT administrator needs to ensure that each user’s profile reflectsaccurate details. What category should the IT administrator navigate to in the Microsoft Entra admin center to update an employee’sprofile with the new job title and department?Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Manage Azure identities and governance/ReportBack to the Courseh
Download Report
A. IdentitywrongB. Job Informationright
boDashboardMy CoursesHands-on LabsSandboxSupport

10/5/25, 15:23LMS | Whizlabs
Page 2 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
IncorrectExplanation:Correct Answer: B
Reference:
Ask our ExpertsDid you like this Question?Question 2C. Contact InfoD. Parental ControlsE. Settings
Option B is CORRECT because in the Microsoft Entra admin center, the “Job Information” category serves as a dedicated sectionfor administrators to manage and update user profiles with job-related details, including job titles and departments. Thiscategory is crucial in ensuring that user profiles accurately reflect each user’s role within the organization. By navigating to the“Job Information” section, IT administrators can efficiently update employees’ profiles with the new job title and department,thereby maintaining the integrity and accuracy of user profiles across the organization’s Microsoft Entra environment. To update the employee's job title or department the IT administrator needs to perform the following steps - Sign in to the Microsoft Entra admin centerBrowse to Identity → Users → All usersSelect the employeeSelect Edit propertiesNavigate to the Job Information section to update the employee's job title or departmentOption A is INCORRECT because  this category typically deals with user-specific information such as username, display name,and user principal name. It is primarily focused on managing identity-related data for users in the Microsoft Entra environment.Option C is INCORRECT because this category is dedicated to managing contact information for users, including phone numbers,email addresses, and mailing addresses. It does not encompass job-related details such as job title and department.Option D is INCORRECT because this category in the Microsoft Entra admin center focuses on settings related to managingaccess and permissions for minors. It is unrelated to updating user profiles with job-specific information.Option E is INCORRECT because while the “Settings” category may offer various options for configuring the Microsoft Entraenvironment, it does not specifically address updating user profiles with job-related information like job title and department. https://learn.microsoft.com/en-us/entra/fundamentals/how-to-manage-user-profile-info?WT.mc_id=AZ-MVP-5004069#add-or-change-profile-information
10/5/25, 15:23LMS | Whizlabs
Page 3 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
Domain: Manage Azure identities and governanceContoso Inc. is implementing Microsoft Entra for managing group properties and group membership. The IT administrator needs tocreate a new group and add members using the Microsoft Entra admin center. Based on the scenario, which statements are correctregarding creating a group and adding members in Microsoft Entra? (Select 3 options)
Explanation:Correct Answers: A, C, and E
Reference:Your AnswerThe IT administrator must have the GroupsAdministrator or User Administrator role to create abasic group and add members simultaneously.The IT administrator needs a P1 or P2 license andthe Privileged Role Administrator role to enable theoption for assigning Microsoft Entra roles to thegroup.The IT administrator can add Owners or Membersto the group during the group creation processCorrect AnswerThe IT administrator must have the GroupsAdministrator or User Administrator role to create abasic group and add members simultaneously.The IT administrator can add Owners or Membersto the group during the group creation processThe IT administrator can edit a group’s name,description, or membership type at any timewithout role restrictions
Option A is CORRECT because in the Microsoft Entra admin center, creating a basic group and adding members simultaneously isa privileged action that requires specific administrative roles. The Groups Administrator or User Administrator roles are essentialfor this task. These roles empower the IT administrator with the necessary permissions to manage groups and their membershipefficiently. Without these roles, the IT administrator won’t have the authority to perform such actions, ensuring proper accesscontrol and security within the organization’s Microsoft Entra environment.Option C is CORRECT because during the group creation process, the IT administrator can assign ownership and membershiproles to users right from the outset. This flexibility streamlines the group management process, allowing the IT administrator toestablish the group’s structure and permissions effectively. By adding Owners or Members during the creation phase, the ITadministrator ensures that the group is properly configured and ready for use as soon as it is created.Option E is CORRECT because the IT administrator can modify various aspects of a group, including its name, description, ormembership type, at any time. This flexibility enables him to adapt the group settings to meet changing organizational needsefficiently. The IT administrator can make these changes without being restricted by specific roles in the Microsoft Entra admincenter. This ensures that the group remains dynamic and aligned with the organization’s objectives over time.Option B is INCORRECT because the availability of the Group email address option depends on the group type selected during thegroup creation process in the Microsoft Entra admin center, and not on the IT administrator’s action. This option is not availablefor all group types. This option is only available for Microsoft 365 group types.Option D is INCORRECT because while the IT administrator may need a P1 or P2 license and the Privileged Role Administrator role toassign Microsoft Entra roles to a group, these requirements do not apply to enable the option for assigning roles. The ITadministrator can create a group without these requirements but won’t be able to assign roles without meeting them. https://learn.microsoft.com/en-us/entra/fundamentals/how-to-manage-groups?WT.mc_id=AZ-MVP-5004069#create-a-basic-group-and-add-members
10/5/25, 15:23LMS | Whizlabs
Page 4 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
Correct
CorrectAsk our ExpertsDid you like this Question?Question 3Domain: Manage Azure identities and governanceContoso Inc. is implementing Microsoft Entra Privileged Identity Management (PIM) to enhance security measures. However, they areuncertain about the licensing requirements for PIM usage.Proposed Solution: Contoso Inc. must ensure they possess either Microsoft Entra ID Governance licenses or Microsoft Entra ID P2 licenses for PIM usage.These licenses cover various user categories, including role assignments, group memberships, approval privileges, and access reviewduties. Is this proposed solution correct? (Select True or False)
Explanation:Correct Answer: A
Reference:Ask our ExpertsDid you like this Question?Question 4A. TruerightB. False
Option A is CORRECT because it addresses the licensing requirements for Microsoft Entra Privileged Identity Management (PIM)implementation, which was the problem posed in the question. It emphasizes the critical need for either Microsoft Entra IDGovernance licenses or Microsoft Entra ID P2 licenses to facilitate various aspects of PIM usage, including role assignments, groupmemberships, approval privileges, and access review duties. By acquiring the appropriate licenses, Contoso Inc. can ensurecompliance with licensing regulations and effectively integrate PIM into its security framework to manage privileged identitiessecurely and efficiently. Option B is INCORRECT because the above-proposed solution is True. https://learn.microsoft.com/en-us/entra/fundamentals/licensing#microsoft-entra-privileged-identity-management
10/5/25, 15:23LMS | Whizlabs
Page 5 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
Domain: Manage Azure identities and governanceContosos Ltd. is transitioning its license management to group-based licensing in Microsoft Entra ID for improved efficiency. The ITlead is assigning licenses to departmental groups. The lead needs to ensure that licenses are automatically managed when usersjoin or leave the Finance Department’s security group. Which aspect of group-based licensing facilitates this automaticmanagement?
Explanation:Correct Answer: C
Reference: Ask our ExpertsDid you like this Question?A. Group-based licensing disables unnecessary service plans automaticallyB. Group-based licensing supports synchronization with on-premises Microsoft Entra ID groupC. Group-based licensing automatically adjusts license assignments based on group membership changesrightD. Group-based licensing requires manual intervention for license adjustmentsE. Group-based licensing is limited to Microsoft 365 products only
Option C is CORRECT because it is one of the key features of group-based licensing in Microsoft Entra ID. With group-basedlicensing, licenses are assigned based on the membership of specific groups. When users join or leave these groups, the licenseassignments are automatically adjusted accordingly. This automation ensures that users have the appropriate licenses assignedto them as their roles within the organization change, without the need for manual intervention. In the scenario provided, the ITlead is assigning licenses to departmental groups. By utilizing group-based licensing, it can be ensured that licenses for theFinance Department are automatically managed when users join or leave the Finance Department’s security group.Option A is INCORRECT because it suggests that group-based licensing automatically disables unnecessary service plans, whichis not accurate. It primarily focuses on managing license assignments based on group membership changes, rather than serviceplan management.Option B is INCORRECT because it correctly states that group-based licensing supports synchronization with on-premisesMicrosoft Entra ID groups. However, synchronization alone doesn’t directly address the requirement of automatically managinglicenses based on group membership changes.Option D is INCORRECT because group-based licensing is designed to automate the process of license adjustments based ongroup membership changes, eliminating the need for manual intervention.Option E is INCORRECT because group-based licensing can be used for various  Microsoft products and services, not limited toMicrosoft 365 products.https://learn.microsoft.com/en-us/entra/fundamentals/concept-group-based-licensing#features
10/5/25, 15:23LMS | Whizlabs
Page 6 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
CorrectQuestion 5Domain: Manage Azure identities and governanceContoso Ltd. is planning to enforce conditional access policies to control access to their Microsoft Entra tenant based on specificconditions. Which license is required to implement risk-based conditional access?
Explanation:Correct Answer: B
Reference:Ask our ExpertsA. Microsoft Entra ID Free - Security defaultsB. Microsoft Entra ID P2rightC. Microsoft Entra ID P1D. Office 365E. Microsoft Entra ID Free - Global Administrators only
Option B is CORRECT because Microsoft Entra ID P2 includes all features of P1 and adds additional advanced security capabilities,including risk-based conditional access policies. This feature allows organizations to dynamically adjust access controls basedon the risk level associated with a user’s sign-in attempt, device location, or other contextual factors. Microsoft Entra ID P2 enablesadministrators to define specific conditions under which access is granted or denied, helping organizations enforce securitypolicies more effectively. This granular control enhances security posture by allowing organizations to respond dynamically toemerging threats or suspicious activities. It offers a holistic security solution that helps organizations protect their digital assetsand mitigate cybersecurity risks effectively.Option A is INCORRECT because the free version of Microsoft Entra only includes basic security features like protecting MicrosoftEntra tenant admin accounts with MFA, the Mobile app as a second factor, and Self-service password reset (SSPR). It does notsupport advanced conditional access policies like risk-based conditional access.Option C is INCORRECT because Microsoft Entra ID P1 offers some advanced security features, but it does not include risk-basedconditional access policies, which are available in the P2 version. Some of the features of Microsoft Entra ID P1 are Fraud alerts,MFA Reports, Custom greetings for phone calls, Conditional Access, etc.Option D is INCORRECT because the Office 365 license provides access to features like Remember MFA for trusted devices, Self-service password reset (SSPR), Admin control over verification methods, etc. They do not include the security features necessaryfor implementing risk-based conditional access policies.Option E is INCORRECT because even though it’s a free version, it only allows access for global administrators and does notinclude the necessary features for implementing risk-based conditional access policies. It includes some features like Admincontrol over verification methods, Remember MFA for trusted devices, Self-service password reset (SSPR), etc. https://learn.microsoft.com/en-us/entra/fundamentals/licensing#authentication
10/5/25, 15:23LMS | Whizlabs
Page 7 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
CorrectDid you like this Question?Question 6Domain: Manage Azure identities and governanceYou want to invite an external guest user to your Microsoft Entra ID tenant.You enable the send invite message checkbox while sending the email invitation.Which of the following are mandatory field(s) that are required to be validated and send the invitation request? (Select Two)
Explanation:Correct Answer: A and D
Architectural Diagram/Snapshots:A. EmailrightB. Display NameC. CC recipientD. Invite redirect URLright
Option A is CORRECT because to invite an external guest user to your Microsoft Entra ID tenant, you need to specify the emailaddress of the external guest user to whom the invitation will be sent. Without the email address, the system would not knowwhere to send the invitation. Thus, Email is a mandatory field that needs to be updated to validate the invitation request.Option D is CORRECT because the invite redirect URL is the URL to which the user is redirected once the invitation is redeemed.After the external guest user accepts the invitation, they need to be redirected somewhere, such as a sign-up page or a landingpage with more information. Providing the redirect URL is necessary for the invitation process to proceed smoothly. By default, ifno changes are made in the invite redirect URL field, the user will be redirected to the MyApplications page. Thus, the inviteredirect URL is a mandatory field that needs to be included to validate the invitation request.Option B is INCORRECT because while displaying the name of the guest user may be desirable for personalization purposes, it’snot mandatory for sending the invitation. If the Display Name field is left blank while sending the request, the system allocates theusername part of the email address as the default Display Name for that specific guest user.Option C is INCORRECT because the CC recipient field is required to include additional recipients who will receive a copy of theemail invitation alongside the guest user. However, it’s not mandatory to send the invitation to the external guest user.
10/5/25, 15:23LMS | Whizlabs
Page 8 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
Incorrect
Reference: Ask our ExpertsDid you like this Question?Question 7Domain: Manage Azure identities and governanceYou have an external user named “External User” in your Microsoft Entra ID tenant.You want to convert the user into an Internal user. Which specific tile option do you select in the My Feed section of the overview bladeto convert an external user to an internal user?How to create or delete users in Microsoft Entra ID
A. B2B InvitationwrongB. Account StatusC. Edit propertiesD. B2B collaborationright
10/5/25, 15:23LMS | Whizlabs
Page 9 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
Explanation:Correct Answer: D
Architectural Diagram/Snapshots:
 Reference:Option D is CORRECT because it pertains to B2B collaboration, which encompasses facilitating collaboration between externalusers and those within your organization's environment. This typically involves functionalities geared towards regulating accessrights and securely sharing resources with external partners. The process of transitioning an external user to an internal userinvolves changing their status from an external collaborator to an internal member within your organization's ecosystem. Thiscapability to convert an external user into an internal one is accessible through the B2B collaboration tile located within the MyFeed section of the overview blade.Option A is INCORRECT because the B2B invitation typically involves inviting external users to collaborate with your organization.It's used for inviting external users to access resources within your organization's environment. However, converting an externaluser to an internal user is a different process and does not directly involve inviting them via B2B invitation. One can check thestatus of the Invitation state (Accepted or Pending), and resend the invitation using the B2B invitation tile.Option B is INCORRECT because the Account Status option is used to display information about the status of user accounts withinyour organization's tenant. It indicates whether a user account is enabled or disabled. However, it doesn't inherently providefunctionality for converting an external user to an internal user.Option C is INCORRECT because the Edit Properties option would typically allow administrators to modify various properties orattributes associated with a user account. This could include details such as display name, contact information, and more. Whilethis option might allow administrators to make changes to a user's profile, it doesn't specifically offer functionality for convertingan external user to an internal user.
10/5/25, 15:23LMS | Whizlabs
Page 10 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
IncorrectAsk our ExpertsDid you like this Question?Question 8Domain: Manage Azure identities and governanceYou own a Microsoft Entra ID tenant named “test.onmicrosoft.com”.The tenant contains two users, named, User1 and User2. User1 and User2 are members of Group1 and Group2 respectively having noroles assigned to them.You enable the self-service password reset feature for Group1 only. Under the authentication methods, you select two methods to reset the password, 1) mobile phone and 2) security questions. Undersecurity questions, you select the number of security questions required to reset as 3. Refer to the below exhibit for details: NameMember ofRole AssignedNumber of Methodsrequired to resetAuthenticationMethodsNumber of QuestionsRequired to resetUser 1Group 1None2Mobile Phone, SecretQuestions3User 2Group 2NoneNoneNoneNoneProposed Solution: User1 can immediately reset password by answering three security questions correctly. Is this proposed solutioncorrect?  (Select True or False)
Explanation:Correct Answer: B https://learn.microsoft.com/en-us/entra/identity/users/convert-external-users-internal#converting-an-external-user
A. TruewrongB. Falseright
Option B is CORRECT because while User1 is a member of Group1 for which the self-service password reset feature is enabled, the
10/5/25, 15:23LMS | Whizlabs
Page 11 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
CorrectReference: Ask our ExpertsDid you like this Question?Question 9Domain: Manage Azure identities and governanceYou own a Microsoft Entra ID tenant named “test.onmicrosoft.com”.The tenant contains two users, named, User1 and User2. User1 and User2 are members of Group1 and Group2 respectively and no rolesare assigned to them.You enable the self-service password reset feature for Group1 only.  Under the authentication methods, you select two methods toreset the password, 1) mobile phone and 2) security questions. Under security questions, you select the number of security questionsrequired to reset as 3. Refer to the below exhibit for details: NameMember ofRole AssignedNumber of Methodsrequired to resetAuthenticationMethodsNumber of QuestionsRequired to resetUser 1Group 1None2Mobile Phone, SecretQuestions3User 2Group 2NoneNoneNoneNoneProposed Solution: User2 can reset password using the text code received on mobile phone. Is this proposed solution correct?  (SelectTrue or False)selected authentication methods for password reset are mobile phone and security questions. The scenario mentions that twoauthentication methods are selected for password reset: mobile phone and security questions. This means that when User1attempts to reset their password, they would need to authenticate using both of these methods. The proposed solution suggeststhat User1 can immediately reset its password by answering three security questions correctly. However, it overlooks therequirement for User1 to authenticate using both selected methods: mobile phone and security questions. Since the proposedsolution only mentions answering security questions, it does not address the need for User1 to authenticate using the mobilephone method. Therefore, it's not a correct solution and the statement is false.Option A is INCORRECT because the above-proposed solution is False.https://learn.microsoft.com/en-us/entra/identity/authentication/tutorial-enable-sspr#enable-self-service-password-reset
A. True
10/5/25, 15:23LMS | Whizlabs
Page 12 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
IncorrectExplanation:Correct Answer: B
Reference:  Ask our ExpertsDid you like this Question?Question 10Domain: Manage Azure identities and governanceYou have an Azure subscription named testSubscription1. In testSubscription1, you create an alert rule named testAlert1 of alert type Anomaly. Now you want to edit the alert rule you createdpreviously.Which information can you change for the alert rule from the Edit alert rule panel? 
Explanation:Correct Answer: A, B and EB. Falseright
Option B is correct answer : Although User2 is a member of Group2 and the self-service password reset feature is enabled only forGroup1, User2 cannot reset their password using a text code received on their mobile phone. The self-service password resetfeature is only enabled for Group1, not Group2. Therefore, User2 does not have access to the self-service password resetfunctionality. Therefore, the proposed solution is incorrect and the statement is false.Enable Microsoft Entra self-service password reset - Microsoft Entra ID
A. Alert start daterightB. Alert end daterightC. Alert typeD. Alert namewrongE. Alert viewright
Option A is correct, you can change the alert start date from the Edit alert rule panel. This allows you to specify when the alert
10/5/25, 15:23LMS | Whizlabs
Page 13 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
IncorrectReference: 
Ask our ExpertsDid you like this Question?Question 11Domain: Manage Azure identities and governanceYou are creating a budget using the Azure Resource Manager Template (ARM) without filters.  You enter the following values for thegiven fields as mentioned below - 
Contact Emails: user1@contoso.comshould begin monitoring.Option B is correct, you can also change the alert end date. This lets you define when the alert should stop monitoring.Option C is incorrect, Once an alert rule is created, the alert type (e.g., Anomaly, Metric, Log) cannot be changed. If you need adifferent alert type, you must create a new alert rule.Option D is incorrect, The alert name is set when you create the alert rule and cannot be changed later. If you need a differentname, you would have to create a new alert rule with the desired name.Option E is Correct, you can change the alert view, which determines how the alert data is displayed and managed.https://learn.microsoft.com/en-us/azure/cost-management-billing/understand/analyze-unexpected-charges#create-an-anomaly-alertManage your alert rules - Azure Monitor | Microsoft Learn
Subscription: Contoso Inc R&D SubscriptionRegion: East USBudget Name: New_BudgetAmount: 1000Time Grain: MonthlyStart Date: YYYY-MM-DDEnd Date: YYYY-MM-DDFirst Threshold: 90
10/5/25, 15:23LMS | Whizlabs
Page 14 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
CorrectYou receive a validation error when the budget is generated. What is the cause of the error?
Explanation:Correct Answer: E
Reference:
Ask our ExpertsDid you like this Question?Question 12A. You are not allowed to use underscore in the Budget Name fieldwrongB. You have not provided any value for the Second Threshold fieldC. The First Threshold value should be less than 90D. You should provide a minimum of two email addressesE. Email addresses should be provided as an array of stringsright
Option E is CORRECT because in ARM templates when specifying contact emails, they should be provided as an array of strings. Inthe case of the scenario provided, you should enter the email address as [“user1@contoso.com”] for the Contact Emails field. Eachemail address should be enclosed in double quotes and separated by commas within square brackets to form an array. Failureto format the email addresses correctly would lead to a validation error. To enter multiple email addresses in the Contact Emailsfield, you should enter the value as [“user1@contoso.com”, “user2@contoso.com”].Option A is INCORRECT because there are no restrictions on using underscores in the Budget Name field in Azure ResourceManager Template (ARM). The error message likely stems from a different issue. For the Budget Name field only alphanumeric,underscore, and hyphen characters are allowed.Option B is INCORRECT because while thresholds are a part of the budget configuration in Azure, the absence of a secondthreshold does not necessarily cause a validation error. It might be optional depending on the specific requirements.Option C is INCORRECT because the threshold value can be greater than or equal to 90. The threshold value is always in percentand can be between 0.01 and 1000. When the cost exceeds the threshold value a notification is sent to the contact emails. Theerror message would not relate to this specific condition.Option D is INCORRECT because there is no specific minimum requirement for the number of contact emails in ARM templates forbudget creation. While it's generally a good practice to have multiple contacts for redundancy and notification purposes, it's nota validation requirement. Therefore, the absence of a second email address wouldn't directly cause a validation error. https://learn.microsoft.com/en-us/azure/cost-management-billing/costs/quick-create-budget-template?tabs=no-filter%2Cportal#deploy-the-template
10/5/25, 15:23LMS | Whizlabs
Page 15 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
CorrectDomain: Manage Azure identities and governanceYour company uses Microsoft Entra ID to manage access to Azure resources. A project team needs temporary access to a sensitiveresource group for a 2-week sprint. The access should be granted only after manager approval and must automatically expire afterthe sprint ends.Which feature should you use to meet this requirement?
Explanation:Correct Answer: C
Reference:
Ask our ExpertsDid you like this Question?Question 13A. Assign a permanent role using Microsoft Entra IDB. Create a Conditional Access policyC. Use Microsoft Entra ID Privileged Identity Management with an access reviewrightD. Enable Multi-Factor Authentication (MFA) for the resource group
Option C is CORRECT because Microsoft Entra ID Privileged Identity Management (PIM) allows just-in-time access to privilegedroles, includes approval workflows, and supports time-bound access. Access reviews can be used to ensure that permissions arestill needed and can automatically revoke access when no longer required. This solution aligns perfectly with the requirement fortemporary, approved access.Option A is INCORRECT because this option would give users continuous access to the resource group, which contradicts therequirement for temporary access. Permanent role assignments are suitable for users who need ongoing access, but in this case,the access should be time-bound and approved, making this option unsuitable.Option B is INCORRECT because Conditional Access policies are used to enforce access controls based on conditions like userlocation, device compliance, or risk level. While powerful for securing access, they do not provide mechanisms for temporaryaccess or approval workflows. Therefore, this option does not meet the scenario's needs. Option D is INCORRECT because While enabling MFA enhances security by requiring additional verification during sign-in, it doesnot control the duration or approval of access. MFA is a good practice for protecting resources, but it does not fulfill the scenario'sneed for temporary, manager-approved access with automatic expiration. https://learn.microsoft.com/en-us/azure/advisor/advisor-cost-recommendations#optimize-virtual-machine-vm-or-virtual-machine-scale-set-vmss-spend-by-resizing-or-shutting-down-underutilized-instances
10/5/25, 15:23LMS | Whizlabs
Page 16 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
CorrectDomain: Manage Azure identities and governanceYou have an Azure subscription.  You want to implement role-based access control (RBAC) to assign users with particular permissionsdepending on their job responsibilities.Which built-in role should you assign to a user to grant them full access to manage resources within the subscription, except foraccess to user and group management in Microsoft Entra ID? 
Explanation:Correct Answer: C
Reference:Ask our ExpertsDid you like this Question?Question 14A. OwnerB. ReaderC. ContributorrightD. User Access Administrator
Option C is CORRECT because the Contributor role grants full access to manage all resources within an Azure subscription, whichaligns with the requirement. However, it explicitly does not allow assigning roles in Azure RBAC. This role also doesn't provideaccess to user and group management in Microsoft Entra ID, meeting the specified requirement.Option A is INCORRECT because the Owner role grants full access to manage all resources within an Azure subscription, includingthe ability to assign roles in Azure RBAC. However, it doesn't specifically restrict access to user and group management inMicrosoft Entra ID. Therefore, while this role grants the necessary permissions for managing resources, it doesn't meet therequirement of excluding access to user and group management.Option B is INCORRECT because the Reader role allows viewing all resources within an Azure subscription but doesn't permitmaking any changes. Since the requirement is to grant full access to manage resources, the Reader role is not suitable as itdoesn't provide the necessary permissions for managing resources.Option D is INCORRECT because the User Access Administrator role specifically focuses on managing user access to Azureresources. While it allows managing access to resources, it doesn't grant full access to manage all resources within an Azuresubscription, which is required in our scenario. Additionally, it doesn't restrict access to user and group management in MicrosoftEntra ID. https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#general
10/5/25, 15:23LMS | Whizlabs
Page 17 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
Domain: Manage Azure identities and governanceA multinational company utilizes Azure for its cloud infrastructure. The IT department needs to efficiently assign roles at differentscopes within Azure while ensuring proper access management and compliance.They want to grant a contractor access to deploy resources within a specific resource group named "project-rg1" without grantingaccess to other resources. Which Azure scope and role assignment should be implemented for this scenario? 
Explanation:Correct Answer: AA. Resource Group; Contributor rolerightB. Subscription; Contributor roleC. Resource Group; Reader roleD. Management Group; Contributor roleE. Subscription; Owner role
Option A is CORRECT because assigning the Contributor role at the Resource Group scope grants the contractor the necessarypermissions to deploy, manage, and delete Azure resources within the specific resource group named "project-rg1." However, itdoes not provide access to resources outside of this resource group, aligning with the organization’s requirement to restrictaccess to only the designated resources. The Contributor role allows the contractor to perform actions such as creating andmanaging resources like virtual machines, databases, or web apps, while still maintaining limitations within the defined scope.This approach enhances security by adhering to the principle of least privilege, ensuring that the contractor can fulfill theirresponsibilities effectively while minimizing the risk of unauthorized access to sensitive resources outside of their designatedscope. Option B is INCORRECT because assigning the Contributor role at the Subscription scope would grant the contractor permissionto manage resources across the entire subscription, including resources outside the "project-rg1" resource group. This violates theorganization’s requirement to limit access to a specific resource group.Option C is INCORRECT because assigning the Reader role at the Resource Group scope would only provide the contractor withread-only access to resources within the "project-rg1" resource group. It would not allow them to deploy or modify resources,which is necessary for their role.Option D is INCORRECT because Management Groups are used to manage access, policies, and compliance across multiplesubscriptions. Assigning the Contributor role to the Management Group scope would grant permissions across all subscriptionsand resource groups under that management group, which exceeds the scope needed for the contractor's task within the"project-rg1" resource group.Option E is INCORRECT because assigning the Owner role at the Subscription scope would grant the contractor full control over allresources within the subscription, which goes beyond the requirement of restricting access to the "project-rg1" resource group.The Owner role includes permissions to manage access control, billing, and all Azure resources, posing a security risk andviolating the principle of least privilege.
10/5/25, 15:23LMS | Whizlabs
Page 18 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
IncorrectReference:Ask our ExpertsDid you like this Question?Question 15Domain: Manage Azure identities and governanceA multinational corporation with various departments and teams spread across different regions has migrated its infrastructure toMicrosoft Azure. The corporation's finance department requires read-only access to all Azure resources for monitoring purposes. Atwhich scope should the IT administrator assign the Reader role to the finance department to meet this requirement?
Explanation:Correct Answer: A
Reference: https://learn.microsoft.com/en-us/azure/role-based-access-control/role-assignments-steps
A. Management grouprightB. SubscriptionC. Resource groupwrongD. Resource
Option A is CORRECT. If the finance department needs read-only access to all Azure resources across multiple subscriptions,assigning the Reader role at the management group level is appropriate. This provides comprehensive monitoring capabilitiesacross the entire management groupOption B is INCORRECT. If the finance department only needs read-only access to resources within a specific subscription,assigning the Reader role at the subscription level is sufficient. This ensures they can monitor all resources within that particularsubscription.Option C is INCORRECT because assigning the Reader role at the resource group scope would only provide read-only access toresources within that specific resource group. Since the scenario states that the finance department requires access to all Azureresources, assigning the role to the subscription scope would be more suitable.Option D is INCORRECT because assigning the Reader role at the resource scope would only provide read-only access to aspecific Azure resource. The scenario requires access to all Azure resources, so assigning the role to the subscription scope wouldbe more appropriate. https://learn.microsoft.com/en-us/Azure/role-based-access-control/role-assignmentsAzure built-in roles - Azure RBAC | Microsoft Learn
10/5/25, 15:23LMS | Whizlabs
Page 19 of 19https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67123/report/8442785
Ask our ExpertsDid you like this Question?Finish Review
CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdHands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/5/25, 15:22LMS | Whizlabs
Page 1 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
Incorrect
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationImplement and manage storage - Practice ModeCompleted on Sun, 28 Sep 20251stAttempt5/15Marks Obtained33.33%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Implement and manage storage1551000TotalAll Domains1551000Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Implement and manage storageA multinational corporation is planning to migrate its file storage infrastructure to Azure Cloud to enhance scalability and availability.The corporation has a diverse set of users across different geographical locations who need access to the Azure file shares. The IT department aims to implement identity-based access control for Azure Files over SMB to ensure seamless authentication andauthorization. Which authentication options should the corporation consider? (Select 2 options)Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Implement and manage storage/ReportBack to the Courseh
Download Report
A. Azure role-based access controlwrong
boDashboardMy CoursesHands-on LabsSandboxSupport

10/5/25, 15:22LMS | Whizlabs
Page 2 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
IncorrectExplanation:Correct Answer: C and E
Reference: 
Ask our ExpertsDid you like this Question?Question 2Domain: Implement and manage storageA healthcare organization is transitioning its file storage infrastructure to Azure Cloud to improve data accessibility and security. Whatauthentication method should be prioritized for integrating with on-premises Active Directory Domain Services (AD DS) whenB. Azure Multi-Factor AuthenticationC. On-premises AD DS authenticationrightD. Azure Multi-Protocol AuthenticationwrongE. Microsoft Entra Kerberos for hybrid identitiesright
Option C is CORRECT because it enables users to authenticate to Azure file shares using their on-premises Active Directorycredentials. It ensures seamless integration with existing identity infrastructure and enables identity-based access control forAzure Files over SMB. It enables organizations to maintain uniform access control rules, simplifying identity management andensuring consistent access control policies across on-premises and cloud environments.Option E is CORRECT because Microsoft Entra Kerberos for hybrid identities enables Microsoft Entra users to authenticate to Azurefile shares using Kerberos authentication. It ensures proper identity-based access control for Azure Files over SMB, particularly inhybrid identity scenarios where users have both on-premises and cloud-based identities. Additionally, it enables users to accessAzure file shares without requiring direct network connectivity to on-premises domain controllers, enhancing flexibility andscalability for hybrid cloud environments.Option A is INCORRECT because Azure RBAC enables fine-grained access management for Azure resources. While it’s not directlyrelated to identity-based access control for Azure Files over SMB, it can still be used to manage access permissions for Azureresources at a broader level. However, it does not handle authentication specifically for file shares.Option B is INCORRECT because although Azure MFA improves security by demanding multiple forms of verification during usersign-ins, it is not specifically related to authentication for Azure Files over SMB. While it provides an additional degree of protection,it doesn’t handle authentication for file shares.Option D is INCORRECT because Azure Multi-Protocol Authentication is not a recognized authentication method for Azure Filesover SMB. This option is not relevant for providing identity-based access control to Azure file shares.https://learn.microsoft.com/en-us/azure/storage/files/storage-files-active-directory-overview#supported-authentication-scenarios
10/5/25, 15:22LMS | Whizlabs
Page 3 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
Incorrectconfiguring identity-based access for Azure Files?Proposed Solution: The healthcare organization should prioritize setting up AD domain controllers and domain-joining machines orVMs for integrating with on-premises AD DS. Is this proposed solution correct?  (Select True or False)
Explanation:Correct Answer: A
Reference:Ask our ExpertsDid you like this Question?Question 3Domain: Implement and manage storageYou have an Azure storage account named teststorage1. You need to enable soft delete for all the file shares in teststorage1. What isthe maximum retention period you can specify?A. TruerightB. Falsewrong
Option A is CORRECT because implementing AD domain controllers and domain-joining machines or VMs to integrate with on-premises AD DS is the recommended authentication method for configuring identity-based access to Azure files. By leveragingthe organization’s established AD infrastructure, the healthcare organization can maintain a cohesive identity managementsystem, simplifying user authentication and access control processes. Prioritizing this authentication method facilitates a smoothtransition to Azure Cloud storage while upholding stringent security standards and regulatory requirements.Option B is INCORRECT because the above-proposed solution is True. https://learn.microsoft.com/en-us/azure/storage/files/storage-files-active-directory-overview#how-it-works
A. 30 daysB. 90 dayswrongC. 365 daysrightD. 48 hoursE. 7 days
10/5/25, 15:22LMS | Whizlabs
Page 4 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
IncorrectExplanation:Correct Answer: C
Reference:Ask our ExpertsDid you like this Question?Question 4Domain: Implement and manage storageYou have an Azure file share named testshare3. What should you do before deleting testshare3?Option C is CORRECT because Azure storage accounts enable you to set a maximum retention duration of 365 days for softdelete. Allowing enough time for file shares or data to be recovered after deletion. By using soft delete you can retrieve data thathas been accidentally erased or overwritten. When soft delete is enabled, data that has been erased is retained for a specifiedperiod, during which it can be recovered. To enable soft delete for all the file shares in teststorage1 and set the file share retention period, you need to perform the followingsteps - Sign in to the Azure PortalNavigate to the storage account teststorage1Select File shares under the Data storage column on the left paneSelect Disabled next to the Soft delete under File share settingsSelect Enabled for soft delete for all file shares when the Soft delete settings panel appearsUse the slider to adjust the File share retention period in days, to specify a number between 1 to 365 daysTo confirm your data retention setting click on the save buttonOption A is INCORRECT because the maximum retention period for soft delete in an Azure storage account is longer than 30 days.Therefore this is not a correct option.Option B is INCORRECT because the maximum retention period for soft delete in an Azure storage account is longer than 90 days.Therefore this is not the correct option.Option D is INCORRECT because the maximum retention period for soft delete in an Azure storage account is much longer than 48hours. Therefore this is not a correct option.Option E is INCORRECT because the maximum retention period for soft delete in an Azure storage account is longer than 7 days.Therefore this is not a correct option. https://learn.microsoft.com/en-us/azure/storage/files/storage-files-enable-soft-delete?tabs=azure-portal#getting-started
10/5/25, 15:22LMS | Whizlabs
Page 5 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
IncorrectExplanation:Correct Answer: D
Reference:Ask our ExpertsDid you like this Question?Question 5Domain: Implement and manage storageYou have two storage accounts, testsource1, and testdestination1.A. Rename the snapshotsB. Migrate the snapshots to another storage accountC. Disable share snapshots for testshare3D. Delete all snapshots associated with testshare3rightE. Convert the snapshots to read-write modewrong
Option D is CORRECT because Azure requires that all snapshots associated with a file share, in this case testshare3, be deletedbefore the file share itself can be deleted. This ensures that no data from the snapshots is retained inadvertently. Azure enforces apolicy where a file share that contains snapshots cannot be deleted unless all the snapshots are removed first. Snapshots arepoint-in-time, read-only copies of data within the file share. They serve to protect and restore data in case of accidentaldeletions or data corruption. As long as the snapshots exist, they provide recovery points that are critical for data protection.Deleting all snapshots associated with testshare3 ensures that all potential recovery points are consciously discarded before theprimary data container is removed.Option A is INCORRECT because renaming snapshots does not allow the deletion of the file share. Snapshots need to be deleted,not renamed, to delete the file share.Option B is INCORRECT because migrating snapshots to another storage account is not a requirement for deleting the file share.Moreover, Azure does not support directly migrating Azure files share snapshots to another storage account; snapshots must behandled within the same account.Option C is INCORRECT because simply disabling the snapshot feature does not remove existing snapshots. The existingsnapshots must be explicitly deleted before the file share can be deleted.Option E is INCORRECT because snapshots are inherently read-only and cannot be converted to read-write mode. The snapshotsmust be deleted to proceed with the deletion of the file share. https://learn.microsoft.com/en-us/azure/storage/files/storage-snapshots-files#capabilities
10/5/25, 15:22LMS | Whizlabs
Page 6 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
IncorrectYou want to replicate only specific blobs that start with “logs” from testsource1 to testdestination1. How can you achieve this during theconfiguration of the object replication policy?  
Explanation:Correct Answer: B
Reference:
Ask our ExpertsDid you like this Question?Question 6A. Use a wildcard character in the prefixB. Create a filter with the prefix “logs”rightC. Enable immutable storagewrongD. Set up a lifecycle management ruleE. Use multi-protocol access
Option B is CORRECT because to replicate only specific blobs that start with the prefix “logs” from testsource1 to testdestination1,you need to create a filter with the prefix “logs” in the object replication policy. This filter ensures that only blobs matching thespecified prefix are replicated. Creating a filter with the prefix “logs” is the appropriate approach to replicate only specific blobsfrom the source storage account (testsource1) to the destination storage account (testdestination1). This filter effectively narrowsdown the scope of replication to include only the desired subset of blobs that meet the specified criteria.Option A is INCORRECT because Object replication policies do not support the use of wildcard characters in prefixes. Prefix filtersmust specify an exact prefix to replicate specific blobs.Option C is INCORRECT because enabling immutable storage is not directly related to configuring object replication policies.Immutable storage provides an additional layer of data protection by preventing data from being modified or deleted for aspecified retention period.Option D is INCORRECT because lifecycle management rules are used to automatically manage the lifecycle of blobs based onspecified criteria such as age or access tier. They are not directly related to configuring object replication policies for replicatingspecific blobs with a particular prefix.Option E is INCORRECT because multi-protocol access allows access to Azure Blob Storage using both Azure Blob Storage APIsand Azure Data Lake Storage Gen2 APIs. It does not specifically address the replication of specific blobs with a particular prefixfrom one storage account to another. https://learn.microsoft.com/en-us/azure/storage/blobs/object-replication-configure?tabs=portal#configure-object-replication-with-access-to-both-storage-accounts
10/5/25, 15:22LMS | Whizlabs
Page 7 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
CorrectDomain: Implement and manage storageWhich feature should Contoso enable to protect against accidental deletions or modifications of blobs in Azure Blob Storage?
Explanation:Correct Answer: C
Reference:Ask our ExpertsDid you like this Question?Question 7Domain: Implement and manage storageContoso wants to ensure that only authorized users from their corporate network (10.0.0.0/16) and a specific Azure virtual network(VNet1) can access their Azure Blob Storage account. Which configuration option should they use to achieve this?A. Azure Storage firewalls and virtual networksB. Blob encryptionwrongC. Blob versioningrightD. Azure Backup
Option C is CORRECT because blob versioning automatically maintains previous versions of blobs when they are modified ordeleted, allowing users to restore earlier versions if necessary. This feature directly addresses the requirement to protect againstaccidental deletions or modifications by retaining historical versions of blobs. Enabling blob versioning would allow Contoso torecover data in case of errors or unintended changes.Option A is INCORRECT because Azure Storage firewalls and virtual networks help control access to Azure Storage accounts byrestricting access based on IP address ranges and virtual network configurations. This feature enhances security by limiting whocan access the storage account, but it does not directly address protecting against accidental deletions or modifications ofblobs.Option B is INCORRECT because blob encryption ensures that the data stored in Azure Blob Storage is encrypted at rest, providingan additional layer of security. While encryption is crucial for protecting data confidentiality, integrity, and compliance, it doesn'tdirectly address the need for maintaining previous versions of blobs for recovery purposes.Option D is INCORRECT because Azure Backup is a service that allows organizations to back up data from on-premises systemsand Azure services to Azure Storage. While Azure Backup is valuable for data protection and disaster recovery, it is not specificallydesigned for protecting blobs against accidental deletions or modifications. Azure Backup focuses more on regular backups andrestoring entire systems or datasets, rather than managing versioning at the blob level. https://learn.microsoft.com/en-us/azure/storage/blobs/versioning-enable?tabs=portal
10/5/25, 15:22LMS | Whizlabs
Page 8 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
IncorrectExplanation:Correct Answer: A
Reference:Ask our ExpertsDid you like this Question?Question 8Domain: Implement and manage storageAs part of their data migration strategy, Contoso needs to transfer large datasets from their on-premises systems to Azure BlobStorage. Which tool should they utilize to perform this task efficiently and maintain data integrity?A. Azure Storage firewalls and virtual networksrightB. Blob encryptionC. Blob versioningD. Azure Backup
Option A is CORRECT because Azure Storage firewalls and virtual networks help control access to Azure Storage accounts byrestricting access based on IP address ranges and virtual network configurations. It can allow Contoso to control access to theirAzure Blob Storage account based on IP address ranges and Azure Virtual Network configurations. Contoso can specify allowed IPaddresses or IP address ranges, including their corporate network (10.0.0.0/16), and configure access permissions for specificAzure Virtual Networks like VNet1. This option aligns with Contoso's requirement to restrict access to their storage account toauthorized users from their corporate network and a specific Azure Virtual Network.Option B is INCORRECT because blob encryption ensures that the data stored in Azure Blob Storage is encrypted at rest, providingsecurity for the stored data. While encryption is important for protecting data confidentiality, integrity, and compliance, it doesnot directly control access to the storage account based on IP addresses or virtual networks.Option C is INCORRECT because blob versioning automatically maintains previous versions of blobs when they are modified ordeleted, allowing users to restore earlier versions if necessary. While blob versioning is essential for data protection and recovery,it does not control access to the storage account based on IP addresses or virtual networks.Option D is INCORRECT because Azure Backup is a service that allows organizations to back up data to Azure Storage for dataprotection and disaster recovery purposes. While Azure Backup is valuable for backing up and restoring data, it does not controlaccess to Azure Blob Storage based on IP addresses or virtual networks. Configure Azure Storage firewalls and virtual networks | Microsoft Learn
A. Azure Storage Explorer B. Azure Data Boxright
10/5/25, 15:22LMS | Whizlabs
Page 9 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
CorrectExplanation:Correct Answer: BWhen transferring large datasets from on-premises to Azure Blob Storage, Azure Data Box is the most efficient and reliable tool for thejob.Designed for large-scale data transfers (terabytes to petabytes).Provides a secure, ruggedized physical device that you load data onto locally.Microsoft then ships the device back, and the data is uploaded directly into your Azure Blob Storage.Ensures data integrity and encryption throughout the process.
Reference:  Ask our ExpertsDid you like this Question?Question 9Domain: Implement and manage storageYou have an Azure subscription. You created a storage account in the EastUS location and a virtual machine in the WestUS locationand integrated both the services for a common requirement. What should you configure on the storage account to ensure that datamoving between the storage account and the virtual machine does not go over the internet?C. Azure Data FactoryD. AzCopywrong
Option A is INCORRECT because while Azure Storage Explorer helps explore and manage data within Azure storage accounts, itmay not be the most efficient tool for transferring large datasets from on-premises systems to Azure Blob Storage, especiallywhen dealing with huge volumes of data.Option C is INCORRECT because Azure Data Factory supports hybrid data integration, enabling users to efficiently transfer databetween on-premises systems and cloud storage services like Azure Blob Storage. Azure Data Factory is well-suited fororchestrating complex data workflows and handling large datasets.Option D is INCORRECT. Command-line tool for fast uploads/downloads to Blob Storage. Works well for moderate-sized datasets,but not ideal for very large volumes due to bandwidth and time constraints.Tutorial: Migrate on-premises data to Azure Storage with AzCopy | Microsoft Learn
A. Data protectionB. A private endpointright
10/5/25, 15:22LMS | Whizlabs
Page 10 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
CorrectExplanation:Correct Answer: B
Reference:Ask our ExpertsDid you like this Question?Question 10Domain: Implement and manage storageYou have an Azure subscription. The subscription contains a list of devices along with the platforms configured as shown in the belowexhibit:DEVICE NAMEPLATFORMDevice1WindowsDevice2Ubuntu LinuxC. A shared access signature (SAS)D. None of the above
Option B is CORRECT because a private endpoint allows you to connect privately to a service powered by Azure Private Link. Itprovides secure connectivity between the virtual network and the Azure service, such as Azure Storage. By configuring a privateendpoint for the storage account, you can ensure that data transfers occur securely within the Azure network and do nottraverse the internet.Option A is INCORRECT because data protection typically refers to measures taken to safeguard data integrity, confidentiality,and availability. While important, it does not directly address the requirement to ensure that data transfers between the storageaccount and virtual machine do not traverse the internet.Option C is INCORRECT because a Shared Access Signature (SAS) provides secure delegated access to resources in a storageaccount without sharing the account keys. While SAS tokens can help control access to resources, they do not inherently preventdata transfers between the storage account and virtual machine from going over the internet.Option D is INCORRECT because this option implies that there is another solution or configuration that should be implemented toachieve the requirement of ensuring that data transfers between the storage account and virtual machine do not traverse theinternet. However, given the context of the question, option B, configuring a private endpoint, would be the appropriate choice. https://learn.microsoft.com/en-us/azure/storage/common/storage-private-endpoints
10/5/25, 15:22LMS | Whizlabs
Page 11 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
IncorrectDevice3AndroidDevice4macOSWhich device(s) can be used to install Azure Storage Explorer? 
Explanation:Correct Answer: C
Reference:Ask our ExpertsDid you like this Question?Question 11Domain: Implement and manage storageYou create an Azure storage account and add a file share. Please select steps that you need to implement for secure access to the Azure files from on-premises.A. Device1 onlyB. Device1 and Device3 onlyC. Device1, Device2 and Device4 onlyrightD. Device1, Device2 and Device3 only
Option C is CORRECT because Azure Storage Explorer is available for Windows, macOS, and Linux. Device1 runs on Windows,Device2 runs on Ubuntu Linux, and Device4 runs on macOS, all of which are supported platforms for Azure Storage Explorer.Therefore, Device1, Device2, and Device4 can be used to install Azure Storage Explorer.Option A is INCORRECT because Device1 is running on Windows, which is a supported platform for Azure Storage Explorer. So, it ispossible to install Azure Storage Explorer on Device1. This option is partially correct as it identifies one device correctly, but itneglects other devices that also support Azure Storage Explorer.Option B is INCORRECT because Device3 runs on Android, which is not a supported platform for Azure Storage Explorer.Option D is INCORRECT because Device3 runs on Android, which is not a supported platform for Azure Storage Explorer. Get started with Storage Explorer | Microsoft Learn
10/5/25, 15:22LMS | Whizlabs
Page 12 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
Explanation:Correct Answers: A, C, and D
To secure access to shared Azure Files from on-premises, you need to ensure that your SMB port 445 is enabled. Users can access theAzure Files using the Server Message Block (SMB) or Network File System (NFS) protocols.Clients can access the SMB file shares on Windows, Linux, or macOS. The NFS protocol applies to Linux and macOS clients. The secureway of accessing the files when you know the incoming IP address of the client. On the Networking screen for the storage account(Number 1), you can create an Azure storage firewall rule (Number 2) based on the known client IP address (Number 3) or the addressrange (Number 4) and limit access to the files.
You need to require the secure transfer when you create a storage account (Number 1) or enable this option (Number 3) on theConfiguration screen (Number 2). It will force REST clients to establish only HTTPS connections and reject not secure data transferA. Enable port 445rightB. Create service principalC. Create a firewall rule based on IP client accessrightD. Secure transfer requiredrightE. Enable port 3389wrong
Option B is incorrect because the service principal is an identity for applications and services to access Azure resources, and it isirrelevant to the file share access.Option E is incorrect because port 3389 is an RDP port, and it is irrelevant to the file share access.
10/5/25, 15:22LMS | Whizlabs
Page 13 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
when using SMB protocol.
To prevent accidental deletion of the files, you need to use the Share snapshots of your file shares, the backups, and soft deletes.
 For more information about secure access to file shares, please visit the below URLs:
10/5/25, 15:22LMS | Whizlabs
Page 14 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
CorrectView Case StudyAsk our ExpertsDid you like this Question?Question 12Domain: Implement and manage storageIn the planned changes, move the existing business critical data from File Servers to Azure Files. The file servers are migrated to Azurefiles.Share name: \\azfs.file.core.windows.net\DataWhich of the following identity types would you use to manage share level permissions and file/directory level permission?https://docs.microsoft.com/en-us/learn/modules/store-and-share-with-azure-files/5-secure-azure-fileshttps://docs.microsoft.com/en-us/azure/storage/files/storage-files-introductionhttps://docs.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal#managing-virtual-network-rules
10/5/25, 15:22LMS | Whizlabs
Page 15 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
Explanation:Correct Answer: 1-A, 2-C, 3-BAuthenticating to Azure file shares: AD DS authenticationWindows Access Control List: File/Directory Level PermissionsMicrosoft Entra users or groups: Share Level PermissionsActive Directory Domain Services (AD DS) authentication allows you to use your on-premises AD credentials to access Azure fileshares. This means you can manage permissions using the same identities and groups you already have in your AD environment. Thissetup provides a seamless integration with your existing identity infrastructure.File and directory-level permissions in Azure Files are managed using Windows Access Control Lists (ACLs). These permissions allowyou to control access at a more granular level, specifying what operations users can perform on individual files or directories. Forexample, you can set read, write, or modify permissions for specific users or groups. These permissions are enforced alongside share-level permissions, with the most restrictive permission taking precedenceShare-level permissions determine whether a user can access the entire file share. These permissions are typically managed usingAzure Role-Based Access Control (RBAC), which allows you to assign roles to Microsoft Entra (formerly Azure AD) users, groups, orYour AnswersAuthenticating to Azure file shares. AD DS authentication
Windows Access Control ListFile/Directory Level Permissions
Microsoft Entra ID users or groupsShare Level PermissionsCorrect AnswersAuthenticating to Azure file shares. AD DS authenticationWindows Access Control ListFile/Directory Level PermissionsMicrosoft Entra ID users or groupsShare Level Permissions
10/5/25, 15:22LMS | Whizlabs
Page 16 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
Incorrectservice principals. Share-level permissions act as a high-level gatekeeper, and you must configure these before setting moregranular file/directory-level permissions.References: 
Ask our ExpertsDid you like this Question?Question 13Domain: Implement and manage storageA multinational company has a storage account named “mncstore”.The communication between a client application and the storage account is encrypted using Transport Layer Security (TLS). Which ofthe following TLS version is not supported by the azure storage account?
Explanation:Correct Answer: DAzure Storage currently supports three versions of the TLS protocol: 1.0, 1.1, and 1.2. Azure Storage uses TLS 1.2 on public HTTPS endpoints,but TLS 1.0 and TLS 1.1 are still supported for backward compatibility.
Reference:Control what a user can do at the directory and file level - Azure FilesEnable AD DS authentication for Azure file shares | Microsoft LearnControl access to Azure file shares by assigning share-level permissions | Microsoft Learn
A. 1.0wrongB. 1.1C. 1.2D. 1.3right
Option A is incorrect because 1.0 is supported for backward compatibility of previous version of TLS that is now deprecated formost of the applications.Option B is incorrect because 1.1 is still supported for the legacy applications.Option C is incorrect because azure storage uses the 1.2 version for TLS public endpoints.Option D is correct because it is not supported by the azure storage account at the moment.
10/5/25, 15:22LMS | Whizlabs
Page 17 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
IncorrectAsk our ExpertsDid you like this Question?Question 14Domain: Implement and manage storageA multinational company has hired an external auditor.  You as a security engineer are tasked to grant access to storage accountsfor a limited period of time. Which of the following solutions is the best way to grant permission to the external auditor?
Explanation:Correct Answer: CA shared access signature (SAS) is a URI that grants restricted access rights to Azure Storage resources for a specified period of time,with a specified set of permissions. You can provide a shared access signature to clients who should not be trusted with your storageaccount key but to whom you wish to delegate access to certain storage account resources.
Reference:Ask our Expertshttps://docs.microsoft.com/en-us/azure/storage/common/transport-layer-security-configure-minimum-version?tabs=portal
A. Shared storage access keyB. Permission through Access ControlC. Shared Access SignaturerightD. Group Policywrong
Option A is incorrect because when you create a storage account, Azure generates two 512-bit storage account access keys forthat account. These keys can be used to authorize access to data in your storage account via Shared Key authorization.Option B is incorrect because You can associate a security principle with an access level for files and directories. Eachassociation is captured as an entry in an access control list (ACL). Each file and directory in your storage account has an accesscontrol list.Option C is correct because A shared access signature (SAS) is a URI that grants restricted access rights to Azure Storageresources for a specified period of time, with a specified set of permissions.Option D is incorrect because Group Policies can be used to grant access to file shares.https://docs.microsoft.com/en-us/rest/api/storageservices/delegate-access-with-shared-access-signature
10/5/25, 15:22LMS | Whizlabs
Page 18 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
CorrectDid you like this Question?Question 15Domain: Implement and manage storageA company is planning to migrate its on-premises files data to Azure.  They have a storage account named ‘mystorageunit’. Thecompany wants to ensure that data is encrypted at rest using the company’s provided keys. Which of the following services supports such requirements? (Select Two)
Explanation:Correct Answers: A and CAzure Storage by default encrypts all data in a storage account at rest. By default, data is encrypted with Microsoft-managed keys.Customer-managed keys rely on managed identities for Azure resources, a feature of Microsoft Entra ID. Managed identities do notcurrently support cross-tenant scenarios. When you configure customer-managed keys in the Azure portal, a managed identity isautomatically assigned to your storage account under the covers. If you subsequently move the subscription, resource group, orstorage account from one Microsoft Entra ID tenant to another, the managed identity associated with the storage account is nottransferred to the new tenant, so customer-managed keys may no longer work.Option A is correct because by design Customer-managed key (CMK) support can be limited to blob service and file service only. Once the storage account is created, this support cannot be changed.A. Azure FilesrightB. Azure Table storageC. Azure Blob storagerightD. Azure Queue storage
10/5/25, 15:22LMS | Whizlabs
Page 19 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
Option B is incorrect because data stored in Table storage is not automatically protected by a customer-managed key whencustomer-managed keys are enabled for the storage account, however, it can be configured during the time of the creation of thestorage account.Option C is correct because by design Customer-managed key (CMK) support can be limited to blob service and file service only.Once the storage account is created, this support cannot be changed.

10/5/25, 15:22LMS | Whizlabs
Page 20 of 20https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67122/report/8440961
Option D is incorrect because data stored in Queue storage is not automatically protected using customer-managed keys, however,it can be configured during the time of storage account creation.References:
Ask our ExpertsDid you like this Question?Finish Review
CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdConfigure customer-managed keys for an existing storage account - Azure Storage | Microsoft DocsAzure Storage encryption for data at rest | Microsoft Docs
Hands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/5/25, 15:21LMS | Whizlabs
Page 1 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Correct
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationDeploy and manage Azure compute resources - Practice ModeCompleted on Fri, 22 Aug 20251stAttempt5/15Marks Obtained33.33%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Deploying and Managing VirtualMachines101002Deploy and manage Azurecompute resources145630TotalAll Domains155730Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Deploy and manage Azure compute resourcesYou have an Azure subscription that contains a resource group in the EastUS location.The requirement is to deploy a storage account in the same location as the resource group. You create a Bicep file named“TestBicepFile” to automate the deployment of the storage account to the resource group.Which property should you modify in the Bicep file? Home/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Deploy and manage Azure compute resources/ReportBack to the Courseh
Download Report
boDashboardMy CoursesHands-on LabsSandboxSupport

10/5/25, 15:21LMS | Whizlabs
Page 2 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
CorrectExplanation:Correct Answer: C
References:
 Ask our ExpertsDid you like this Question?Question 2Domain: Deploy and manage Azure compute resourcesA. SKUB. scopeC. locationrightD. kind
Option C is CORRECT because the location property in the Bicep file, used for Azure resource deployment specifies the Azureregion where the resource should be deployed. In the given requirement, the goal is to deploy the storage account in the samelocation as the existing resource group (EastUS). Modifying the location property to match the location of the resource groupensures that the storage account is deployed to the desired region. Option A is INCORRECT because the SKU property in the Bicep file, used for Azure resource deployment specifies the performancetier of the resource (ex. SKU for a storage account could be Standard_LRS). Modifying the SKU is related to the performancecharacteristics of the resource rather than its deployment location. This property is not directly related to the deploymentlocation.Option B is INCORRECT because the scope property in the Bicep file, used for Azure resource deployment specifies thedeployment scope, such as a resource group or a management group. Modifying the scope would affect where the resource isdeployed, but it doesn’t specify the location within Azure. While specifying the correct scope is crucial for deployment, it’s notdirectly related to ensuring the resource is deployed in the same location as the resource group.Option D is INCORRECT because the kind property in the Bicep file, used for Azure resource deployment defines the type ofresource within the storage account (ex. BlobStorage, FileStorage, etc). It’s unlikely that you need to modify the kind property inthis scenario, as Bicep likely has the correct type defined based on your resource requirements. The kind property is not directlyrelated to the deployment location. https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/resource-declaration?tabs=azure-powershell#locationhttps://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/file#bicep-format
10/5/25, 15:21LMS | Whizlabs
Page 3 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
CorrectAs an Azure administrator, you are tasked with assigning permissions to your team members based on their job assignment withinyour organization’s Azure environment.One of your team members is assigned the task of automating the deployments of virtual machines using a Bicep file.Which of the following permission(s) should you assign?(Select Two) 
Explanation:Correct Answers: C and D
Reference:
Ask our ExpertsDid you like this Question?Question 3A. Microsoft.Compute/virtualMachines/readB. Microsoft.Resources/deployments/readC. Microsoft.Resources/deployments/*rightD. Microsoft.Compute/virtualMachines/writeright
Option C is CORRECT because “Microsoft.Resources/deployments/*” permission grants access to all operations on thedeployment resource type, including write operations. Since the team member is tasked with automating the deployment ofvirtual machines using a Bicep file, they would need this level of access to successfully deploy resources.Option D is CORRECT because “Microsoft.Compute/virtualMachines/write” permission grants write access to virtual machines,allowing the team member to create, update, or delete virtual machines. Since the task involves automating the deployment ofvirtual machines using a Bicep file, write access to virtual machines is necessary for successful deployment. Option A is INCORRECT because “Microsoft.Compute/virtualMachines/read” permission grants read access to virtual machines.While read access might be necessary for certain operations, it is not sufficient for deploying virtual machines using a Bicep file.Option B is INCORRECT because “Microsoft.Resources/deployments/read” permission grants read access to deployments, whichincludes viewing existing deployments. However, for automating the deployment of virtual machines using a Bicep file, the teammember would need write access to the deployment resource type, not just read access. https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/deploy-what-if?tabs=azure-powershell%2CCLI#required-permissions
10/5/25, 15:21LMS | Whizlabs
Page 4 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Domain: Deploy and manage Azure compute resourcesYou have a Bicep file named “TestBicep1” that currently deploys a virtual network and a subnet as shown in the below exhibit:
You get a requirement to deploy a new storage account using the existing Bicep file with specific storage account properties asshown below: 
Which of the following option(s) correctly adds the storage account using the TestBicep1 file to meet the requirement?(Select two) 
Explanation:Correct Answers: A and CName : ‘teststorageacct’SKU : ‘Standard_LRS’Location : the same as the virtual networkKind : ‘StorageV2’Access Tier : ‘Hot’
A. resource storageAccount ‘Microsoft.Storage/storageAccounts@2023-01-01’ = { name : ‘teststorageacct’ location : vnet.locationsku : { name : ‘Standard_LRS’ } kind : ‘StorageV2’ properties : { accessTier : ‘Hot’ } }rightB. resource storageAccount ‘Microsoft.Storage/storageAccounts@2023-01-01’ = { name : ‘teststorageacct’ location : vnet.locationsku : { name : ‘Standard_LRS’ } properties : { accessTier : ‘Hot’ } }C. resource storageAccount ‘Microsoft.Storage/storageAccounts@2023-01-01’ = { name : ‘teststorageacct’ location : ‘eastus’ sku :{ name : ‘Standard_LRS’ } kind : ‘StorageV2’ properties : { accessTier : ‘Hot’ } }rightD. resource storageAccount ‘Microsoft.Storage/storageAccounts@2023-01-01’ = { name : ‘teststorageacct’ location : vnet.locationsku : { name : ‘Standard_GRS’ } kind : ‘StorageV2’ properties : { accessTier : ‘Hot’ } }
Option A is CORRECT because this option correctly adds a storage account with the name ‘teststorageacct’, uses the SKU
10/5/25, 15:21LMS | Whizlabs
Page 5 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
UnattemptedReferences:  Ask our ExpertsDid you like this Question?Question 4Domain: Deploy and manage Azure compute resourcesContoso, a leading technology company, wants to migrate its Azure resource deployments from ARM templates to Bicep files forbetter manageability and efficiency.You are tasked with planning and deploying steps to convert Contoso's Azure Resource Manager template to a Bicep file. How wouldyou arrange the steps? Note: To achieve the above requirement drag the correct options and then drop them in the correct sequence into the answer area. ‘Standard_LRS’, sets the location to match the virtual network location using ‘vnet.location’, specifies the kind as ‘StorageV2’, andsets the access tier to ‘Hot’.Option C is CORRECT because this option correctly sets the name, SKU, kind, access tier, and location as ‘eastus’ instead of using‘vnet.location’. Although it hardcodes the location value, it still matches the requirement of the same location (eastus) as thevirtual network.Option B is INCORRECT because while this option sets the correct location, name, SKU, and access tier, it is missing the kindproperty, which should be set to ‘StorageV2’. This omission makes the configuration incomplete.Option D is INCORRECT because it uses ‘Standard_GRS’ which is the wrong SKU, instead, you should use ‘Standard_LRS’ as the SKU.Therefore this deviation does not adhere to the required standards.Microsoft.Storage/storageAccounts - Bicep, ARM template & Terraform AzAPI referenceBicep accessor operators - Azure Resource Manager | Microsoft Learn
Correct Answer1.C.Convert2.A. Migrate3.B. Refactor4.E.Test5.D. Deploy
10/5/25, 15:21LMS | Whizlabs
Page 6 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Explanation:Correct Answer : C - A - B - E - DContoso's migration process from ARM templates to Bicep files involves several phases as explained below:
Architectural Diagram/Screenshots:Convert: In the first phase, Convert, Contoso captures an initial representation of its Azure resources. This involves eitherextracting existing Azure resources from an ARM template or exporting resources directly from the Azure portal using Azure CLI orPowerShell. Once the representation is captured, if necessary, Contoso decompiles the JSON ARM template to an initial Bicep file.This initial Bicep file serves as the starting point for the migration process.Migrate: The Migrate phase involves creating the first draft of the deployable Bicep file. Contoso begins by creating a new emptyBicep file, distinct from the initial one created in the Convert phase. Next, Contoso copies each resource from the decompiledtemplate to the new Bicep file. This step allows Contoso to address any issues on a per-resource basis and ensures clarity as theBicep file grows in complexity. Additionally, Contoso identifies and recreates any missing resources that were not exported duringthe initial capture phase.Refactor: In the Refactor phase, Contoso focuses on improving the quality of its Bicep code. This includes reviewing resource APIversions and linter suggestions within the new Bicep file. Contoso revises parameters, variables, and symbolic names to align withinternal naming conventions and simplifies expressions where necessary. Additionally, Contoso ensures that child and extensionresources are correctly structured and modularizes the code for better organization and reusability. Comments and descriptionsare added to document the infrastructure, and Contoso ensures adherence to Bicep's best practices.Test: The Test phase involves verifying the integrity of the migrated templates and performing test deployments. Contoso runsthe ARM template deployment what-if operation to compare the current environment state with the desired state defined in theBicep file. This allows Contoso to identify any potential issues or conflicts before actual deployment. Contoso also conducts testdeployments to non-production environments to validate the functionality of the Bicep file and ensure consistency with theoriginal resources.Deploy: In the final phase, Deploy, Contoso deploys the finalized Bicep file to production. Before deployment, Contoso prepares arollback plan to mitigate any risks associated with the deployment process. Contoso runs the ARM template deployment what-ifoperation against the production environment and manually deploys the Bicep file, preferably from a local machine, to ensureproper functionality. After deployment, Contoso runs smoke tests to confirm that the application or workload is functioning asexpected, minimizing downtime and ensuring a smooth transition to Bicep-based deployments.
10/5/25, 15:21LMS | Whizlabs
Page 7 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Incorrect
Reference:Ask our ExpertsDid you like this Question?Question 5Domain: Deploy and manage Azure compute resourcesYou have deployed a web app on Azure using Azure Container Instance (ACI). The web app experiences a huge amount of traffic atcertain hours. To distribute the traffic, you want to scale out your Azure Container Instance.Solution: You can use the auto-scaling feature of Azure Container Instance (ACI).Does the solution meet the goal?  https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/migrate
A. YeswrongB. Noright
10/5/25, 15:21LMS | Whizlabs
Page 8 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
IncorrectExplanation:Correct Answer: B
Reference:
Ask our ExpertsDid you like this Question?Question 6Domain: Deploy and manage Azure compute resourcesContoso Inc. is managing a web application hosted on Azure App Service. The web application is accessed via a custom domain andrequires a secure connection using HTTPS. Additionally, they need to configure a TLS/SSL certificate to ensure secure communicationand map an existing custom DNS name to the Azure App Service. You are working as an Azure Administrator for the company.Solution: You generate and use an Azure App Service Managed Certificate to secure the custom domain with HTTPS. Does the solutionmeet the goal?
Explanation:Correct Answer: AOption B is CORRECT because Azure Container Instances (ACI) do not provide built-in concepts like scale or load balancing. ACI ismore of a lower-level "building block" option compared to higher-level services like Azure Container Apps. While Azure KubernetesService (AKS) can layer orchestration and scale on top of ACI through virtual nodes, ACI itself does not inherently offer auto-scaling functionality. If the goal is to distribute traffic and scale out the Azure Container Instance, other solutions, such asmanually creating more container instances to handle the increased load or using higher-level services like Azure KubernetesService (AKS) that provide built-in auto-scaling capabilities can provide the desired results.Option A is INCORRECT because Azure Container Instances (ACI) do not inherently provide auto-scaling functionality. https://learn.microsoft.com/en-us/azure/container-instances/container-instances-best-practices-and-considerations#azure-container-instanceshttps://learn.microsoft.com/en-us/azure/container-instances/container-instances-overview
A. YesrightB. Nowrong
Option A is CORRECT because using an Azure App Service Managed Certificate is a valid solution to secure your custom domainwith HTTPS. These certificates are free and provide the necessary TLS/SSL encryption to secure the communication for your webapplication hosted on Azure App Service. Therefore, this solution meets the goal.
10/5/25, 15:21LMS | Whizlabs
Page 9 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
IncorrectReference: Ask our ExpertsDid you like this Question?Question 7Domain: Deploy and manage Azure compute resourcesContoso Inc. has a web application on Azure App Service that uses a custom domain. They need it to be secure with HTTPS. Your job asan Azure Administrator is to set up a TLS/SSL certificate for secure communication and connect the custom DNS name to the AzureApp Service.Solution: You configure a CNAME record in the DNS registrar to map a custom domain to the Azure App Service's default domain. Doesthe solution meet the goal?
Explanation:Correct Answer: B
Reference: Option B is INCORRECT because the aforementioned solution meets the requirement goal.https://learn.microsoft.com/en-us/azure/app-service/configure-ssl-certificate?tabs=apex#create-a-free-managed-certificate
A. YeswrongB. Noright
The solution provided does not fully meet the goal. Configuring a CNAME record in the DNS registrar to map a custom domain tothe Azure App Service’s default domain is a necessary step, but it is not sufficient to secure the web application with HTTPS.To secure the application with HTTPS, you also need to:1. Obtain a TLS/SSL certificate: This can be done through Azure App Service, which offers free App Service Managed Certificates forcustom domains, or you can use a certificate from a third-party provider.2. Bind the certificate to the custom domain: This involves uploading the certificate to the Azure App Service and configuring thecustom domain to use the certificate for HTTPS. https://learn.microsoft.com/en-us/azure/app-service/app-service-web-tutorial-custom-domain?tabs=root%2CazurecliAdd and manage TLS/SSL certificates - Azure App Service | Microsoft LearnZero to Hero with App Service, Part 5: Add and Secure a Custom Domain on Your Azure App Service Web App - Azure App Service
10/5/25, 15:21LMS | Whizlabs
Page 10 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
IncorrectAsk our ExpertsDid you like this Question?Question 8Domain: Deploy and manage Azure compute resourcesA Multinational Company is preparing a test environment for the Research team. The team deployed the latest Visual Studio edition.The test environment requires several third-party applications to support the application testing across the organization. The supportteam created a customized image for the research team. The customized VM must be saved to allow provisioning in the future. Whichof the following locations would be suitable for storing this image?
Explanation:Correct Answer:  AManaged images are helpful in the development and test environments where you need a consistent baseline VM. A managedimage resource can be stored as either a managed disk or an unmanaged disk in a storage account.
Reference:https://docs.microsoft.com/en-us/azure/virtual-machines/windows/capture-image-resource#create-an-image-of-a-vm-using-powershellAsk our ExpertsDid you like this Question?A. Azure Blob StoragerightB. Azure FilesC. Remote File ServerD. On-prem Server Locationwrong
Option A is correct because all the images that are going to be used for deploying virtual machines in the cloud need to bestored in Azure blobs as an object.Option B is incorrect because Azure Files cannot be used to store images as these  are accessible via the industry-standard SMB.Option C is incorrect because VM images need to be stored in Azure for deploying the VMs in the cloud.Option D is incorrect because on-prem server would not allow deployment of the VM over the cloud.
10/5/25, 15:21LMS | Whizlabs
Page 11 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
IncorrectQuestion 9Domain: Deploy and manage Azure compute resourcesYou deploy your web app to the App service plan and want to add a custom domain. You need to update the DNS provider records forthe custom domain to prove that you are the domain owner.Which of the following options should you choose to update DNS provider records? [Select TWO]
Explanation:Correct Answers: B and EBefore you add a custom domain to your web app, you need to verify your domain ownership.Your domain ownership could not be verified: If domain ownership is failing, verify if your CNAME or A records are configured correctly.To map the custom domain to the webapp, create either a CNAME or A Record (If you want to use the root domain, you must use Aand TXT records as well)
A. SOA RecordB. CNAMErightC. MX RecordwrongD. SRV RecordwrongE. A Recordright
10/5/25, 15:21LMS | Whizlabs
Page 12 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
UnattemptedOptions B and E are correct: You need to verify that CNAME or A records are configured correctly for Domain ownershipOption A is incorrect: The SOA and NS records are created automatically when you create a DNS zone by using Azure DNS.Option C is incorrect: MX is the mail exchange record. It maps mail requests to your mail server, whether hosted on-premises or in thecloud.Option D is incorrect: The SRV record is a Domain Name System (DNS) resource record. It's used to identify computers hostingspecific services.For more information about adding custom domains to the App service, please visit the below URLs:
Ask our ExpertsDid you like this Question?Question 10Domain: Deploy and manage Azure compute resourcesYou create an App Service (Whiz-app) in resource group (webappRG) in the West US 2 location.The app uses the Microsoft SQL Server database as a data source. You provision a VM (vmdata) witha Microsoft SQL server image.This VM is connected to a subnet [vnetdatasub (10.0.1.0/24)] of VNet [vnetdata (10.0.0.0/16)].It has a public IP address ‘vmdata-publicip’ (52.158.225.2) and a private IP address (10.0.1.4).Except for Whizlab-app, all resources are provisioned in the resource group (dataRG) in theWest US 2 location.Please select the steps to securely connect the ASP.Net web app to the Microsoft SQL database.A is the host record, It maps the domain or hostname to the IP address.CNAME is a Canonical Name record that's used to create an alias from one domain name to another domain name.
Tutorial: Create custom Azure DNS records for a web app | Microsoft DocsTutorial: Map existing custom DNS name - Azure App Service | Microsoft DocsFAQ App Service Domain and Custom Domains - Azure App Service
10/5/25, 15:21LMS | Whizlabs
Page 13 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Explanation:Correct Answers:1. Add vnetdata to web app2. Add vnetdatasub to web app3. Dissociate a vmdata-publicip from vmdata4. Modify web app connection string with NIC Private IPTo connect your web app to the VM running Microsoft SQL Server, you need to connect the App Service to the virtual network and asubnet that the VM is connected to. From the web app screen, you select Networking and then VNet integration. On the VNetIntegration screen (Number 1), under the VNet Configuration section, select the Add VNet (Number 2). The portal opens a new panel tothe right with the Virtual Networks and the Subnets information (Number 3). After you input the required information (vnetdata andvnetdatasub) and push the OK, Azure attaches your web app to the VNet.Correct Answer1.Add vnetdata to web app2.Add vnetdatasub to web app3.Dissociate a vmdata-publicip from vmdata4.Modify web app connection string with NIC Private IP
10/5/25, 15:21LMS | Whizlabs
Page 14 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Next, you need to minimize security risk and dissociate a vmdata-publicip from vmdata. From the vmdata screen (Number 1), youselect Networking (Number 2). On the Networking screen, you click on the NIC Public IP (Number 3).
The portal opens the screen with information about vmdata-publicip (Number 1). You can select the Dissociate button (Number 2)and confirm the selection by pushing the Yes button (Number 3). Azure removes the public IP address associated with vmdata VM.
10/5/25, 15:21LMS | Whizlabs
Page 15 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Incorrect
Then you can modify the connection string in your web app and put the NIC Private IP for the vmdata VM. After you publish the app,your App service app will be connected to the Microsoft SQL server using VNet and a private IP.For more information about App Service app networking, please visit the below URLs:
Ask our ExpertsDid you like this Question?Question 11Domain: Deploying and Managing Virtual MachinesYou work as a database administrator in an organization. Your manager wants to use a managed registry service to build, store,preserve, and replicate container images and artifacts. Which of the following options can you suggest?https://docs.microsoft.com/en-us/azure/app-service/web-sites-integrate-with-vnethttps://docs.microsoft.com/en-us/azure/app-service/networking-features
A. Azure Container RegistryrightB. Azure FunctionsC. Azure Container Apps
10/5/25, 15:21LMS | Whizlabs
Page 16 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
CorrectExplanation:Correct Answer: AAzure Container Registry is a managed registry service based on the open-source Docker Registry 2.0. Create and manage Azurecontainer registries to store and manage your container images and related artifacts.It allows you to build, store, and manage container images and artifacts in a private registry for all types of container deployments.Use Azure Container Registries with your existing container development and deployment pipelines. Hence, all other options are incorrect.References:
Ask our ExpertsDid you like this Question?Question 12Domain: Deploy and manage Azure compute resourcesABCD Corp. is a multinational company which develops software. Research department of the company creates and destroys virtual machines on a regular basis for their development and testingpurposes.  Which of the following VM series is well suited for the given scenario?
Explanation:Correct Answer:  CD. All of the abovewrong
Azure Container Registry | Microsoft AzureManaged container registries - Azure Container Registry | Microsoft LearnAzure Containers—Services and Management | Microsoft Azure
A. Ls-SeriesB. F-SeriesC. Bs-SeriesrightD. Mv2-Series
10/5/25, 15:21LMS | Whizlabs
Page 17 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
CorrectView Case StudyBs-series VMs are economical virtual machines that provide a low-cost option for workloads that typically run at a low to moderatebaseline CPU utilization, but sometimes need to burst to significantly higher CPU utilization when the demand rises. Bs-series VMs arenot hyperthreaded.Example workloads include development and test servers, low-traffic web servers, small databases, micro services, servers for proof-of-concepts, and build servers.
Reference:Ask our ExpertsDid you like this Question?Question 13Domain: Deploy and manage Azure compute resourcesTo meet all technical requirements, company has developed bicep script to deploy backup vaults in Paris, France branch. A newresource group needs to be created and deploy the vault using the bicep file.Resource Group name – pr-fr-rg-01Resource Group Location – Should be in closest azure region.Below is content of the bicep script is as follows:@description('Name of the Vault')param vaultName string@description('Enable CRR (Works if vault has not registered any backup instance)')param enableCRR bool = trueOption A is incorrect because the Ls-series VMs are storage optimised, and are ideal for applications requiring low latency, highthroughput, and large local disk storage.Option B is incorrect because F-series VMs has a higher CPU-to-memory ratio. They are equipped with 2 GB RAM and 16 GB oflocal solid-state drive (SSD) per CPU core and are optimized for compute intensive workloads.Option C is correct because Bs-series VMs are economical virtual machines that provide a low-cost option for workloads thattypically run at a low to moderate baseline CPU utilization, but sometimes need to burst to significantly higher CPU utilizationwhen the demand rises. This is best suited for the test/dev environments.Option D is incorrect because The Azure Mv2-series virtual machines are hyper-threaded and feature Intel® Xeon® Platinum8180M 2.5GHz (Skylake) processors, offering up to 416 vCPU on a single VM and offer 3TB, 6 TB, and 12 TB memory configurations.This is by far the largest-memory virtual machine offered on Azure and provides unparalleled computational performance tosupport large in-memory databases.https://azure.microsoft.com/en-in/pricing/details/virtual-machines/series/
10/5/25, 15:21LMS | Whizlabs
Page 18 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
@description('Change Vault Storage Type (Works if vault has not registered any backup instance)')@allowed([  'LocallyRedundant'  'GeoRedundant'])param vaultStorageType string = 'GeoRedundant'@description('Location for all resources.')param location string = resourceGroup().locationvar skuName = 'RS0'var skuTier = 'Standard'resource recoveryServicesVault 'Microsoft.RecoveryServices/vaults@2022-02-01' = {  name: vaultName  location: location  sku: {    name: skuName    tier: skuTier  }  properties: {}}resource vaultName_vaultstorageconfig 'Microsoft.RecoveryServices/vaults/backupstorageconfig@2022-02-01' = {  parent: recoveryServicesVault  name: 'vaultstorageconfig'  properties: {    storageModelType: vaultStorageType    crossRegionRestoreFlag: enableCRR  }}A backup vault needs to be deployed using bicep file. Which of the following command syntax is correct to deploy bicep files forbackup vault using Azure PowerShell?
Explanation:Correct Answer: CA. New-AzResourceGroup -Name pr-fr-rg-01 -Location “France” New-AzResourceGroupDeployment -ResourceGroupName pr-fr-rg-01 -TemplateFile ./main.bicep -vaultName "<vault-name>"B. New-AzResourceGroup -Name pr-fr-rg-01 -Location france New-AzResourceGroupDeployment -ResourceName pr-fr-rg-01 -TemplateFile ./main.bicep -vaultName "<vault-name>"C. New-AzResourceGroup -Name pr-fr-rg-01 -Location france New-AzResourceGroupDeployment -ResourceGroupName pr-fr-rg-01 -TemplateFile ./main.bicep -vaultName "<vault-name>"rightD. New-AzResourceGroup -GroupName pr-fr-rg-01 -Location france New-AzResourceGroupDeployment -ResourceGroupNamepr-fr-rg-01 -TemplateFile ./main.bicep -vault "<vault-name>"
10/5/25, 15:21LMS | Whizlabs
Page 19 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
IncorrectThe correct answer for creating a new resource group and deploying vault using bicep file:New-AzResourceGroup -Name pr-fr-rg-01 -Location franceNew-AzResourceGroupDeployment -ResourceGroupName pr-fr-rg-01 -TemplateFile ./main.bicep -vaultName "<vault-name>"
New-AzResourceGroup -Name pr-fr-rg-01 -Location franceAnd to deploy the vault using bicep file will be as below:New-AzResourceGroupDeployment -ResourceGroupName pr-fr-rg-01 -TemplateFile ./main.bicep -vaultName "<vault-name>"Reference:Ask our ExpertsDid you like this Question?Question 14Option A is incorrect because location should not be in quote “france”, makes the resource group create command incorrect.Option B is incorrect because “resourcename” in the second command should be written as “resourcegroupname” presentcommand will fail.Option C is correct because to create resource group should be
Option D is incorrect because -vault in the second command should be -vaultName.Quickstart to create an Azure Recovery Services vault using Bicep. - Azure Site Recovery | Microsoft Learn
10/5/25, 15:21LMS | Whizlabs
Page 20 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Domain: Deploy and manage Azure compute resourcesA multinational company with its headquarters in New York plans to automate the deployment of a virtual machine scale set runningWindows 2022 Server Image.The virtual machine scale set needs to have an IIS role installed on them upon provisioning.  Which of the following functionality wouldhelp achieve the above?
Explanation:Correct Answer: AA. Creating an Azure DSC ExtensionrightB. Create an automation accountC. Creating an Azure policywrongD. Install IIS before capturing images
Option A is correct because the PowerShell cmdlets can be used through DSC extension for deploying or installing any roles orfeatures on a server. It is best used in interactive troubleshooting and information-gathering scenarios. You can use the cmdletsto package, publish, and monitor DSC extension deployments.Option B is incorrect because Azure Automation delivers cloud-based automation, operating system updates, and configurationservice that supports consistent management across your Azure and non-Azure environments.Option C is incorrect because Azure Policy helps to enforce organizational standards and to assess compliance at scale.Option D is incorrect because the manual installation of the roles before capturing could cause it hard to manage the scale setsand may leave it in inconsistent mode.
10/5/25, 15:21LMS | Whizlabs
Page 21 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Unattempted
Reference:Ask our ExpertsDid you like this Question?Question 15Domain: Deploy and manage Azure compute resourcesYou host a website in Microsoft Azure app service. The App service uses Web Application Firewall version 2.  You need to create a newcustom Web Application Firewall rule to allow connections.  Which of the following commands will achieve the goal? https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-dsc
A. $rgName = "WebRG" $appGWName = "AppGw" $fwPolicyName = "Wafpol" # Pull the existing Azure resources $appGW = Get-AzApplicationGateway -Name $appGWName -ResourceGroupName $rgName $pol = Get-AzApplicationGatewayFirewallPolicy -Name $fwPolicyName -ResourceGroupName $rgName # Update the resources $pol[0].CustomRules[0].Action = "deny"$appGW.FirewallPolicy = $pol # Push your changes to Azure Set-AzApplicationGatewayFirewallPolicy -Name $fwPolicyName -ResourceGroupName $rgName -CustomRule $pol.CustomRules Set-AzApplicationGateway -ApplicationGateway $appGWB. $rgName = "WebRG" $appGWName = "AppGw" $fwPolicyName = "Wafpol" # Pull the existing Azure resources $appGW = Get-AzApplicationGateway -Name $appGWName -ResourceGroupName $rgName $pol = Get-AzApplicationGatewayFirewallPolicy -
10/5/25, 15:21LMS | Whizlabs
Page 22 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609
Explanation:Correct Answer: BThe line $pol[0].CustomRules[0].Action = "allow" modifies the policy to adds action allow on the policy.
Reference:Ask our ExpertsDid you like this Question?Finish ReviewName $fwPolicyName -ResourceGroupName $rgName # Update the resources $pol[0].CustomRules[0].Action = "allow"$appGW.FirewallPolicy = $pol # Push your changes to Azure Set-AzApplicationGatewayFirewallPolicy -Name $fwPolicyName -ResourceGroupName $rgName -CustomRule $pol.CustomRules Set-AzApplicationGateway -ApplicationGateway$appGWrightC. $rgName = "WebRG" $appGWName = "AppGw" $fwPolicyName = "Wafpol" # Pull the existing Azure resources $appGW = Get-AzApplicationGateway -Name $appGWName -ResourceGroupName $rgName $pol = Get-AzApplicationGatewayFirewallPolicy -Name $fwPolicyName -ResourceGroupName $rgName # Update the resources $pol[0].CustomRules[0].Action = "allow"$appGW.FirewallPolicy = $pol # Push your changes to Azure Set-AzApplicationGateway -ApplicationGateway $appGWD. $rgName = "WebRG" $appGWName = "AppGw" $fwPolicyName = "Wafpol" # Pull the existing Azure resources $appGW = Get-AzApplicationGateway -Name $appGWName -ResourceGroupName $rgName $pol = Get-AzApplicationGatewayFirewallPolicy -Name $fwPolicyName -ResourceGroupName $rgName # Update the resources $pol[0].CustomRules[0].Action = "allow"$appGW.FirewallPolicy = $pol # Push your changes to Azure Set-AzApplicationGatewayFirewallPolicy -Name $fwPolicyName -ResourceGroupName $rgName -CustomRule $pol.CustomRules
Option A is incorrect because the line $pol[0].CustomRules[0].Action = "deny" blocks any action on the policy.Option B is correct because the line $pol[0].CustomRules[0].Action = "allow" modifies the policy to adds action allow on the policy.Option C is incorrect because Set-AzApplicationGatewayFirewallPolicy -Name $fwPolicyName -ResourceGroupName $rgName -CustomRule $pol.CustomRules command is missing thus the created rule is not going to update the policy changes to make iteffective.Option D is incorrect because Set-AzApplicationGateway -ApplicationGateway $appGW command is missing meaning updatedpolicy will not be applied to application gateway.Quickstart: Create an Azure WAF v2 on Application Gateway - Bicep - Azure Application Gateway | Microsoft Learn
10/5/25, 15:21LMS | Whizlabs
Page 23 of 23https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/67121/report/8412609CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdHands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/5/25, 15:20LMS | Whizlabs
Page 1 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationPractice Test III - Practice ModeCompleted on Sun, 21 Sep 20251stAttempt28/55Marks Obtained50.91%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Manage Azure identities andgovernance17116002Implement and manage storage1477003Deploy and manage Azurecompute resources1248004Implement and manage virtualnetworking1064005Monitor and maintain Azureresources20200TotalAll Domains55282700Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Implement and manage virtual networkingHome/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Practice Test III/ReportBack to the Courseh
Download Report
boDashboardMy CoursesHands-on LabsSandboxSupport

10/5/25, 15:20LMS | Whizlabs
Page 2 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
A team member has created a point-to-site VPN connection between a computer named "WorkstationA" and an Azure VirtualNetwork. Another point-to-site VPN connection needs to be made between the same Azure Virtual Network and a computer named"WorkstationB." The VPN client package was generated and installed on "WorkstationB." You need to ensure that you can create asuccessful point-to-site VPN connection.You decide to export the "Workstation A" client certificate and install it on "Workstation B."Would this solution fulfill the requirement?
Explanation:Answer – AYes, this is one of the requirements. This is also mentioned in the Microsoft documentation.
For more information on creating point-to-site VPN connections, please visit the below URL-Ask our ExpertsA. YesrightB. Nowrong
https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-point-to-site-resource-manager-portal
10/5/25, 15:20LMS | Whizlabs
Page 3 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectDid you like this Question?Question 2Domain: Implement and manage storageYou have a storage account named whizlabstore. You have created a file share named demo using the file service. You need toensure that users can connect to the file share from their home computers. Which of the following port should be open to provide theconnectivity?
Explanation:Answer – CTo access files from home computers, users have to use SMB protocol that expects port 445 to be open.This is clearly given in the Microsoft documentation.
A. 80wrongB. 443C. 445rightD. 3389
10/5/25, 15:20LMS | Whizlabs
Page 4 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectFor more information on using file shares in Azure, please visit the below URL-Ask our ExpertsDid you like this Question?Question 3Domain: Implement and manage storageA company has created a storage account in its Azure subscription. The name of the storage account is whizlabstore. They have alsocreated a file share named demo. They need to access the files in the file share via a UNC path.You need to fill in the following blocks to ensure that the right UNC path is provided.
Which of the following needs to go into Slot1?
Explanation:Answer – Fhttps://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-windows
A. blobB. blob.core.windows.netC. portal.azure.comD. fileE. file.core.windows.netF. whizlabstorerightG. demo
10/5/25, 15:20LMS | Whizlabs
Page 5 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectTo work with UNC path format, you have to mount the Azure file share with File Explorer. The UNC path format is:\\.file.core.windows.net\or in our case:\\whizlabstore.file.core.windows.net\demo For more information on using Aure file share service, please visit the below URLs-https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-windowshttps://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file?redirectedfrom=MSDNAsk our ExpertsDid you like this Question?Question 4Domain: Implement and manage storageA company has created a storage account in their Azure subscription. The name of the storage account is whizlabstore. They havealso created a file share named demo. They need to access the files in the file share via a UNC path.You need to fill in the following blocks to ensure that the right UNC path is provided.
Which of the following needs to go into Slot2?A. blobB. blob.core.windows.netC. portal.azure.comD. filewrongE. file.core.windows.netright
10/5/25, 15:20LMS | Whizlabs
Page 6 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectExplanation:Answer – ETo work with UNC path format, you have to mount the Azure file share with File Explorer. The UNC path format is:\\.file.core.windows.net\or in our case:\\whizlabstore.file.core.windows.net\demoFor more information on using Aure file share service, please visit the below URLs-
Ask our ExpertsDid you like this Question?Question 5Domain: Implement and manage storageA company has created a storage account in their Azure subscription. The name of the storage account is whizlabstore. They havealso created a file share named demo. They need to access the files in the file share via a UNC path.You need to fill in the following blocks to ensure that the right UNC path is provided.
Which of the following needs to go into Slot3?F. whizlabstoreG. demo
https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-windowshttps://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file?redirectedfrom=MSDN
A. blob
10/5/25, 15:20LMS | Whizlabs
Page 7 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectView Case StudyExplanation:Answer – GUNC stand for Universal naming convention. UNC is used  for Microsoft Windows for accessing shared network folder .and printer.Generic naming convention for UNC is given below: \\host-name\share-name\file pathTo work with UNC path format, you have to mount the Azure file share with File Explorer. The UNC path format is:\\.file.core.windows.net\or in our case:\\whizlabstore.file.core.windows.net\demoFrom the above is it clear that G is the correct answer  all other answers are wrong.For more information on using Azure file share service, please visit the below URLs-
Ask our ExpertsDid you like this Question?Question 6Domain: Implement and manage virtual networkingWould Virtual Machines launched in the whizlab-client virtual network automatically get registered in the private domain ofprivate.whizlabs.com if auto registration is enabled?B. blob.core.windows.netC. portal.azure.comwrongD. fileE. file.core.windows.netF. whizlabstoreG. demoright
https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-windowshttps://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file?redirectedfrom=MSDN
A. Yesright
10/5/25, 15:20LMS | Whizlabs
Page 8 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Explanation:Answer – ASo below is the representation of the network based on the details given in the question.
Since the whizlab-client is registered with the private hosted zone, automatic registration of VM’s is possible.This is also given in the Microsoft documentation.B. No
10/5/25, 15:20LMS | Whizlabs
Page 9 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
For more information on private DNS zones, please visit the below URL-
Ask our ExpertsDid you like this Question?Question 7Domain: Implement and manage virtual networkingA company has set up a Virtual Machine in Azure. A web server listening on port 80 and a DNS server has been installed on the Virtualmachine. A network security group is attached to the network interface for the virtual machine. The rules for the NSG are given below.Inbound Ruleshttps://docs.microsoft.com/en-us/azure/dns/private-dns-overviewhttps://docs.microsoft.com/en-us/azure/dns/private-dns-autoregistration
10/5/25, 15:20LMS | Whizlabs
Page 10 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Outbound Rules
If RuleB is deleted/omitted, please select the service through which Internet users connect to the virtual machine.
Explanation:Answer – DIf RuleB is deleted, users won’t be able to access port 80 and the web server.There is a Deny rule of RuleA for ports 50-60. Since DNS listens on port 53, you will not be able to access the DNS server. But you will stillbe able to connect to the virtual machine using Remote Desktop Protocol (RDP) under the Allow_rdp rule.Because of this logic, all other options are incorrect.For more information on network security, please visit the below URL-A. Through the web server B. Through the DNS server C. both Web and DNS serversD. Through RDPrightE. Through RDP, Web, and DNS servers
Azure network security groups overview | Microsoft Docs
10/5/25, 15:20LMS | Whizlabs
Page 11 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectAsk our ExpertsDid you like this Question?Question 8Domain: Implement and manage storageYour company has set up a storage account in Azure, as shown below.
The company needs to allow only connections to the storage account from an IP address range of 51.107.2.0 to 51.107.2.255. From whichof the following section of the storage account would you modify to fulfill this requirement?
Explanation:Answer – AThis can be done from the Networking, as shown below.A. NetworkingrightB. Advanced securityC. Soft DeleteD. Lifecycle Management
10/5/25, 15:20LMS | Whizlabs
Page 12 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
Ensure to click on “Selected networks” and then enter the IP address range.Since this is clear from the implementation, all other options are incorrect.For more information on the Firewall and virtual network feature, please visit the below URL-https://docs.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal Ask our ExpertsDid you like this Question?Question 9Domain: Implement and manage storageYour company has set up a storage account in Azure, as shown below.
10/5/25, 15:20LMS | Whizlabs
Page 13 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
There is a requirement to retain any blob data that might accidentally be deleted. The deleted data needs to be retained for 14 days.From which of the following option of the storage account would you modify to fulfill this requirement?
Explanation:Answer – CThis can be done from the Data Protection option/tab from the storage account at any time by using the Azure portal, PowerShell, orAzure CLI.
A. Firewall and virtual networksB. Advanced securityC. Data Protection(Soft Delete)rightD. Lifecycle Management
10/5/25, 15:20LMS | Whizlabs
Page 14 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
 Blob soft delete protects an individual blob, snapshot, or version from accidental deletes or overwrites by maintaining the deleteddata in the system for a specified period of time. During the retention period, you can restore a soft-deleted object to its state at thetime it was deleted.Since this is clear from the implementation, all other options are incorrect. Reference: Enable soft delete for blobs - Azure Storage | Microsoft Learn Ask our ExpertsDid you like this Question?Question 10Domain: Deploy and manage Azure compute resourcesA company wants to deploy a virtual machine using a Resource Manager template. The template needs to be submitted via Azure CLIcommands. The template is stored in a file named storage.json.You need to complete the below CLI command.
10/5/25, 15:20LMS | Whizlabs
Page 15 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into SLOT 1?
Explanation:Answer - BSLOT 1 covers the word "deployment".
All other options are incorrect.A. templatewrongB. deploymentrightC. resourceD. vm
10/5/25, 15:20LMS | Whizlabs
Page 16 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectFor more information on deploying templates via the CLI, please visit the below URL-Ask our ExpertsDid you like this Question?Question 11Domain: Deploy and manage Azure compute resourcesA company wants to deploy a virtual machine using a Resource Manager template. The template needs to be submitted via Azure CLIcommands. The template is stored in a file named storage.json.You need to complete the below CLI command.
Which of the following would go into SLOT 2?
Explanation:Answer - CSLOT 2 covers "--template-file" option.https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy-cli
A. --templateB. --template-uriC. --template-filerightD. --template-resource
10/5/25, 15:20LMS | Whizlabs
Page 17 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
All other options are incorrect.For more information on deploying templates via the CLI, please visit the below URL-Ask our ExpertsDid you like this Question?Question 12Domain: Manage Azure identities and governanceA company has set up an Azure subscription and a tenant. They want to ensure that only Virtual Machines of a particular SKU size canbe launched in their Azure account.They decide to implement Role-Based access control.Does this fulfill the requirement?https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy-cli
A. YeswrongB. Noright
10/5/25, 15:20LMS | Whizlabs
Page 18 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer — BRole-based access control can be used to restrict access to resources. RBAC does not put any governance, regarding type ofresources to be created. If you need to limit the resource creation, like provision VM's  only of a particular SKU's, you need to implementAzure policies.You can use allowed virtual machine policy in this scenario: For more information on policy and role-based access control, please refer to following list. Policy -- Overview of Azure Policy - Azure Policy | Microsoft DocsRBAC -- https://docs.microsoft.com/en-us/azure/role-based-access-control/overviewAsk our ExpertsDid you like this Question?Question 13Domain: Manage Azure identities and governanceA company has set up an Azure subscription and a tenant. They want to ensure that only Virtual Machines of a particular SKU size canbe launched in their Azure account.They decide to implement Azure locks.Does this fulfill the requirement?
Explanation:Answer - BAzure locks are used to prevent users from accidentally deleting or modifying critical resources. If you need to limit the resourcecreation, like provision VM only of a particular SKU, you need to implement Azure policies. For more information on Azure locks, please visit the below URL-Allowed Virtual Machine SKUs (Deny): Specifies a set of virtual machine SKUs that you can deploy as parameter to this policy.Any  VM SKU which is not in the  parameter list, cannot be created as per  this policy. Users will get a message  “VM SKU “is notallowed by the policy -- Allowed Virtual Machine SKUs. 
A. YesB. Noright
10/5/25, 15:20LMS | Whizlabs
Page 19 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectAsk our ExpertsDid you like this Question?Question 14Domain: Manage Azure identities and governanceA company has set up an Azure subscription and a tenant. They want to ensure that only Virtual Machines of a particular SKU size canbe launched in their Azure account.They decide to implement Azure policies.Does this fulfill the requirement?
Explanation:Answer - AYes, this can be done with Azure policies. There is also already an in-built policy which can implement this policy as shown below.https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-lock-resources
A. YesrightB. No
10/5/25, 15:20LMS | Whizlabs
Page 20 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
For more information on an example on this, please visit the below URL-Ask our ExpertsDid you like this Question?Question 15Domain: Implement and manage virtual networkingA company plans to use Azure Network watcher to perform the following tasks.
Which of the following Network watcher feature would you use for the following requirement?"Find out if a network security rule is preventing a network packet from reaching a virtual machine hosted in an Azure virtualnetwork."https://docs.microsoft.com/en-us/azure/governance/policy/samples/allowed-skus-storage
Find out if a network security rule prevents a network packet from reaching a virtual machine hosted in an Azure virtualnetwork.Find out if there is outbound connectivity between an Azure virtual machine and an external host.
A. IP Flow Verifyright
10/5/25, 15:20LMS | Whizlabs
Page 21 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Explanation:Answer – AThis can be done with the IP Flow Verify feature. The Microsoft documentation mentions the following.
Option B is incorrect since this feature is used to get the next hop type and IP address of a specific VM packet. Option C is incorrect since this feature is used for deep-dive network packet capture.Option D is incorrect since this feature is a cloud-based solution that provides visibility into user and application activity in cloudnetworks.For more information on the IP Flow Verify feature, please visit the below URL-Ask our ExpertsDid you like this Question?B. Next HopC. Packet CapturewrongD. Traffic Analysis
https://docs.microsoft.com/en-us/azure/network-watcher/network-watcher-ip-flow-verify-overview
10/5/25, 15:20LMS | Whizlabs
Page 22 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectQuestion 16Domain: Implement and manage virtual networkingA company plans to use Azure Network watcher to perform the following tasks.
Which of the following network watcher feature would you use for the following requirement?"Find out if there is outbound connectivity between an Azure virtual machine and an external host."
Explanation:Answer – CThis can be done with the Connection Monitor feature. The Microsoft documentation mentions the following.
Find out if a network security rule prevents a network packet from reaching a virtual machine hosted in an Azure virtualnetwork.Find out if there is outbound connectivity between an Azure virtual machine and an external host.
A. IP Flow VerifywrongB. Next HopC. Connection MonitorrightD. Traffic Analytics
10/5/25, 15:20LMS | Whizlabs
Page 23 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectOption A is incorrect since this feature is used to verify traffic flow based on security group rules.Option B is incorrect since this feature is used to get the next hop type and IP address of a specific VM packet.Option D is incorrect since this feature is a cloud-based solution that provides visibility into user and application activity in cloudnetworks.For more information on the network watcher tool, please visit the below URL-
Ask our ExpertsDid you like this Question?Question 17Domain: Deploy and manage Azure compute resourcesA company is planning to deploy an application to a set of Virtual Machines in an Azure network. The company needs to have an SLAof 99.99% for the application hosted on the Virtual machines. Which of the following should be implemented to guarantee an SLA of99.99% on the infrastructure level?
Explanation:Answer – BYou can achieve 99.99% SLA on your virtual machines' infrastructure level by deploying them across availability zones.The Microsoft documentation mentions the following.https://docs.microsoft.com/en-us/azure/network-watcher/connection-monitor-overviewhttps://docs.microsoft.com/en-us/learn/modules/troubleshoot-azure-network-infrastructure/2-troubleshoot-networking-with-network-watcher
A. Make the virtual machines part of an availability set.B. Deploy the virtual machines across availability zones.rightC. Assign a standard public IP address to the virtual machines.D. Deploy single virtual machines across multiple regions.
10/5/25, 15:20LMS | Whizlabs
Page 24 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Option A is incorrect since availability sets can only guarantee an SLA of 99.95%.Option C is incorrect since this will not help ensure 99.99% availability for the architecture.Option D is incorrect since this is normally used for disaster recovery purposes.For more information on availability zones, please visit the below URL-Ask our ExpertsDid you like this Question?Question 18Domain: Implement and manage storageYour company wants to provision an Azure storage account. The storage account needs to meet the following requirements.
You need to complete the below command to create the storage account.https://docs.microsoft.com/en-us/azure/availability-zones/az-overview
Should be able to support hot, cool, and archive blob tiers.Should be able to provide fault tolerance if a disaster hits the Azure region, which has the storage account.Should minimize on costs.
10/5/25, 15:20LMS | Whizlabs
Page 25 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot1?
Explanation:Answer – CThe task requires to support the Hot, Cool, and Archive tiers. There is only one option from our list of options that can provide this:StorageV2 or General Purpose v2 Storage Account. With this storage account type, we will have the complete functionality of the BLOBservice.A. FileStorageB. StorageC. StorageV2rightD. TableE. BlockBlobStoragewrong
10/5/25, 15:20LMS | Whizlabs
Page 26 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
Option A is incorrect since it does not support the access tiers.Option B is incorrect since it does not support the access tiers.Option D is incorrect since this is a service and not a storage account kind.Option E is incorrect since it does not support the access tiers.For more information on storage accounts, please visit the below URL-Ask our ExpertsDid you like this Question?Question 19Domain: Implement and manage storageYour company wants to provision an Azure storage account. The storage account needs to meet the following requirements.https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview
Should be able to support hot, cool, and archive blob tiers.Should be able to provide fault tolerance if a disaster hits the Azure region, which has the storage account.Should minimize on costs.
10/5/25, 15:20LMS | Whizlabs
Page 27 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
You need to complete the below command to create the storage account.
Which of the following would go into Slot2?
Explanation:Answer – AStandard_GRS, which is geo-redundant storage would ensure that data is available in a secondary region if the primary region goesdown.The Microsoft documentation mentions the following.A. Standard_GRSrightB. Standard_LRSC. Standard_RAGRSD. Premium_LRS
10/5/25, 15:20LMS | Whizlabs
Page 28 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Options B and D are incorrect since these don’t guarantee that data will be available if a region goes down.Option C is incorrect since the costs would be more than Standard_GRS.For more information on geo-redundant storage, please visit the below URL-Ask our ExpertsDid you like this Question?Question 20Domain: Monitor and maintain Azure resourcesCurrently, in your production environment, containerized applications are running on the Azure Kubernetes Service cluster (AKScluster). Managed disks, for persistent storage, are being used. Currently, managed disk backup is being done via automation scripts.The scripts are hard to maintain. You're working as an Azure administrator, and are expected to suggest a backup solution formanaging disk, with the following requirements:1. It should support snapshot backup lifecycle which is policy-driven and provide fast backup and recovery  2. It should have a very light admin overhead. 3. The cost of the overall solution is low https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy-grs
10/5/25, 15:20LMS | Whizlabs
Page 29 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following solutions will you select? 
Explanation:Correct Answers: B and D 
Azure backup vault supports manage disk snapshot backup lifecycle, which is policy-driven and provides fast backup and recoveryfrom the snapshot of managed disk. The backup process of the backup vault does not cause any performance issues on the virtual machine. It has virtually noadministrative overhead and low cost.  We can easily create a backup vault from the backup center.Backup Center provides a single unified management experience in Azure for enterprises to govern, monitor, operate and analysebackups at scale. The following figure shows how a backup vault can be created from the backup centerA. Azure recovery service vault B. Azure Backup vault rightC. Azure site recovery wrongD. Azure Backup Center right
Option B is correct because a backup vault can be used for managing Azure disk snapshot life cycle management, as explainedlater.Option D is correct because the backup center is the best option for creating the backup vault Option A is incorrect because the recovery service, vault, does not support, disk snapshot life cycle management. Option C is incorrect because Azure site recovery is used for creating disaster recovery sites. 
10/5/25, 15:20LMS | Whizlabs
Page 30 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
For more details, please refer to the following Azure documentation link https://docs.microsoft.com/en-us/Azure/backup/disk-backup-overview https://docs.microsoft.com/en-us/Azure/backup/backup-center-overview
10/5/25, 15:20LMS | Whizlabs
Page 31 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectAsk our ExpertsDid you like this Question?Question 21Domain: Monitor and maintain Azure resourcesA team has set up Log Analytics for a virtual machine named demovm. They are running the following query in the Log AnalyticsWorkspace.Perf| where Computer == "demovm"| where ObjectName == "Processor" and CounterName == "% Processor Time"| summarize avg(CounterValue) by bin(TimeGenerated, 1h), Computer| render timechartIn which of the following formats will the data be displayed?
Explanation:Answer – DTo determine the format in which the data will be displayed, we need to understand the structure of the query being run in the LogAnalytics Workspace.1. Table with 2 Columns:Perf| where TimeGenerated > ago(1h)| project Computer, CounterValueOutput: A table with columns Computer and CounterValue2. Table with 3 Columns:A. table that has 2 columnswrongB. table that has 3 columnsC. graph that has the Computer values on the Y axisD. graph that has the avg(CounterValue) values on the Y axisright
If the query selects two specific fields, the result will be a table with two columns.Example Query:
If the query selects three specific fields, the result will be a table with three columns.
10/5/25, 15:20LMS | Whizlabs
Page 32 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectPerf| where TimeGenerated > ago(1h)| project Computer, CounterName, CounterValueOutput: A table with columns Computer, CounterName, and CounterValue.3. Graph with Computer Values on the Y Axis:Perf| where TimeGenerated > ago(1h)| summarize avg(CounterValue) by Computer| render barchartOutput: A graph (e.g., bar chart) with Computer values on the Y axis.4. Graph with avg(CounterValue) Values on the Y Axis:Perf| where TimeGenerated > ago(1h)| summarize avg(CounterValue) by Computer| render timechartOutput: A graph (e.g., time chart) with avg(CounterValue) values on the Y axis.Without the specific query, the most likely answer based on common usage patterns in Log Analytics is graph that has theavg(CounterValue) values on the Y axisThis is because queries often involve summarizing performance metrics and visualizing them over time or by different dimensions.For more information on performing log queries, please visit the URL below-Ask our ExpertsDid you like this Question?Question 22Domain: Deploy and manage Azure compute resourcesYou have a virtual machine (VM) named myVM that is using Azure Disk Encryption and is currently located in the resource groupoldResourceGroup in the region eastus. You need to recreate this VM in a different region (westus) and resource groupExample Query:
If the query is designed to visualize data with Computer values on the Y axis, it typically involves a summarization or aggregation.Example Query:
If the query is designed to visualize data with avg(CounterValue) on the Y axis, it involves summarization or aggregation.Example Query:
https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/log-query-overview
10/5/25, 15:20LMS | Whizlabs
Page 33 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
(newResourceGroup), since encrypted VMs cannot be moved across regions directly.Using the Azure CLI, arrange the following steps in the correct order to achieve this:
Explanation:Correct Answer: B, D, A, and CA virtual machine that is integrated with a key vault to implement Azure Disk Encryption for Linux VMs or Azure Disk Encryption forWindows VMs can be moved to another resource group when it is in a deallocated state.However, to move such a virtual machine to another subscription, you must disable encryption.To move a virtual machine (VM) named "myVM" to a different resource group, subscription, and region using the Azure CLI, here is thecorrect order of steps:The correct order of steps is B, D, A & C.
Reference:Ask our ExpertsDid you like this Question?Your Answer1.A. az vm wait --name myVM --resource-groupoldResourceGroup --deleted2.B. az vm deallocate --name myVM --resource-group oldResourceGroup3.D. az group create --namenewResourceGroup --location newRegion4.C. az vm create --name myVM --resource-group newResourceGroup --locationnewRegion --source oldResourceGroupCorrect Answer1.B. az vm deallocate --name myVM --resource-group oldResourceGroup2.D. az group create --namenewResourceGroup --location newRegion3.A. az vm wait --name myVM --resource-group oldResourceGroup --deleted4.C. az vm create --name myVM --resource-group newResourceGroup --locationnewRegion --source oldResourceGroup
B. az vm deallocate --name myVM --resource-group oldResourceGroup : Stop the VM in the old resource group.D. az group create --name newResourceGroup --location newRegion: Create a new resource group in the desired region.A. az vm wait --name myVM --resource-group oldResourceGroup --deleted: Wait for the VM to be deleted from the old resourcegroup.C. az vm create --name myVM --resource-group newResourceGroup --location newRegion --source oldResourceGroup : Movethe VM to the new resource group and region.Move Azure VMs to new subscription or resource group - Azure Resource Manager | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 34 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
CorrectQuestion 23Domain: Deploy and manage Azure compute resourcesWhen managing virtual machine disks in Azure, which of the following options allows you to increase the size of a virtual hard disk(VHD) without detaching it from the virtual machine?
Explanation:Correct Answer: DAzure Managed Disks provide a convenient way to manage virtual machine disks. With Azure Managed Disks, you can easily increasethe size of a virtual hard disk (VHD) without detaching it from the virtual machine. This scalability feature allows you to adjust thestorage capacity as needed without disrupting the VM's operation.
Reference:Ask our ExpertsDid you like this Question?Question 24Domain: Deploy and manage Azure compute resourcesWhizlabs Corporation is looking to deploy containerized applications in Azure and needs a container registry to store their Dockerimages. Which of the following Azure service provides a private and secure repository for storing Docker container images?A. Azure Blob StorageB. Azure Disk EncryptionC. Azure Virtual Disk ResizewrongD. Azure Managed Disksright
Option A is incorrect because Azure Blob Storage is primarily used for unstructured data storage and is not directly related toresizing virtual machine disks.Option B is incorrect because Azure Disk Encryption is a security feature for encrypting virtual machine disks and does not offerdisk resizing capabilities.Option C is incorrect because there is no specific "Azure Virtual Disk Resize" feature. The resizing of virtual disks is typicallymanaged through Azure Managed Disks.Option D is correct because Azure managed disks can be resized by changing the configuration of the disk.Expand virtual hard disks attached to a Windows VM in an Azure - Azure Virtual Machines | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 35 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Correct Answer: CAzure Container Registry (ACR) is a private and secure repository for storing Docker container images. It allows organizations tomanage and distribute container images securely, making it an essential service for containerized applications in Azure.
References:
Ask our ExpertsDid you like this Question?Question 25Domain: Manage Azure identities and governanceA company has set up an Azure subscription. They have provisioned a storage account and are currently using the BLOB service. Theywant to assign permissions to 3 user groups.A. Azure Kubernetes Service (AKS)B. Azure Container Instances (ACI)C. Azure Container Registry (ACR)rightD. Azure Container Service (ACS)
Option A is incorrect because Azure Kubernetes Service (AKS) is a managed Kubernetes container orchestration service, not acontainer registry.Option B is incorrect Azure Container Instances (ACI) is a serverless container service for running containers, but it does notprovide container image storage.Option C is correct because Azure Container Registry (ACR) is a private and secure repository for storing Docker containerimages. It allows organizations to manage and distribute container images securely, making it an essential service forcontainerized applications in Azure.Option D is incorrect because Azure Container Service (ACS) is an older service that has been deprecated in favor of AzureKubernetes Service (AKS) for managing Kubernetes clusters.Azure Container Registry | Microsoft AzureManaged container registries - Azure Container Registry | Microsoft Learn
GroupA – This group should have the ability to manage the storage account.GroupB – This group should be able to manage containers within a storage account.GroupC – This group should be given full access to Azure Storage blob containers and data, including assigning POSIX access
10/5/25, 15:20LMS | Whizlabs
Page 36 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
You need to assign the relevant Role-Based Access Control, ensuring the privilege of least access.Which of the following would you assign to GroupA?
Explanation:Answer – CThis can be accomplished by the Storage Account Contributor.The Microsoft documentation mentions the following.
Options A and B are incorrect since these would provide more permissions than required.Options D and E are incorrect since these roles don’t have the required permissions.For more information on built-in roles, please visit the below URL-control.
A. OwnerB. ContributorC. Storage Account ContributorrightD. Storage Blob Data ContributorE. Storage Blob Data Owner
10/5/25, 15:20LMS | Whizlabs
Page 37 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectAsk our ExpertsDid you like this Question?Question 26Domain: Manage Azure identities and governanceA company has set up an Azure subscription. They have provisioned a storage account and are currently using the BLOB service. Theywant to assign permissions to 3 user groups.
You need to assign the relevant Role-Based Access Control, ensuring the privilege of least access.Which of the following would you assign to GroupB?
Explanation:Answer – DThis can be accomplished with the Storage Blob Data Contributor.The Microsoft documentation mentions the following.https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
GroupA – This group should have the ability to manage the storage account.GroupB – This group should be able to manage containers within a storage account.GroupC – This group should be given full access to Azure Storage blob containers and data, including assigning POSIX accesscontrol.
A. OwnerB. ContributorC. Storage Account ContributorD. Storage Blob Data ContributorrightE. Storage Blob Data Owner
10/5/25, 15:20LMS | Whizlabs
Page 38 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Options A and B are incorrect since these would provide more permissions than required.Options C and E are incorrect since these roles don’t have the required permissions.For more information on built-in roles, please visit the below URL-Ask our ExpertsDid you like this Question?Question 27Domain: Manage Azure identities and governanceA company has set up an Azure subscription. They have provisioned a storage account and are currently using the BLOB service. Theywant to assign permissions to 3 user groups.
You need to assign the relevant Role-Based Access Control, ensuring the privilege of least access.https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
GroupA – This group should have the ability to manage the storage account.GroupB – This group should be able to manage containers within a storage account.GroupC – This group should be given full access to Azure Storage blob containers and data, including assigning POSIX accesscontrol.
10/5/25, 15:20LMS | Whizlabs
Page 39 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would you assign to GroupC?
Explanation:Answer – EThis can be accomplished with the Storage Blob Data Owner. The Microsoft documentation mentions the following.
Options A and B are incorrect since these would provide more permissions than required.Options C and D are incorrect since these roles don’t have the required permissions.For more information on built-in roles, please visit the below URL-Ask our ExpertsA. OwnerwrongB. ContributorC. Storage Account ContributorD. Storage Blob Data ContributorE. Storage Blob Data Ownerright
https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
10/5/25, 15:20LMS | Whizlabs
Page 40 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectDid you like this Question?Question 28Domain: Manage Azure identities and governanceA company is planning to use the Azure Import/Export service to move data out of its Azure Storage account. Which of the followingservice could be used when defining the Azure Export job?
Explanation:Answer – AOnly the BLOB service is supported by the Export job feature. This is also given in the Microsoft documentation.
Since this is clearly mentioned, all other options are incorrect.For more information on Azure import/export requirements, please visit the below URL-A. BLOB storagerightB. File storageC. Queue storagewrongD. Table storage
10/5/25, 15:20LMS | Whizlabs
Page 41 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectAsk our ExpertsDid you like this Question?Question 29Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to add data disks to an existing virtual machine. Below is the incomplete script.
Which of the following would go into Slot1?
Explanation:Answer – BAn example of this is given in the Microsoft documentation.https://docs.microsoft.com/en-us/azure/storage/common/storage-import-export-requirements
A. New-AzDiskwrongB. New-AzDiskConfigrightC. Add-AzVMDataDiskD. Set-AzDisk
10/5/25, 15:20LMS | Whizlabs
Page 42 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on managing data disk, please visit the below URL-Ask our ExpertsDid you like this Question?Question 30Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to add data disks to an existing virtual machine. Below is the incomplete script.
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
10/5/25, 15:20LMS | Whizlabs
Page 43 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot2?
Explanation:Answer - AAn example of this is given in the Microsoft documentation.
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on managing data disk, please visit the below URL-Ask our ExpertsDid you like this Question?A. New-AzDiskrightB. New-AzDiskConfigC. Add-AzVMDataDiskwrongD. Set-AzDisk
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
10/5/25, 15:20LMS | Whizlabs
Page 44 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectQuestion 31Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to be used to add data disks to an existing virtual machine. Below is theincomplete script.
Which of the following would go into Slot3?
Explanation:Answer – CAn example of this is given in the Microsoft documentation.A. Set-AzVMB. UpdateAzVMwrongC. Get-AzVMrightD. New-AzVM
10/5/25, 15:20LMS | Whizlabs
Page 45 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on managing data disk, please visit the below URL-Ask our ExpertsDid you like this Question?Question 32Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to be used to add data disks to an existing virtual machine. Below is theincomplete script.https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
10/5/25, 15:20LMS | Whizlabs
Page 46 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot 4?
Explanation:Correct Answer - COption C is correct because Add-AzVMDataDisk is the appropriate command to attach a data disk to an existing virtual machine. Itallows specifying the virtual machine, data disk, and parameters like LUN and CreateOption. This matches the context of Slot 4 inthe script.An example of this is given in the Microsoft documentation.A. New-AzDiskB. New-AzDiskConfigwrongC. Add-AzVMDataDiskrightD. Set-AzDisk
10/5/25, 15:20LMS | Whizlabs
Page 47 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Since this is given in the Microsoft documentation, all other options are incorrect.Option A is incorrect because New-AzDisk is used to create a new managed disk in Azure, not to attach a data disk to an existingvirtual machine. In this scenario, the disk has already been created, so this command is unnecessary.Option B is Incorrect because New-AzDiskConfig is used to create a configuration object for a new disk. While it is part of the processto define a disk, it does not act to attach the disk to a virtual machine.Option D is incorrect because Set-AzDisk is used to update the properties of an existing managed disk in Azure. It does not attach adata disk to a virtual machine, which is the required action for this scenario.Reference:Ask our ExpertsDid you like this Question?Question 33Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to be used to add data disks to an existing virtual machine. Below is theincomplete script.https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
10/5/25, 15:20LMS | Whizlabs
Page 48 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot5?
Explanation:Correct Answer – BThe Update-AzVM cmdlet is used to apply changes to an existing virtual machine after modifications have been made, such asadding a data disk. This ensures that the changes are saved and the VM configuration is updated accordingly
Option A is incorrect. Set-AzVM: This cmdlet is used to set the properties of a virtual machine object in memory. It does not applyA. Set-AzVMwrongB. Update-AzVMrightC. Get-AzVMD. New-AzVM
10/5/25, 15:20LMS | Whizlabs
Page 49 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correctchanges to the actual VM in Azure. It is typically used in conjunction with other cmdlets to build a VM configuration before creating orupdating the VM.Option C is incorrect. Get-AzVM: This cmdlet retrieves information about an existing virtual machine. It is used to get the current stateand properties of a VM but does not apply any changes to the VM.Option D is incorrect. New-AzVM: This cmdlet is used to create a new virtual machine. It is not applicable for updating an existing VMwith additional data disks.For more information on managing data disks, please visit the below URL-Ask our ExpertsDid you like this Question?Question 34Domain: Deploy and manage Azure compute resourcesYou have an Azure virtual machine based on the Windows Server 2016 image. You implement Azure backup for the virtual machine.You want to restore the virtual machine by using the Replace existing option.You need to go ahead and replace the virtual machine using the Azure Backup option. You have started the backup operation but itfailed and is showing an error message: VM is not in a state to allow backups.Which of the following should be done to solve this problem?
Explanation:Correct Answer – BThe backup operation failed because the VM is in Failed state. For a successful backup, the VM state should be Running, Stopped, orStopped (deallocated).https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
A. Create a custom image.B. Stop the virtual machine.rightC. Allocate a new disk.D. Enable encryption on the disk.
10/5/25, 15:20LMS | Whizlabs
Page 50 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
Reference:Troubleshoot backup errors with Azure VMs - Azure Backup | Microsoft LearnAsk our ExpertsDid you like this Question?Question 35Domain: Manage Azure identities and governanceYou have an Azure subscription named whizlabstaging. Under the subscription, you create a resource group named whizlabs-rg.Then you create an Azure policy based on the “Not allowed resources types” definition. Here you define the parameters asMicrosoft.Network.virtual networks as the not allowed resource type. You assign this policy to the Tenant Root Group and a VirtualNetwork does not already exist in this subscription.Would you be able to create a virtual machine in the whizlabs-rg resource group?A. YesB. Noright
10/5/25, 15:20LMS | Whizlabs
Page 51 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer — BAzure policy is applied to the Tenant Root Group. It means that it would be applied to all subscriptions and all resource groups withinthe subscription. A VM can be created only inside a network. If you need to create a virtual machine, you must have permission tocreate virtual network resources, required for VM provisioning. This policy “not allowed resources type" includes Microsoft.Network in its parameter list. So the policy will not allow the creation of anynetwork resources. So, B is the correct answer. For more information on creating Azure Policies, please visit the below URL:Ask our ExpertsDid you like this Question?Question 36Domain: Implement and manage virtual networkingA company currently has the following networks defined in Azure.NameAddress spacewhizlab-vnet110.1.0.0/16whizlab-vnet210.2.0.0/16whizlab-vnet310.3.0.0/16All virtual networks are hosting virtual machines with varying workloads. A virtual machine named whizlab-detect hosted in whizlab-vnet2. This virtual machine will have an intrusion detection software installed on it. All traffic on all virtual networks must be routed viathis virtual machine.You need to complete the required steps for implementing this requirement.You are going to create the virtual network peering connection for all of the virtual networks. Which of the following is important to setfor the virtual network peering connection?https://docs.microsoft.com/en-us/azure/governance/policy/overview
10/5/25, 15:20LMS | Whizlabs
Page 52 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Explanation:Correct Answer – CTo ensure that traffic can be forwarded across networks, you need to enable forwarded traffic settings.This is like the Hub and spoke model given in the Microsoft documentation wherein you need to enable forwarded traffic.
Option A is incorrect. The Classic deployment model is outdated and not recommended for new deployments. Azure ResourceManager (ARM) is the preferred deployment model, offering more features and better management capabilitiesA. Set the virtual network deployment model as Classic.B. Set the virtual network access settings as Disabled.C. Set the forwarded traffic settings as Enabled.rightD. Enable “Allow gateway transit”.
10/5/25, 15:20LMS | Whizlabs
Page 53 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectOption B is incorrect. Disabling virtual network access would prevent any communication between the virtual networks, whichcontradicts the requirement to route all traffic through the whizlab-detect VM.Option D is incorrect This setting is used to allow a virtual network to use a VPN gateway in a peered virtual network. It is not relevant tothe requirement of routing all traffic through a specific VM for intrusion detection.For more information on the hub-spoke setup, please visit the below URL-Ask our ExpertsDid you like this Question?Question 37Domain: Implement and manage virtual networkingA company currently has the following networks defined in Azure.NameAddress spacewhizlab-vnet110.1.0.0/16whizlab-vnet210.2.0.0/16whizlab-vnet310.3.0.0/16All virtual networks are hosting virtual machines with varying workloads. A virtual machine named whizlab-detect hosted in whizlab-vnet2. This virtual machine will have an intrusion detection software installed on it. All traffic on all virtual networks must be routed viathis virtual machine(intrusion-based device).You need to complete the required steps for implementing this requirement.Which of the following would you need to create additional to ensure that traffic is sent via the virtual machine hosting the intrusionsoftware?https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/hybrid-networking/hub-spoke
A. A new route tablerightB. Add an address spaceC. Add DNS servers
10/5/25, 15:20LMS | Whizlabs
Page 54 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer – AIn order to ensure that traffic is routed via the intrusion-based device, you need to set up a route table and add the route table to thesubnets in the other virtual networks.The diagram of the hub and spoke model also includes the use of a User-defined route (UDR), which is nothing but a custom routetable.
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on working with route tables, please visit the below URLs-
Ask our ExpertsDid you like this Question?Question 38D. Add a service endpoint
https://docs.microsoft.com/en-us/azure/virtual-network/tutorial-create-route-table-portalhttps://docs.microsoft.com/en-us/azure/virtual-wan/scenario-route-through-nva
10/5/25, 15:20LMS | Whizlabs
Page 55 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Domain: Implement and manage virtual networkingA company currently has the following networks defined in Azure.NameAddress spacewhizlab-vnet110.1.0.0/16whizlab-vnet210.2.0.0/16whizlab-vnet310.3.0.0/16All virtual networks are hosting virtual machines with varying workloads. A virtual machine named whizlab-detect is hosted inwhizlab-vnet2. This virtual machine will have an intrusion detection software installed on it. All traffic on all virtual networks must berouted via this virtual machine(intrusion-based device)You need to complete the required steps for implementing this requirement.Which of the following needs to be enabled on the virtual machine whizlab-detect?
Explanation:Answer - AIn order to ensure traffic can be forwarded, you need to enable IP forwarding. An example of this is given in the Microsoftdocumentation.A. Enable IP forwarding.rightB. Enable the identity for the virtual machine.C. Add an extension to the virtual machine.D. Change the size of the virtual machine.
10/5/25, 15:20LMS | Whizlabs
Page 56 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
 
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on working with route tables, please visit the below URL-https://docs.microsoft.com/en-us/azure/virtual-network/tutorial-create-route-table-portal
10/5/25, 15:20LMS | Whizlabs
Page 57 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
CorrectAsk our ExpertsDid you like this Question?Question 39Domain: Manage Azure identities and governanceA company is planning to use Azure for the various services they offer. They want to ensure that they can bill each department for theresources they consume. They decide to use Azure policies to separate the bills department wise.Would this fulfill the requirement?
Explanation:Answer – BAzure policies are used from a governance perspective and can’t be used to create bills department wise.For more information on Azure policies, please visit the below URL-Ask our ExpertsDid you like this Question?Question 40Domain: Manage Azure identities and governanceA company is planning to use Azure for the various services they offer. They want to ensure that they can bill each department for theresources they consume. They decide to use Azure resource tags to separate the bills department wise.Would this fulfill the requirement?A. YesB. Noright
https://docs.microsoft.com/en-us/azure/governance/policy/overview
A. YesrightB. No
10/5/25, 15:20LMS | Whizlabs
Page 58 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer – AYes, you can use resource tags to organize your Azure resources and also apply billing techniques department wise. The Microsoftdocumentation mentions the following.
For more information on tagging resources, please visit the below URLs-
Ask our ExpertsDid you like this Question?Question 41Domain: Manage Azure identities and governanceA company is planning to use Azure for the various services they offer. They want to ensure that they can bill each department for theresources they consume. They decide to use Azure role-based access control to separate the bills department wise.https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/tag-resourceshttps://docs.microsoft.com/en-us/azure/cloud-adoption-framework/decision-guides/resource-tagging/?toc=/azure/azure-resource-manager/management/toc.json
10/5/25, 15:20LMS | Whizlabs
Page 59 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectWould this fulfill the requirement?
Explanation:Answer – BThis is used to control access to resources and can’t be used for billing purposes.For more information on Role-based access control, please visit the below URL-Ask our ExpertsDid you like this Question?Question 42Domain: Manage Azure identities and governanceYour company uses Azure Virtual Machines for its enterprise applications. You need to use Azure Policy to do some of the morecommon tasks related to creating, assigning, and managing policies across your organization. You can create a policy with the RESTAPI for Azure Policy Definitions. The REST API allows you to create and delete policy definitions and get information about existingdefinitions.Is this statement correct? [Select Yes or No]
Explanation:Correct Answer – AThe statement is correct. The REST API for Azure Policy Definitions allows you to create, delete, and get information about policydefinitions. It also enables you to create, assign, and manage policies across your organization.Reference: Tutorial: Build policies to enforce compliance - Azure Policy | Microsoft LearnAzure REST API reference documentation | Microsoft LearnA. YesB. Noright
https://docs.microsoft.com/en-us/azure/role-based-access-control/overview
A. YesrightB. Nowrong
10/5/25, 15:20LMS | Whizlabs
Page 60 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectAsk our ExpertsDid you like this Question?Question 43Domain: Manage Azure identities and governanceA company has the following resources deployed to their Azure subscription.NameTypeResource Groupwhizlab-vnet1Virtual Networkwhizlabs-rgwhizlab-vnet2Virtual Networkwhizlabs-rgwhizlabvmVirtual machinewhizlabs-rg The virtual machine whizlabvm is currently in a running state.The company now assigns the below Azure policy. 
 
10/5/25, 15:20LMS | Whizlabs
Page 61 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
The Not Allowed resources types areWould the state of the virtual machine change to deallocated?
Explanation:Correct Answer – BAzure policies would only highlight the compliance of existing resources and enforce the policy restrictions on new resources.Here, the virtual machine whizlabvm is currently in a running state, and the company assigns the "Not allowed resource types Azurepolicy" Not allowed resource types (Deny): Prevents a list of resource types from being deployed.Hence the state of the virtual machine would remain as it is.For more information on Azure policies, please visit the below URL-
Ask our ExpertsDid you like this Question?Question 44Domain: Manage Azure identities and governanceMicrosoft.Network/virtualNetworksMicrosoft/Compute/virtualMachinesA. YeswrongB. Noright
Overview of Azure Policy - Azure Policy | Microsoft Docs1Overview of Azure Policy - Azure Policy | Microsoft Docs2
10/5/25, 15:20LMS | Whizlabs
Page 62 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
A company has the following resources deployed to their Azure subscription.NameTypeResource Groupwhizlab-vnet1Virtual Networkwhizlabs-rgwhizlab-vnet2Virtual Networkwhizlabs-rgwhizlabvmVirtual machinewhizlabs-rg The virtual machine whizlabvm is currently running.The company now assigns the below Azure policy.
 
The Not Allowed resources types areWould an administrator be able to modify the address space of whizlab-vnet2?Microsoft.Network/virtualNetworksMicrosoft/Compute/virtualMachines
10/5/25, 15:20LMS | Whizlabs
Page 63 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectExplanation:Answer – BAzure Policy: "Not Allowed Resource Types"The policy blocks:Microsoft.Network/virtualNetworks → affects virtual networksMicrosoft.Compute/virtualMachines → affects virtual machinesThis means any operation that involves creating, updating, or modifying these resource types is denied, even if the resources alreadyexist.Changing the address space of a virtual network is considered a modification to Microsoft.Network/virtualNetworks resource type.Since this type is explicitly disallowed by the policy, no changes can be made even by an administrator.Azure policies apply at the subscription or resource group level, and they enforce compliance by blocking actions that violate therules.The policy doesn’t just prevent the creation of new virtual networks or VMs; it also blocks updates to existing ones.Even though whizlab-vnet2 already exists, modifying its configuration (like address space) is treated as an update and is thereforenot permitted.For more information on Azure policies, please visit the URL below-Ask our ExpertsDid you like this Question?Question 45Domain: Implement and manage storageA team is currently storing all of their objects in an Azure storage account. They are using the Azure Blob service. They want to create alifecycle management rule that would do the following.The Lifecycle rule would be applied to a container called demo and a folder within the container called data.You have to complete the following JSON snippet for the Lifecycle rule.A. YeswrongB. Noright
https://docs.microsoft.com/en-us/azure/governance/policy/overview
Change the objects' tier level to the cool tier if they have not been modified in the past 30 days.Archive an object if they have not been modified in the past 90 days.
10/5/25, 15:20LMS | Whizlabs
Page 64 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot1?
Explanation:Answer – DThe format of the prefixMatch is container/folder: demo/data. An example of this is given in the Microsoft documentation.
A. demowrongB. dataC. data/demoD. demo/dataright
10/5/25, 15:20LMS | Whizlabs
Page 65 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectSince this is clearly mentioned in the Microsoft documentation, all other options are invalid.For more information on lifecycle management rules, please visit the below URL-Ask our ExpertsDid you like this Question?Question 46Domain: Implement and manage storageA team is currently storing all of their objects in an Azure storage account. They are using the Azure Blob service. They want to create alifecycle management rule that would do the following.The Lifecycle rule would be applied to a container called demo and a folder within the container called data.You have to complete the following JSON snippet for the Lifecycle rule.
Which of the following would go into Slot2?
Explanation:https://docs.microsoft.com/en-us/azure/storage/blobs/storage-lifecycle-management-concepts
Change the objects' tier level to the cool tier if they have not been modified in the past 30 days.Archive an object if they have not been modified in the past 90 days.
A. 15B. 30rightC. 90D. 120
10/5/25, 15:20LMS | Whizlabs
Page 66 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectAnswer – BSince the question states that we need to move the objects to the cool tier after 30 days, this should be the value for tierToCool.
An example of this is given in the Microsoft documentation.Since this is clearly mentioned in the Microsoft documentation, all other options are invalid.For more information on lifecycle management rules, please visit the below URL-Ask our ExpertsDid you like this Question?Question 47Domain: Implement and manage storageA team is currently storing all of their objects in an Azure storage account. They are using the Azure Blob service. They want to create alifecycle management rule that would do the following.https://docs.microsoft.com/en-us/azure/storage/blobs/storage-lifecycle-management-concepts
Change the objects' tier level to the cool tier if they have not been modified in the past 30 days.Archive an object if they have not been modified in the past 90 days.
10/5/25, 15:20LMS | Whizlabs
Page 67 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
The Lifecycle rule would be applied to a container called demo and a folder within the container called data.You have to complete the following JSON snippet for the Lifecycle rule.
Which of the following would go into Slot3?
Explanation:Answer – CSince the question states that we need to move the objects to the archive tier after 90 days, this should be the value fortierToArchive.A. 15B. 30C. 90rightD. 120
10/5/25, 15:20LMS | Whizlabs
Page 68 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
Since this is clearly mentioned in the Microsoft documentation, all other options are invalid.For more information on lifecycle management rules, please visit the below URL-Ask our ExpertsDid you like this Question?Question 48Domain: Implement and manage storageA team is currently making use of an Azure storage account as shown below
https://docs.microsoft.com/en-us/azure/storage/blobs/storage-lifecycle-management-concepts
10/5/25, 15:20LMS | Whizlabs
Page 69 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
A file named audio.log has been uploaded to a container called demo.Which of the following is a valid URL that could be used to access the file?
Explanation:Answer – CThe URL of the accessing an object must be https://<storageAccountName>.blob.core.windows.net /<containerName>/<objectName>:https://whizlabstore.blob.core.windows.net/demo/audio.logThe Microsoft documentation mentions the following on the format of the URL for blob objects.
Since this is clearly mentioned in the Microsoft documentation, all other options are invalid.For more information on the blob service, please visit the below URLA. https://whizlabstore/demo/audio.logB. https://whizlabstore.blob.core.windows.net/audio.logC. https://whizlabstore.blob.core.windows.net/demo/audio.logrightD. https://whizlabstore/audio.log
https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction
10/5/25, 15:20LMS | Whizlabs
Page 70 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectAsk our ExpertsDid you like this Question?Question 49Domain: Implement and manage storageA team is currently making use of an Azure storage account, as shown below.
A file named audio.log has been uploaded to a container called demo.You need to allow users to download the object. The access should be granted for a day only. You need to provide a secure way toaccess the object. Which of the following would you implement for this purpose?
Explanation:Answer – CThe secure way to implement this is to generate a shared access signature. The Microsoft documentation mentions the following.A. Provide access Keys.B. Mark public access on the container.C. Generate a shared access signature.rightD. Mark public access on the object.wrong
10/5/25, 15:20LMS | Whizlabs
Page 71 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
All of the other ways are incorrect since they don’t provide secure access to the storage account object.For more information on Shared access signatures, please visit the below URL-Ask our ExpertsDid you like this Question?Question 50Domain: Manage Azure identities and governanceA company currently has a set of Azure virtual machines. They want to ensure that their IT administrative team gets alert when any ofthe virtual machines are shut down.They decide to create alerts based on Activity Logs in Azure Monitor.Would this fulfill the requirement?https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview
A. YesrightB. No
10/5/25, 15:20LMS | Whizlabs
Page 72 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer – AThe Activity Log service provides insights for all resource activities within your subscription. An example of events recorded is shownbelow.
You can create alerts based on the Activity logs.For more information on Azure activity logs, please visit the below URLs-Ask our ExpertsDid you like this Question?Question 51Domain: Manage Azure identities and governanceA company currently has a set of Azure virtual machines. They want to ensure that their IT administrative team gets alert when any ofthe virtual machines are shut down.They decide to create alerts in the Azure Advisor service.https://docs.microsoft.com/en-us/azure/azure-monitor/platform/activity-log
10/5/25, 15:20LMS | Whizlabs
Page 73 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectWould this fulfill the requirement?
Explanation:Answer – BThe Azure Advisor service is used as a recommendation engine and can’t be used to record virtual machines' activities.For more information on Azure Advisor, please visit the below URL-Ask our ExpertsDid you like this Question?Question 52Domain: Manage Azure identities and governanceA company currently has a set of Azure virtual machines. They want to ensure that their IT administrative team gets alert when anyvirtual machines are shut down.They decide to create alerts in the Service Health service.Would this fulfill the requirement?
Explanation:Answer – BThe Service Health service is used to inform users of the health of Azure-based services.For more information on Azure Service Health, please visit the below URL-A. YesB. Noright
https://docs.microsoft.com/en-us/azure/advisor/advisor-overview
A. YesB. Noright
https://azure.microsoft.com/en-us/features/service-health
10/5/25, 15:20LMS | Whizlabs
Page 74 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectView Case StudyAsk our ExpertsDid you like this Question?Question 53Domain: Implement and manage storageYou need to provision the Azure storage account. You need to complete the below Azure CLI script for this.
Which of the following would go into Slot1?
Explanation:Answer- BWe need to keep costs minimized. There is no mention in the question on Fault tolerance and disaster recovery. We can opt for LocalRedundant storage.Since this is the most cost-effective approach, all other options are incorrect.For more information on Data Redundancy, please visit the below URL-Ask our ExpertsA. Standard_GRSB. Standard_LRSrightC. Standard_RAGRSwrongD. Standard_ZRS
https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy
10/5/25, 15:20LMS | Whizlabs
Page 75 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectView Case StudyDid you like this Question?Question 54Domain: Implement and manage virtual networkingYou need to configure a VPN connection for whizlabs-net2. Which of the following would you need to configure in the virtual network?
Explanation:Answer – BFor the Virtual network, you need to have a gateway subnet.The Microsoft documentation mentions the following.
Since this is clearly mentioned in the documentation, all other options are incorrect.A. An additional address spaceB. A gateway subnetrightC. A peering connectionD. An express route connectionwrong
10/5/25, 15:20LMS | Whizlabs
Page 76 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectView Case StudyFor more information on Site-to-Site VPN connections, please visit the below URL-Ask our ExpertsDid you like this Question?Question 55Domain: Implement and manage virtual networkingYou have to ensure that users can communicate with the virtual machine whizlabapi on port number 80. You decide to create anOutbound rule in the Network Security Group associated with the virtual machine's network interface.Would this fulfill the requirement?
Explanation:Answer – BYou need to add an Inbound security rule and not an Outbound Security rule.For more information on network security, please visit the below URL-Ask our ExpertsDid you like this Question?Finish Reviewhttps://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-site-to-site-resource-manager-portal
A. YesB. Noright
https://docs.microsoft.com/en-us/azure/virtual-network/security-overview
10/5/25, 15:20LMS | Whizlabs
Page 77 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdHands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/5/25, 15:20LMS | Whizlabs
Page 1 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Incorrect
Level: AdvancedMicrosoft Azure Exam AZ-104 CertificationFree Test - Practice ModeCompleted on Mon, 15 Sep 20251stAttempt20/40Marks Obtained50.00%Your ScoreFAILResultShare this Report in Social MediaQShareDomain wise Quiz Performance ReportNo.DomainTotal QuestionCorrectIncorrectUnattemptedMarked for Review1Manage Azure identities andgovernance532002Implement and manage storage12210003Deploy and manage Azurecompute resources1274134Implement and manage virtualnetworking642015Monitor and maintain Azureresources54100TotalAll Domains40201914Review the AnswersFilter ByAll QuestionsQuestion 1Domain: Implement and manage storageHome/Dashboard/My Courses/Microsoft Azure Exam AZ-104 Certification/Free Test/ReportBack to the Courseh
Download Report
boDashboardMy CoursesHands-on LabsSandboxSupport

10/5/25, 15:20LMS | Whizlabs
Page 2 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
IncorrectView Case StudyContoso Inc. is a multinational company having offices in multiple countries. The company is planning on moving its on-premises fileservers to Azure Files.While setting up identity-based access for Azure Files, which of the following mechanisms enforces granular access control for filesand directories within a share?
Explanation:Correct Answer: A
Reference: Use Microsoft Entra Domain Services with Azure Files | Microsoft LearnAsk our ExpertsDid you like this Question?Question 2Domain: Implement and manage storageYou have been asked to transfer a 500MB set of training documents to Azure Blob Storage as part of a migration task. Which of thefollowing is the most appropriate and efficient method to complete this task?A. Microsoft Entra Domain ServicesrightB. Role-Based Access Control (RBAC)wrongC. Shared Key AuthenticationD. Virtual Network Service Endpoints
Option A is Correct This service provides managed domain services such as domain join, group policies, LDAP, and Kerberos/NTLMauthentication, which are fully compatible with Active Directory Domain Services. It allows you to configure Windows accesscontrol lists (ACLs) for fine-grained permissions at the file and directory levelOption B is incorrect because While RBAC is used to manage access to Azure resources at a broader level, it does not provide thefine-grained control needed for individual files and directories within an Azure Files share. RBAC is more suitable for controllingaccess to Azure resources like storage accounts, virtual machines, and databases.Option C is incorrect because Shared Key Authentication is a method to authenticate access to Azure Storage resources usingan account's access key securely.Option D is incorrect because Virtual Network Service Endpoints in Azure extend private network connectivity to Azure services,enabling secure access without public internet exposure, enhancing security, and reducing latency.
10/5/25, 15:20LMS | Whizlabs
Page 3 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Explanation:Correct Answer: DOption D: Use Azure Storage Explorer to upload the files directly to Azure Storage. Azure Storage Explorer is a free, GUI-based toolprovided by Microsoft that allows you to manage Azure Storage accounts. It supports drag-and-drop upload, file browsing, andaccess to blobs, file shares, queues, and tables. For transferring a small amount of data, like 500MB, it is the most efficient, simple, anduser-friendly option.
Option A: Generate a Shared Access Signature (SAS), maps the storage as a network drive, and copies the files using File Explorer isincorrect because this method involves generating a SAS token, mounting Azure File Storage as a network drive, and then using FileExplorer to copy files. While technically possible, it introduces unnecessary complexity for a one-time, small-volume transfer like500MB. It’s more suitable for scenarios that require temporary delegated access to users or applications, not for initial data uploadtasks.A. Generate a Shared Access Signature (SAS), map the storage as a network drive, and copy the files using File ExplorerB. Use the Azure Import/Export service to upload the datawrongC. Use an access key to map an Azure File Share as a drive, then copy files using File ExplorerD. Use Azure Storage Explorer to upload the files directly to Azure Storageright
Why it’s correct: No setup complexity, no scripting required, supports direct uploads with a visual interface, ideal for small-to-medium data volumes.
Why it’s wrong: Not user-friendly for one-time use, requires multiple steps, and more setup than needed for small data transfers.
10/5/25, 15:20LMS | Whizlabs
Page 4 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
IncorrectOption B: Using the Azure Import/Export service to upload the data is incorrect because the Azure Import/Export is a service designedfor very large data transfers, often in the terabyte range. It involves preparing data on physical drives and shipping them to Microsoftdata centers, which is time-consuming and costly.Option C: Use an access key to map an Azure File Share as a drive, then copy files using File Explorer is Incorrect because using anaccount key to mount an Azure File Share is useful for continuous or long-term access to Azure Files. It allows applications or users towork with Azure File Shares like regular file servers. However, it’s not the most efficient or necessary method for a small, one-time dataupload like 500MB.Final Takeaway:For ad-hoc or small-sized data uploads to Azure Storage, Azure Storage Explorer is the best combination of simplicity, speed, andusability. Other methods are either too complex or designed for different use cases (e.g., long-term access, massive data volumes). References:
Ask our ExpertsDid you like this Question?Question 3Domain: Implement and manage virtual networkingA company has deployed the following Azure Load Balancer resources to their Azure subscription  Name          SKU  whizlabload1           Basic  whizlabload2        Standard Each load balancer would have to load balance requests across three virtual machines.Why it’s wrong: Completely impractical for just 500MB; the overhead of physical disk preparation and shipping is overkill.
Why it’s wrong: Suitable for persistent drive mapping in hybrid scenarios—not optimal for quick, ad hoc uploads.
Azure Storage Explorer – cloud storage management | Microsoft AzureConnect Azure Storage Explorer to a storage account - Training | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 5 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
You want to ensure that whizlabload1 can load balance requests across the three virtual machines.Which of the following has to be implemented?
Explanation:Answer – DYou look at the comparison between the Standard and the Basic Load Balancer in the Microsoft documentation. It clearly mentionsthat the virtual machines need to be part of an availability set or a virtual machine scale set.
Since this is clearly mentioned in the documentation, all other options are incorrect.For more information on the Azure Load Balancer, please visit the following URL- A. Ensure the virtual machines are created in the different regions.B. Ensure the virtual machines are created in the same resource group.C. Ensure the virtual machines are created in the same virtual network.wrongD. Ensure the virtual machines are created in the same availability set or virtual machine scale set.right
What is Azure Load Balancer? - Azure Load Balancer | Microsoft LearnAzure Load Balancer SKUs | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 6 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectView Case StudyAsk our ExpertsDid you like this Question?Question 4Domain: Monitor and maintain Azure resourcesThe Whizbuddy app is a critical business application. You have been tasked with implementing a backup strategy to ensure dataprotection and recovery capabilities. Which of the following should you create first to begin setting up Azure Backup?
Explanation:Correct Answer: DOption D is correct because A Recovery Services vault is the first and most essential component when configuring Azure Backup. It isa storage and management container for all backup data and configurations. You need to create a vault before you can definepolicies, register virtual machines, or trigger backups. The vault stores backup metadata, recovery points, and configurations. It’sscoped per region and resource group.A. A recovery planB. An Azure Backup ServerC. A backup policyD. A Recovery Services vaultright
Why it’s correct: It’s the prerequisite for all backup activities in Azure. Without it, no backups or policies can be created.                                        
10/5/25, 15:20LMS | Whizlabs
Page 7 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
 Option A is incorrect because A recovery plan is used in Azure Site Recovery (ASR) and is designed to automate failover and failbackprocesses during a disaster. It helps organize the sequence and grouping of virtual machines during failover. However, this is not astarting point for setting up backups. Recovery plans are used after backup infrastructure (like the vault and backup policies) hasbeen configured.Option B is incorrect because Azure Backup Server (MABS) is a Microsoft-provided on-premises solution that allows backup of on-prem workloads (like file servers, VMs, SQL databases) to Azure. While MABS integrates with Azure Backup via a Recovery Services vault,it is not needed for protecting native Azure resources such as Azure VMs.Option C is incorrect because a backup policy defines the schedule and retention rules for backup jobs — i.e., what to back up, howoften, and how long to retain data. However, you cannot create or apply a backup policy until a Recovery Services vault exists toassociate it with. The vault is the container where the backup policy lives. Reference:
Why it’s wrong: It’s a disaster recovery component, not a backup prerequisite. You can’t define a recovery plan without havingbackup components already in place.Why it’s wrong: MABS is part of a hybrid or on-prem backup strategy, not required for Azure-native backups. You only need this ifyou’re backing up non-Azure infrastructure.Why it’s wrong: A backup policy is created after the Recovery Services vault. It depends on the vault for its existence andapplication.Back up Azure VMs in a Recovery Services vault - Azure Backup | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 8 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
IncorrectAsk our ExpertsDid you like this Question?Question 5Domain: Deploy and manage Azure compute resourcesYou need to increase the number of CPU cores and memory for running Azure Container Instance.What steps do you take to carry out this task?
Explanation:Correct Answers: B and EUnfortunately, Azure does not allow to scale Azure Container Instances. You need to delete the current ACI and create a new instancewith the new resource requirements. The most convenient way is to reuse and run the ARM template from the previous ACIdeployment. You can find the template under the Deployments section on the ACI’s resource group blade. When you select thedeployment template and click on the Redeploy button on the top bar, the Azure portal opens the Custom deployment screen(Number 1). Here you click on the “Edit Parameters (Number 2) and can change the number of CPU cores, memory, restart policy, etc.(Number 4). If you have not deleted the previous ACI and keep the same name for the new instance (Number 3), you will get adeployment failed error when you click on the Create button after a review.A. Stop the ACIB. Redeploy ARM ACI deployment templaterightC. In Azure portal, select the Scale up for ACI containerwrongD. Update DockerfileE. Delete the ACIright
10/5/25, 15:20LMS | Whizlabs
Page 9 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
The error status message is the following.
Therefore, you must delete the old ACI or change the name of the new ACI.All other options are incorrect.For more information about creating and updating the ACI using the ARM templates, please visit the below URLs:
10/5/25, 15:20LMS | Whizlabs
Page 10 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectView Case StudyAsk our ExpertsDid you like this Question?Question 6Domain: Implement and manage virtual networkingYou are designing the network architecture for hosting the different tiers (e.g., web application, application logic, and database) of theWhizlabs-app in Azure. How many virtual networks (VNets) would you recommend for hosting the virtual machines across these tiers,considering best practices for network isolation and security?
Explanation:Correct Answer: COption C: Deploy all VMs in a single VNet with three separate subnets is correct because the best practice for network security andisolation dictates the Azure-recommended approach for a three-tier app is to use a single VNet, divided into three subnets one foreach tier (Web, Application, Database).
       https://docs.microsoft.com/en-us/azure/container-instances/container-instances-update#properties-that-require-container-deletehttps://docs.microsoft.com/en-us/azure/container-instances/container-instances-quickstart-template
A. Deploy all VMs in a single VNet and single subnetB. Deploy VMs across two separate VNetsC. Deploy all VMs in a single VNet with three separate subnetsrightD. Deploy each tier in its own VNet
This allows for easier routing, simpler peering setup, centralized DNS, and cost efficiency.Network Security Groups (NSGs) can be scoped to each subnet, enforcing tier-specific access policies.Communication across subnets remains fast, secure, and cost-free within the VNet.
10/5/25, 15:20LMS | Whizlabs
Page 11 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Option A Deploy all VMs in a single VNet and single subnet is incorrect because using a single VNet and a single subnet for all tiersmay simplify initial deployment, but it fails to implement network segmentation. All resources are flat within the same address space,and NSG-level control becomes difficult.Option B: Deploy VMs across two separate VNets is incorrect because separating tiers across two VNets is only partial isolation.   Fora three-tier application, you’d still have at least one tier sharing a VNet, which means security controls may overlap or becomeinconsistent.Option D: Deploying each tier in its own VNet is incorrect because using three separate VNets (one per tier) is possible and offersstrong isolation, but it introduces complexity in routing, VNet peering, and troubleshooting. For most internal-tier communication (app㲗 DB), this setup is overly complex unless you have strict regulatory boundaries between tiers. References:Why it’s correct: This design balances security, manageability, and performance while avoiding unnecessary peering overhead.Why it’s wrong: Lacks isolation. Compromising one tier (e.g., web) can lead to lateral movement to more sensitive tiers (e.g.,database).Why it’s wrong: Provides only limited segmentation and doesn’t allow dedicated control for each tier.Why it’s wrong: Too complex for standard apps; adds overhead with no significant security gain compared to subnet isolationwithin a single VNet.Best practices for network security - Microsoft AzureRecommendations for networking and connectivity - Microsoft Azure Well-Architected Framework
10/5/25, 15:20LMS | Whizlabs
Page 12 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectAsk our ExpertsDid you like this Question?Question 7Domain: Deploy and manage Azure compute resourcesWhich of the following languages supports and facilitates development for deployment of all resource types and API versions available in AzurePreview and General Availability?
Explanation:Correct Answer: CBicep offers immediate compatibility with all preview and generally available (GA) versions of Azure services. Whenever a newresource type or API version is introduced by a resource provider, you can seamlessly incorporate them into your Bicep file. There's noneed to delay your utilization of new services while waiting for tool updates.
Reference:Ask our ExpertsDid you like this Question?A. KQLB. JavaC. BiceprightD. SQL
Option A is incorrect because KQL [Kusto Query Lanuguage] is used for querying against the Log Analytics Workspaces.Option B is incorrect Java JSON format files can be used for these deployments, however, supports are limited and can becomplex to write the ARM templates.Option C is correct Bicep delivers a streamlined syntax, dependable type safety, and the ability to easily reuse code. It presentsan exceptional platform for creating infrastructure-as-code solutions within the Azure environment, providing a top-tierauthoring experience.Option D is incorrect SQL is a database language and is not meant for deployment of azure resources.Bicep language for deploying Azure resources - Azure Resource Manager | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 13 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectView Case StudyQuestion 8Domain: Implement and manage virtual networkingYou are designing the network infrastructure for the Whizlabs-App, a three-tier application consisting of a web front end, anapplication middle tier, and a SQL database back end.  To ensure security and proper network segmentation, how many subnetswould you recommend within a single Virtual Network (VNet) to host the Virtual Machines for this application?
Explanation:Correct Answer: COption C: Use three subnets, one per application tier correct because this is the Azure-recommended design for a three-tierapplication. By using a single VNet divided into three subnets (Web, Application, and Database), you achieve:
Why it’s correct: This model balances security, manageability, and performance. It limits lateral movement in case of compromise,allows flexible security rules per tier, and avoids unnecessary complexity (e.g., peering).A. Use one subnet for all tiersB. Use two subnets for shared and isolated tiersC. Use three subnets, one per application tierrightD. Use four subnets to further isolate each tier
Logical isolation of each tierScoped NSG policies for fine-grained access controlEfficient traffic flow within the same VNet (low latency, no extra costs)Simplified routing, centralized DNS, and easier monitoring
10/5/25, 15:20LMS | Whizlabs
Page 14 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Option A: Use one subnet for all tiers is incorrect because putting all VMs in one subnet simplifies setup but eliminates isolationbetween application tiers. All tiers share a flat address space, making tier-specific NSG policies hard to enforce.Option B: Use two subnets for shared and isolated tiers is incorrect because this offers some isolation but falls short for a three-tierapp. For example, combining Web + App in one subnet still exposes the middle tier to external attack surfaces.Option D: Use four subnets to further isolate each tier is incorrect because more subnets mean more complexity. While advancedcases may justify this (e.g., regulatory needs), for a standard three-tier app, this adds overhead without real benefit.References:
Ask our ExpertsDid you like this Question?Why it’s wrong: One compromised tier (e.g., a vulnerable web server) could easily access others (like the database), increasingthe risk of lateral movement and breach propagation.Why it’s wrong: Security rules become less granular, and you lose the ability to apply targeted NSGs for each tier.Why it’s wrong: It complicates routing, NSG management, and diagnostics, especially if there’s no strict need for additionalsegmentation.Virtual networks and virtual machines in AzureMulti-tier web application built for HA/DR - Azure Architecture Center
10/5/25, 15:20LMS | Whizlabs
Page 15 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectQuestion 9Domain: Manage Azure identities and governanceYou have a Microsoft Entra ID tenant. You create a new user named Admin. You need to ensure that Admin can:Which Microsoft Entra built-in role should you assign to Admin?
Explanation:Correct Answer: DOption D: User Administrator is correct because the User Administrator role provides permissions to manage users and groups,including:Assign Microsoft Entra licenses to groupsReset passwords of other users in Microsoft Entra IDA. Billing AdministratorB. Helpdesk AdministratorC. License AdministratorD. User Administratorright
Resetting passwords for non-administratorsAssigning licenses to users and groupsManaging group membershipsCreating and deleting users
10/5/25, 15:20LMS | Whizlabs
Page 16 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
This role is commonly used for IT helpdesk staff or user management administrators who need broad control over identity objectsbut don’t require full admin access. Option A: Billing Administrator is incorrect because this role is focused solely on managing subscriptions, invoices, and paymentmethods in Microsoft 365 or Azure. It does not have rights to reset passwords or assign licenses.Option B: Helpdesk Administrator is incorrect because this role allows password resets, but only for non-admin users. It does notallow license assignment or group management.Option C: License Administrator is incorrect because this role allows assigning/removing licenses to users, but not to groups. It alsodoes not allow resetting user passwords.Why it’s correct: It’s the only role listed that allows both:Assigning licenses to Microsoft Entra groupsResetting user passwords (for non-admin users)
Why it’s wrong: Limited to financial tasks, not user or group management.Why it’s wrong: Meets only one requirement, resetting passwords -but not license assignment to groups.Why it’s wrong: Provides partial capability — license management for individual users, but not for groups, and lacks passwordreset permissions
10/5/25, 15:20LMS | Whizlabs
Page 17 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Incorrect
References:
Ask our ExpertsDid you like this Question?Question 10Domain: Implement and manage storageVersion-level immutability can be enabled or disabled on the storage account any point of time. Is the above statement true or false?
Explanation:Correct Answer: BVersion-level immutability cannot be disabled after it is enabled on the storage account, although locked policies can be deleted.https://learn.microsoft.com/en-us/entra/fundamentals/licensing https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/permissions-reference#user-administrator
A. TruewrongB. Falseright
10/5/25, 15:20LMS | Whizlabs
Page 18 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectReference:Ask our ExpertsDid you like this Question?Question 11Domain: Manage Azure identities and governanceYou have an Azure subscription that includes a virtual network named VNetW in the West US region. You plan to deploy the followingcontainer instances:
Which container instances can be deployed to VNetW?
Explanation:Correct Answer: DOption D: instance1 and instance2 is correct because Azure Container Instances (ACI) can be deployed into a virtual network (VNet)only if the container and the VNet are in the same region.  In this scenario:Option A is incorrect because version level immutability can be only enabled once and once enabled it cannot be disabled.Option B is correct because the statement is incorrect. Version level immutability can be only enabled once and once enabled itcannot be disabled.Configure immutability policies for blob versions - Azure Storage | Microsoft Learn
instance1, running a Windows container image in West USinstance2, running a Linux container image in West USinstance3, running a Windows container image in East USA. instance1B. instance1, instance2 and instance3C. instance1 and instance3D. instance1 and instance2rightE. instance2
instance1 (Windows, West US) instance2 (Linux, West US)
10/5/25, 15:20LMS | Whizlabs
Page 19 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Both container instances are in the West US, which matches the region of VNetW. Azure supports VNet injection for both Windows andLinux containers in most regions, including the West US.
Option A: instance1 is incorrect because this option includes only instance1, which is valid, but excludes instance2, which is also valid.Option B: instance1, instance2 and instance3 are incorrect because instance3 is in East US, while VNetW is in the West US. Azure doesnot support cross-region VNet deployment for ACI.Option C: instance1 and instance3 are incorrect because only instance1 is in the same region as VNetW. instance3 is in East US, so itcannot be deployed to a West US VNet.Option E: instance2 is incorrect because while instance2 is valid and deployable to VNetW, instance1 is also valid and should beincluded.Final Key Takeaway:Why it’s correct:Both containers are in the same region as VNetW.Azure now supports VNet integration for Linux and Windows containersThese two instances can be deployed to VNetW without issueWhy it’s wrong: It’s partially correct, but not the best answer. instance2 should also be included.Why it’s wrong: Includes instance3, which is not in the same region, making this choice invalid.Why it’s wrong: Includes a container from a different region, which breaks Azure's regional VNet constraint for ACI.Why it’s wrong: It’s incomplete, ignoring a valid Windows container in the same region.
10/5/25, 15:20LMS | Whizlabs
Page 20 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Correct
Reference:Ask our ExpertsDid you like this Question?Question 12Domain: Deploy and manage Azure compute resourcesYou are tasked with deploying Azure resources for a web application using an infrastructure-as-code approach. You have thefollowing code snippet from an Azure Bicep file:param location string = 'East US'resource appServicePlan 'Microsoft.Web/serverfarms@2022-03-01' = {  name: 'myAppServicePlan'  location: location  sku: {    name: 'P1V2'    tier: 'PremiumV2'  }}https://learn.microsoft.com/en-us/azure/container-instances/container-instances-vnet
10/5/25, 15:20LMS | Whizlabs
Page 21 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
resource webApp 'Microsoft.Web/sites@2022-06-01' = {  name: 'WhizApp'  location: location  properties: {    serverFarmId: appServicePlan.id    siteConfig: {      alwaysOn: true      nodeVersion: '14'    }  }}What will the execution of this Bicep file result in?
Explanation:Correct Answer:  CThis block of code creates an Azure Web App with the following details:resource webApp 'Microsoft.Web/sites@2022-06-01' = {  name: 'WhizApp'  location: location  properties: {    serverFarmId: appServicePlan.id    siteConfig: {      alwaysOn: true      nodeVersion: '14'    }  }}name: The name of the Web App is set to 'WhizApp'.location: The location is set to the value of the location parameter, which is 'East US'.serverFarmId: This specifies the App Service Plan that the Web App should be associated with. It uses the id property of theappServicePlan resource, which is the unique identifier of the previously created App Service Plan.siteConfig: Configures settings for the Web App, including enabling 'alwaysOn' (keeping the app always running) and setting theNode.js version to '14'.In summary, this ARM template (or Bicep file) creates an App Service Plan and an associated Web App in the 'East US' region withspecific configuration settings. Parameters like location are used to make the template more flexible, allowing you to specify differentregions and configurations when deploying the resources.A. Creation of an Azure Storage Account in the specified locationB. Deployment of a virtual machine instance with premium storageC. Provisioning of an Azure App Service Plan and a related web apprightD. Configuration of a network security group to restrict incoming traffic
Option A is incorrect because no mention of the storage account configuration in the code.
10/5/25, 15:20LMS | Whizlabs
Page 22 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Marked for reviewIncorrectReference:Ask our ExpertsDid you like this Question?Question 13Domain: Implement and manage virtual networkingA company has set up an external load balancer that load balances traffic on port 80 and 443 across 3 virtual machines. You have toensure that all traffic is directed towards a VM named demovm. How would you achieve this?
Explanation:Answer – CInbound NAT rule: This rule allows you to specify that traffic on certain ports should be directed to a specific backend resource, in thiscase, the demovm VM. This setup ensures that all traffic on ports 80 and 443 is routed directly to demovm, bypassing the loadbalancing across the other VMsOptions A and B are incorrect since we don’t need to recreate an entire load balancer just for this scenario.Option D is incorrect because this option does not address the requirement of directing traffic specifically to demovm through theexisting load balancer setup.For more information on port forwarding for the load balancer, please go to the below URL-Ask our ExpertsOption B is incorrect because a serverless WebApp is being deployed in the configuration.Option C is correct because the code defines a webapp along with its service plan.Option D is incorrect because no network security group or azure firewall policies are being created by the code.https://learn.microsoft.com/en-us/azure/app-service/provision-resource-bicep
A. By creating a new public load balancer for demovmB. By creating a new internal load balancer for demovmwrongC. By creating an inbound NAT rulerightD. By creating a new IP configuration
https://docs.microsoft.com/en-us/azure/load-balancer/tutorial-load-balancer-port-forwarding-portal
10/5/25, 15:20LMS | Whizlabs
Page 23 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectDid you like this Question?Question 14Domain: Manage Azure identities and governanceYou have an Azure subscription that contains the following resources:The subscription contains a virtual network named VirtualNet4 with the following subnets:
You plan to deploy another Azure container instance named container5 into VirtualNet4. To which subnets can you deploycontainer5?
Explanation:Correct Answer: BOption B: SubnetB and SubnetC are correct ones because Azure Container Instances (ACI) can be deployed into a subnet within avirtual network as long as that subnet is not restricted by service endpoint limitations. In this case:
Why it’s correct:A storage account named storage123A container instance named container1SubnetA: Has a Microsoft.Storage service endpointSubnetB: container1 is deployed to this subnetSubnetC: No resources are currently deployed hereA. SubnetA, SubnetB, and SubnetCB. SubnetB and SubnetC onlyrightC. SubnetB onlyD. SubnetC only
SubnetA has a Microsoft.Storage service endpoint, which restricts it to only accept traffic related to Azure Storage services. Thissubnet is not valid for container instance deployment.SubnetB already hosts a container instance (container1), so it’s correctly configured and available for container deployment.SubnetC is empty and has no restrictions — it is also a valid target for ACI deployment.ACI requires unrestricted subnets.Subnets with service endpoints for specific services (like Microsoft.Storage) can block non-storage resources, such as containerinstances
10/5/25, 15:20LMS | Whizlabs
Page 24 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Option A: SubnetA, SubnetB, and SubnetC is incorrect because SubnetA has a Microsoft.Storage service endpoint, which may causeACI deployment to fail unless additional configuration (e.g., NSG and route table exceptions) is applied.Option C: SubnetB only is incorrect because while SubnetB is valid, SubnetC is also available and unrestricted, making this answerincomplete.Option D: SubnetC only is incorrect because while SubnetC is valid, SubnetB already hosts an ACI and is correctly configured, so itshould also be included. References:
Ask our ExpertsDid you like this Question?SubnetB and SubnetC do not have such restrictions and are both valid for deploying container5.
Why it’s wrong: Service endpoints can restrict subnet usage to specific Azure services. It’s not a general-purpose subnet unlessexplicitly configured otherwise.Why it’s wrong: Misses another valid option — SubnetC.Why it’s wrong: Ignore an active subnet already used by container instances.https://learn.microsoft.com/en-us/azure/container-instances/container-instances-vnet#deploy-to-new-virtual-networkhttps://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview
10/5/25, 15:20LMS | Whizlabs
Page 25 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Marked for reviewCorrectView Case Study
Marked for reviewCorrectQuestion 15Domain: Deploy and manage Azure compute resourcesTo meet the technical requirements of migrating all websites and app services from App and Web servers to Azure. Which of thefollowing services must be required for websites and applications to work in an optimized and secured manner? [Select Two] 
Explanation:Correct Answers: C and D
References:
Ask our ExpertsDid you like this Question?Question 16Domain: Deploy and manage Azure compute resourcesYou plan to deploy an Azure Web App with the following settings:A. Network Security GroupsB. Azure FirewallC. Azure App ServicesrightD. Azure Application Gatewayright
Option A is incorrect because network security groups are used for managing security on virtual machines and subnets.Option B is incorrect because Azure firewall is not a required service, it is good to have, however, not required as app serviceshave their own web application firewall features.Option C is correct because Azure App Services is a fully managed platform for building, deploying, and scaling web apps. Itprovides high availability, auto-scaling, and built-in security features, making it ideal for hosting your websites and applicationsOption D is correct because Azure Application Gateway is a web traffic load balancer that enables you to manage traffic to yourweb applications. It includes a Web Application Firewall (WAF) that helps protect your applications from common webvulnerabilities and attackshttps://learn.microsoft.com/en-us/azure/application-gateway/overviewhttps://learn.microsoft.com/en-us/azure/web-application-firewall/ag/ag-overviewhttps://learn.microsoft.com/en-us/azure/app-service/overview
10/5/25, 15:20LMS | Whizlabs
Page 26 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
You need to ensure that WebApp1 uses the ASP.NET V4.8 runtime stack. Which setting should you modify?
Explanation:Correct Answer: AOption A: Publish is correct becuase
Why it’s correct: The Publish option defines how the app is delivered and run.Name: WebApp1Publish: Docker ContainerOperating System: WindowsRegion: West USApp Service Plan (Windows, West US): ASP-RG1-8bcfA. PublishrightB. Operating systemC. RegionD. Windows Plan
Currently, the app is set to "Publish: Docker Container", which means you're deploying a custom container image — not usingbuilt-in runtime stacks such as ASP.NET v4.8.To use ASP.NET V4.8, you must select "Code" as the publish method instead of Docker. This tells Azure App Service to use a pre-configured runtime environment, including ASP.NET frameworks like v4.8, instead of expecting a user-defined container.Selecting “Code” allows you to choose ASP.NET runtime stacks (e.g., .NET Framework 4.8).Selecting “Docker Container” means you must provide a container image that includes everything — including the framework —and Azure won’t give you a runtime stack option.
10/5/25, 15:20LMS | Whizlabs
Page 27 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Marked for reviewIncorrect
Option B: Operating system is incorrect because Windows is the correct OS because ASP.NET 4.8 only runs on Windows App Service —it’s not supported on Linux.Option C: Region is incorrect because the region (West US) has no impact on the runtime stack or framework availabilityOption D: Windows Plan is incorrect because the App Service Plan is already a valid Windows-based plan in the same region. Itdoesn’t affect the available runtime stack, only the hosting resources (e.g., compute, pricing tier).References:
Ask our ExpertsDid you like this Question?Question 17Domain: Deploy and manage Azure compute resourcesWhy it’s wrong:  This setting is already correctly configured.Why it’s wrong: Changing the region won't make ASP.NET 4.8 appear unless Publish is set to “Code”.Why it’s wrong: The issue isn’t with the plan but with how the app is being published.https://learn.microsoft.com/en-us/azure/app-service/overviewhttps://learn.microsoft.com/en-us/azure/app-service/quickstart-dotnetcore?tabs=net80&pivots=development-environment-vs
10/5/25, 15:20LMS | Whizlabs
Page 28 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
You plan to deploy the following Azure web apps:
You need to create the App Service Plans to support these apps. What is the minimum number of App Service Plans that should becreated?
Explanation:Correct Answer: BOption B: 2 Correct because Azure App Service Plans can be shared by multiple web apps, if those apps use the same operatingsystem (OS platform).  The runtime stack determines whether the app needs to run on Windows or Linux:So, we have:WebApp1 – uses the .NET 8 runtime stackWebApp2 – uses the ASP.NET V4.8 runtime stackWebApp3 – uses the Java 21 runtime stackWebApp4 – uses the PHP 8.3 runtime stackA. 1B. 2rightC. 3wrongD. 4
One Windows plan needed for WebApp2 (.NET Framework 4.8 is Windows-only)One Linux plan for WebApp1, WebApp3, and WebApp4 (all supported on Linux)
10/5/25, 15:20LMS | Whizlabs
Page 29 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Option A: 1 incorrect because
Option C: 3 incorrect because 
Option D: 4 incorrect because
  References:Why it’s correct: You can host multiple apps on the same plan as long as they share the same OS platform. Since the Windows vs.Linux boundary is strict, we need 2 separate plans:One Windows App Service PlanOne Linux App Service PlanYou cannot run both Windows and Linux apps on the same App Service Plan.Since ASP.NET V4.8 (WebApp2) requires Windows, and the rest require Linux, at least two plans are mandatory.Azure does not support mixed-platform app plans.This overestimates the number of plans needed.Some may think Java or PHP requires separate plans, but Azure supports hosting different Linux runtimes together in the sameLinux plan.WebApp1 (.NET 8), WebApp3 (Java), and WebApp4 (PHP) can all run on a single Linux plan, so a third plan isn’t needed.You do not need one App Service Plan per web app unless you're intentionally isolating for scaling or billing.Azure App Service Plans are multi-tenant capable — you can deploy multiple apps on one plan, as long as they use the same OS.This option ignores the resource-sharing capabilities of Azure App Service.
10/5/25, 15:20LMS | Whizlabs
Page 30 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
UnattemptedAsk our ExpertsDid you like this Question?Question 18Domain: Deploy and manage Azure compute resourcesWhizlabs Inc. is planning on deploying Azure container registry. What is the correct order in the process of creating and managing anAzure container registry.
Explanation:Correct Answer: D, B, A, E and CThe correct order of steps as follows:
Create an Azure Container Registry: This is the first step in the process. You need to create the actual container registry in Azure beforeyou can perform any other actions related to it.Choose a Pricing Tier: After creating the container registry, you need to select a pricing tier that aligns with your requirements. Thepricing tier determines the features and capacity of the registry.Configure Container Registry Settings: Once the pricing tier is selected, you should configure various settings for the container registry,https://learn.microsoft.com/en-us/azure/app-service/overview-hosting-planshttps://learn.microsoft.com/en-us/azure/app-service/configure-common?tabs=portal
Correct Answer1.D. Create an Azure container registry2.B. Choose a pricing tier3.A. Configure container registry settings4.E. Set up authentication and security5.C. Access and manage container images
D. Create an Azure container registry.B. Choose a pricing tier.A. Configure container registry settings.E. Set up authentication and security.C. Access and manage container images.
10/5/25, 15:20LMS | Whizlabs
Page 31 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Incorrectsuch as network settings, repository names, and more. This step ensures the registry is properly configured for your use case.Set up Authentication and Security: Before you start using the container registry, it's important to set up authentication and securitymeasures. This includes configuring user roles, permissions, and authentication mechanisms to ensure secure access to the registry.Access and Manage Container Images: After all the setup steps are complete, you can start uploading, managing, and accessingcontainer images within the registry. This step involves tasks like pushing images, pulling images, and managing repository versions.Reference:Ask our ExpertsDid you like this Question?Question 19Domain: Implement and manage storageA company needs to create a storage account that must follow the requirements below.
What is the type of replication they need to implement for the storage account?
Explanation:Answer: ACopies your data synchronously three times within a single physical location: LRS replicates data three times within a single datacenter.Durability for storage resources of at least 99.99999999999999% over a given year: LRS provides high durability by keeping multiplecopies of the data.Tutorial - Create geo-replicated registry - Azure Container Registry | Microsoft Learn
Copies your data synchronously three times within a single physical locationDurability for storage resources of at least 99.99999999999999% over a given year.Ability to store archive data.Users should be able to have Azure files in place and accessible across multiple VMs.The solution needs to be cost-effective.A. Locally redundant storage (LRS)rightB. Zone-redundant storage (ZRS)wrongC. Geo-redundant storage (GRS)D. Read-access geo-redundant storage (RA-GRS)
10/5/25, 15:20LMS | Whizlabs
Page 32 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectAbility to store archive data: LRS supports different storage tiers, including archive.Users should be able to have Azure files in place and accessible across multiple VMs: LRS supports Azure Files, which multiple VMs canaccess.The solution needs to be cost-effective: LRS is the most cost-effective option compared to other replication strategies like ZRS, GRS,and RA-GRS.Option B is incorrect because ZRS copies your data synchronously across three Azure availability zones within the same region. Thisprovides high availability and durability but does not meet the requirement of copying data within a single physical location (datacenter). ZRS is generally more expensive than LRS due to the additional redundancy across availability zones.Option C is incorrect because GRS copies your data synchronously three times within one or more availability zones in the primaryregion using LRS, and then copies your data asynchronously to a secondary region. This protects against regional disasters but doesnot meet the requirement of copying data within a single physical location. GRS is more expensive than LRS due to the additional geo-replicationOption D is incorrect because it does not provide GRS durability for storage resources of at least 99.99999999999999% (16 9's) over agiven year and is not supported for Azure Files.Reference: Data redundancy - Azure Storage | Microsoft LearnAsk our ExpertsDid you like this Question?Question 20Domain: Deploy and manage Azure compute resourcesYou have an Azure subscription. You plan to create a storage account with the following settings:
What is the minimum number of copies of storage1 data stored in Azure?
Explanation:Name: storage1Performance: StandardRedundancy: Zone-redundant storage (ZRS)A. 2B. 9C. 6D. 3right
10/5/25, 15:20LMS | Whizlabs
Page 33 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Correct Answer: DOption D: 3 is correct because When you use Zone-Redundant Storage (ZRS), Azure stores three copies of your data across threeavailability zones within a single Azure region.
Option A: 2 is incorrect because Azure does not use 2 copies for any standard redundancy option. Two copies would not meet Azure’sdurability SLA or protect against zone failure.Option B: 9 is incorrect because no Azure storage redundancy tier uses 9 copies. This number might arise if someone assumes ZRS in3 zones × 3 local copies each, but that is not how Azure ZRS operates.Option C: 6 is incorrect because Azure does not store 6 copies for ZRS. This might be confused with RA-GRS (Read-Access Geo-Redundant Storage) which stores 3 local copies in the primary region and 3 geo-replicated copies in a secondary region, totaling 6,but that's not ZRS.Reference:Each availability zone is a physically separate location with independent power, cooling, and networking.ZRS ensures high availability and durability even if one entire zone becomes unavailable.
Why it’s correct: ZRS replicates your data synchronously across three zones, maintaining three distinct copies at all times.Why it’s wrong: This would create a single point of failure and is not supported in Azure’s redundancy models.Why it’s wrong: This is a misunderstanding of the ZRS architecture. It uses 1 copy per zone, not 3 per zone.Why it’s wrong: ZRS is zone-level, not geo-level replication. Only 3 copies are made across zones in a single region.Azure Storage redundancy options
10/5/25, 15:20LMS | Whizlabs
Page 34 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
IncorrectAsk our ExpertsDid you like this Question?Question 21Domain: Implement and manage storageVersion-level immutability can be enabled or disabled on the storage account at any point of time. Is this statement correct? (SelectYes or No)
Explanation:Correct Answer: BVersion-level immutability is a storage account–level setting that allows individual blob versions to be protected from deletion ormodification using immutability policies.
                                               [Source: Microsoft Documentation]Once version-level immutability is enabled, it cannot be disabled — the setting becomes permanent for the storage account. Thisensures that versioned blobs can always be protected using policies, even if future policy enforcement is removed or changed.A. YeswrongB. Noright
10/5/25, 15:20LMS | Whizlabs
Page 35 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Incorrect
This setting is used for regulatory compliance and data protection scenarios where blob data must remain tamper-proof.Reference:Ask our ExpertsDid you like this Question?Question 22Domain: Implement and manage storageYou have a storage account named whizlabstore. You have created a file share named demo using the file service. You need toensure that users can connect to the file share from their home computers. Which of the following port should be open to provide theconnectivity?Why it’s correct: The original statement says that version-level immutability can be disabled at any time, but this is incorrect.Once enabled, it stays enabled permanently, even if you remove individual policies.https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-policy-configure-version-scope?tabs=azure-portal
A. 80wrongB. 443C. 445right
10/5/25, 15:20LMS | Whizlabs
Page 36 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
IncorrectExplanation:Answer – CTo access files from home computers, users have to use SMB protocol that expects port 445 to be open.This is clearly given in the Microsoft documentation.
For more information on using file shares in Azure, please visit the below URL-Ask our ExpertsDid you like this Question?Question 23Domain: Implement and manage storageContoso Inc., a multinational company, is migrating its on-premises file servers to Azure Files. The IT team wants to enforce granularaccess control for users accessing files and directories within a file share, using identity-based access. Which of the followingmechanisms supports this capability?D. 3389
https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-windows
10/5/25, 15:20LMS | Whizlabs
Page 37 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Explanation:Correct Answer: AOption A: Microsoft Entra Domain Services is correct because Microsoft Entra Domain Services provides domain-join, LDAP,Kerberos/NTLM authentication, and is fully compatible with Windows ACLs (Access Control Lists). It allows file shares to be integratedwith a managed domain, enabling fine-grained NTFS permissions at both the file and folder level.
[Source: Microsoft Documentation]Option B: Role-Based Access Control (RBAC) is incorrect because it is used to control access at the Azure resource level, such as whocan manage storage accounts, virtual machines, or networking — not at the file/folder level inside Azure Files.Option C: Shared Key Authentication is incorrect because it grants access using a storage account key, giving broad access to theentire file share. It does not support per-user access control or directory-level restrictions.A. Microsoft Entra Domain ServicesrightB. Role-Based Access Control (RBAC)wrongC. Shared Key AuthenticationD. Virtual Network Service Endpoints
Why it’s correct: It is the only option that enables directory- and file-level granular permissions using Microsoft Entra (formerlyAzure AD) identities through identity-based authentication with Azure Files.
Why it’s wrong: RBAC does not support granular control over individual files and directories. It cannot enforce NTFS-level accesspermissions inside a file share.
10/5/25, 15:20LMS | Whizlabs
Page 38 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectOption D: Virtual Network Service Endpoints is incorrect because Service endpoints secure traffic between your VNet and AzureStorage by keeping traffic on Microsoft’s backbone network. They protect at the network level, not the file system level.Reference: Enable Microsoft Entra Domain Services authentication on Azure FilesAsk our ExpertsDid you like this Question?Question 24Domain: Implement and manage virtual networkingA company has set up a Virtual Machine in Azure. A web server listening on port 80 and a DNS server has been installed on the Virtualmachine. A network security group is attached to the network interface for the virtual machine. The rules for the NSG are given below.Inbound Rules
Outbound Rules
Why it’s wrong: It bypasses identity-based control. Any user with the shared key can access all files, without restrictions orauditing.Why it’s wrong: While they increase network security, they don’t control file or directory access based on user identity orpermissions.
10/5/25, 15:20LMS | Whizlabs
Page 39 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectIf RuleB is deleted/omitted, please select the service through which Internet users connect to the virtual machine.
Explanation:Answer – DIf RuleB is deleted, users won’t be able to access port 80 and the web server.There is a Deny rule of RuleA for ports 50-60. Since DNS listens on port 53, you will not be able to access the DNS server. But you will stillbe able to connect to the virtual machine using Remote Desktop Protocol (RDP) under the Allow_rdp rule.Because of this logic, all other options are incorrect.For more information on network security, please visit the below URL-Ask our ExpertsDid you like this Question?Question 25Domain: Implement and manage storageYour company has set up a storage account in Azure, as shown below.
There is a requirement to retain any blob data that might accidentally be deleted. The deleted data needs to be retained for 14 days.A. Through the web server B. Through the DNS server C. both Web and DNS serversD. Through RDPrightE. Through RDP, Web, and DNS servers
Azure network security groups overview | Microsoft Docs
10/5/25, 15:20LMS | Whizlabs
Page 40 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
From which of the following option of the storage account would you modify to fulfill this requirement?
Explanation:Answer – CThis can be done from the Data Protection option/tab from the storage account at any time by using the Azure portal, PowerShell, orAzure CLI.
A. Firewall and virtual networksB. Advanced securityC. Data Protection(Soft Delete)rightD. Lifecycle Management
10/5/25, 15:20LMS | Whizlabs
Page 41 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Incorrect
 Blob soft delete protects an individual blob, snapshot, or version from accidental deletes or overwrites by maintaining the deleteddata in the system for a specified period of time. During the retention period, you can restore a soft-deleted object to its state at thetime it was deleted.Since this is clear from the implementation, all other options are incorrect. Reference: Enable soft delete for blobs - Azure Storage | Microsoft Learn Ask our ExpertsDid you like this Question?Question 26Domain: Monitor and maintain Azure resourcesMatch each Azure Monitor feature with its correct description in the context of VM Insights. Each feature is used to monitor andanalyze virtual machines and their performance metrics at scale. Note: Drag the appropriate feature name and drop them to the correct description
10/5/25, 15:20LMS | Whizlabs
Page 42 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Explanation:Correct Answers [Matching]: A-1, B-3, C-2, D-4, E-5Option A: Activity log (Correct Match: 1)The activity log provides insight into Azure Resource Manager-level events, such as who started or stopped a VM, created a disk, ormodified configurations. It is not VM-specific but can be filtered by VM resource types.Option B: Alerts (Correct Match: 3)Your AnswersA. Activity logAnalyze performance indicators like CPU usage or disk IOPS acrossmachines without pre-scoping a single VMB. AlertsReview threshold-based or dynamic warnings and incidentsgenerated by rules across multiple VMsC. MetricsAccess prebuilt dashboards and visualizations for multiple VMs,including performance trends and guest OS detailsD. LogsUse powerful query-based investigation into system events, bootdiagnostics, and application logs across all connected machinesE. WorkbooksSee recent operational events, such as VM creation, updates, ordeletions, across all virtual machines by applying resource-typefiltersCorrect AnswersA. Activity logSee recent operational events, such as VM creation, updates, or deletions,across all virtual machines by applying resource-type filtersB. AlertsReview threshold-based or dynamic warnings and incidents generatedby rules across multiple VMsC. MetricsAnalyze performance indicators like CPU usage or disk IOPS acrossmachines without pre-scoping a single VMD. LogsUse powerful query-based investigation into system events, bootdiagnostics, and application logs across all connected machinesE. WorkbooksAccess prebuilt dashboards and visualizations for multiple VMs, includingperformance trends and guest OS details
Why it’s correct: Filtering by Virtual Machine or VMSS lets you narrow down log entries specific to compute resources — useful forauditing and troubleshooting.
10/5/25, 15:20LMS | Whizlabs
Page 43 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Alerts notify you when a monitored condition is met — such as CPU usage > 80% for 5 minutes. These rules apply across resources andcan be viewed centrally for all machines.Option C: Metrics (Correct Match: 2)
Option D: Logs (Correct Match: 4)This refers to Log Analytics, where you can run Kusto Query Language (KQL) queries to analyze logs from connected machines —including boot times, update status, agent health, and custom events.Option E: Workbooks (Correct Match: 5)Workbooks are interactive, visual reports that help you track and correlate data across your infrastructure. The VM insights workbookscome prebuilt for monitoring groups of VMs together.
Why it’s correct: Alerts support both metric- and log-based rules, and VM alerts can be viewed in aggregate by filtering onresource types.The Metrics Explorer allows real-time charting and trend analysis of performance counters like CPU, memory, and network. Bydefault, it's unscoped, enabling multi-VM comparison by selecting a group or subscription.Why it’s correct: Unlike Logs, Metrics are pre-aggregated and offer a near real-time view of performance across many VMs.
Why it’s correct: Log Analytics supports deep inspection and correlation of data at the workspace level, not limited to one VM.
Why it’s correct: They provide dashboard-like experiences using log and metric data for CPU, memory, disk, and health analysis.
10/5/25, 15:20LMS | Whizlabs
Page 44 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Incorrect
                              [Source: Microsoft Documentation]Reference:Monitor virtual machines with Azure Monitor: Analyze monitoring data - Azure Monitor | Microsoft LearnAsk our ExpertsDid you like this Question?Question 27Domain: Deploy and manage Azure compute resourcesA virtual machine (VM) called "myVM" is connected to the key vault to run Azure Disk Encryption. Now you need to move that virtualmachine to a different resource group, subscription, and region. Identify the correct sequence of steps to achieve this using the AzureCLI.Drag the steps into the correct order by selecting the appropriate options below and Drop them in the answer space.
10/5/25, 15:20LMS | Whizlabs
Page 45 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectExplanation:Correct Answer: B, D, C and, AA virtual machine that is integrated with a key vault to implement Azure Disk Encryption for Linux VMs or Azure Disk Encryption forWindows VMs can be moved to another resource group when it is in a deallocated state.However, to move such a virtual machine to another subscription, you must disable encryption.To move a virtual machine (VM) named "myVM" to a different resource group, subscription, and region using the Azure CLI, here is thecorrect order of steps:The correct order of steps is B, D, C & A.
Reference:Ask our ExpertsDid you like this Question?Question 28Domain: Implement and manage virtual networkingYour Answer1.az group create --name newResourceGroup --location newRegion2.az vm deallocate --name myVM --resource-group oldResourceGroup3.az vm wait --name myVM --resource-groupoldResourceGroup --deleted4.az vm create --name myVM --resource-group newResourceGroup --locationnewRegion --source oldResourceGroupCorrect Answer1.az vm deallocate --name myVM --resource-group oldResourceGroup2.az group create --name newResourceGroup --location newRegion3.az vm create --name myVM --resource-group newResourceGroup --locationnewRegion --source oldResourceGroup4.az vm wait --name myVM --resource-groupoldResourceGroup --deleted
B. az vm deallocate --name myVM --resource-group oldResourceGroup : Stop the VM in the old resource group.D. az group create --name newResourceGroup --location newRegion: Create a new resource group in the desired region.C. az vm create --name myVM --resource-group newResourceGroup --location newRegion --source oldResourceGroup : Movethe VM to the new resource group and region.A. az vm wait --name myVM --resource-group oldResourceGroup --deleted: Wait for the VM to be deleted from the old resourcegroup.Move Azure VMs to new subscription or resource group - Azure Resource Manager | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 46 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
You are managing a Virtual Machine (VM) in Azure that hosts both a web server (listening on port 80) and a DNS server (on port 53).The VM is protected using a Network Security Group (NSG) with the following rule configuration:
Outbound rules allow internet access, but inbound rules control public connectivity. If RuleB is deleted, through which service canInternet users still successfully connect to the virtual machine?
Explanation:Correct Answer: DOption D: Through RDP is correct because Even after deleting RuleB, RDP access remains allowed via the “Allow_rdp” rule. Thismeans internet users can still remotely access the VM using RDP.RuleB currently allows inbound TCP traffic on ports 50–500 (priority 120).RuleA denies all traffic on ports 50–60 (priority 100).An explicit rule exists to allow RDP traffic on port 3389 (priority 110).A. Through the web serverB. Through the DNS serverC. Both web and DNS serversD. Through RDPright
RDP uses TCP port 3389.There is an explicit inbound allow rule for RDP in "Allow_rdp" (priority 110).RuleA (priority 100) applies only to ports 50–60 and does not affect port 3389
10/5/25, 15:20LMS | Whizlabs
Page 47 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
 Option A: Through the web server is incorrect because without RuleB, port 80 is not allowed inbound. So, internet users cannotaccess the web server.
Option B: Through the DNS server is incorrect because port 53 falls within the denied range (RuleA: 50–60 Deny), DNS access is alsoblocked.
Option C: Both Web and DNS servers is incorrect because both ports are denied, so internet users cannot access either service.Reference:The web server typically listens on port 80. While outbound traffic on port 80 is explicitly denied via RuleC (priority 100, Action:Deny), it’s important to also look at the inbound rules:RuleA denies traffic on ports 50–60RuleB (deleted in this case) was allowing TCP traffic on ports 50–500If RuleB is removed:No explicit inbound allow rule exists for port 80, andAs per Azure NSG rules, the default behavior is to deny unless explicitly allowed.A DNS server typically uses UDP or TCP port 53.No inbound rule allows port 53.RuleA only denies ports 50–60, which includes 53.With RuleB removed, there's no explicit allow for port 53 either.As explained in A and B: Web server (port 80) and DNS server (port 53) are both blocked due to RuleA and the deletion of RuleB.
10/5/25, 15:20LMS | Whizlabs
Page 48 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectAsk our ExpertsDid you like this Question?Question 29Domain: Deploy and manage Azure compute resourcesWhizlabs Corporation is looking to deploy containerized applications in Azure and needs a container registry to store their Dockerimages. Which of the following Azure service provides a private and secure repository for storing Docker container images?
Explanation:Correct Answer: CAzure Container Registry (ACR) is a private and secure repository for storing Docker container images. It allows organizations tomanage and distribute container images securely, making it an essential service for containerized applications in Azure.
References:Create and configure network security groups (NSGs)
A. Azure Kubernetes Service (AKS)B. Azure Container Instances (ACI)C. Azure Container Registry (ACR)rightD. Azure Container Service (ACS)
Option A is incorrect because Azure Kubernetes Service (AKS) is a managed Kubernetes container orchestration service, not acontainer registry.Option B is incorrect Azure Container Instances (ACI) is a serverless container service for running containers, but it does notprovide container image storage.Option C is correct because Azure Container Registry (ACR) is a private and secure repository for storing Docker containerimages. It allows organizations to manage and distribute container images securely, making it an essential service forcontainerized applications in Azure.Option D is incorrect because Azure Container Service (ACS) is an older service that has been deprecated in favor of AzureKubernetes Service (AKS) for managing Kubernetes clusters.Azure Container Registry | Microsoft AzureManaged container registries - Azure Container Registry | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 49 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
IncorrectAsk our ExpertsDid you like this Question?Question 30Domain: Implement and manage storageYou are configuring Microsoft Entra Domain Services (Entra DS) authentication for Azure Files in a hybrid environment. Yourorganization uses on-premises Active Directory and wants to provide identity-based access to Azure file shares for users.Drag and drop the following steps into the correct order to enable Entra DS-based authentication for Azure Files.
Explanation:Correct Answers [Sequence]: C - A - B - DC. Sync on-prem AD to Microsoft Entra ID using Entra ConnectA. Domain join your virtual machines to Microsoft Entra Domain ServicesB. Enable Azure Files Microsoft Entra DS authenticationD. Configure directory/file-level NTFS permissions Summary Flow (Simplified):  Sync identities → Join VMs to Entra DS → Enable File Share Auth → Set PermissionsYour Answer1.A. Domain join your virtual machines toMicrosoft Entra Domain Services2.C. Sync on-prem AD to Microsoft Entra IDusing Entra Connect3.D. Configure directory/file-level NTFSpermissions4.B. Enable Azure Files Microsoft Entra DSauthenticationCorrect Answer1.C. Sync on-prem AD to Microsoft Entra ID usingEntra Connect2.A. Domain join your virtual machines toMicrosoft Entra Domain Services3.B. Enable Azure Files Microsoft Entra DSauthentication4.D. Configure directory/file-level NTFSpermissions
10/5/25, 15:20LMS | Whizlabs
Page 50 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
                         [Source: Microsoft Documentation]Option C: Sync on-prem AD to Microsoft Entra ID using Entra Connect (Step 1)This is the first and foundational step in enabling Microsoft Entra DS-based authentication. You must sync your on-premises ActiveDirectory users and groups to Entra ID using Microsoft Entra Connect Sync. This hybrid identity setup allows those users to berecognized and authenticated within Azure services, including Microsoft Entra Domain Services.Option A: Domain join your virtual machines to Microsoft Entra Domain Services (Step 2)Once Entra DS is provisioned and identity sync is in place, your VMs in Azure must be domain joined to Microsoft Entra DS. This allowsthem to communicate securely with the domain and apply access controls using NTFS and ACLs for Azure Files.Option B: Enable Azure Files Microsoft Entra DS authentication (Step 3)After the VM is domain-joined, you can enable identity-based access to Azure Files by activating Microsoft Entra DS authenticationfor the file share. This integrates SMB (Server Message Block) file share access with Entra DS accounts.Option D: Configure directory/file-level NTFS permissions (Step 4)After enabling Entra DS authentication, the final step is to apply NTFS-level permissions from a domain-joined VM. This includes usingWindows File Explorer or command-line tools to assign folder- and file-level access for specific Entra DS users or groups.Why it’s correct: Without syncing AD identities to Entra ID, you can’t proceed with domain services in Azure. Entra DS requires cloudvisibility of your on-prem directory.
Why it’s correct: Joining VMs to the domain ensures they can authenticate users and set permissions correctly, just like atraditional Windows domain environment.
Why it’s correct: This setting is what binds the Azure file share to your domain-based identity provider, allowing granular accessmanagement using synced user accounts.
Why it’s correct: This is the final configuration step that secures access at the granular level, just like in traditional file server
10/5/25, 15:20LMS | Whizlabs
Page 51 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
IncorrectReference: Ask our ExpertsDid you like this Question?Question 31Domain: Manage Azure identities and governanceYour organization has several offices. You need to reflect the organization structure in Microsoft Entra ID by creating administrativeunits.Please select the tools you can use to create administrative units.
Explanation:Correct Answers: B and COption A is incorrect, This tool is primarily used for managing Power Platform environments and resources. It does not support thecreation or management of administrative units in Microsoft Entra ID, so this option is not applicable.Option B is Correct, These provide powerful scripting capabilities to automate and manage Microsoft Entra ID resources, includingadministrative units. Ideal for automation and bulk operations.Option C is Correct, This is a user-friendly interface specifically designed for managing Microsoft Entra ID, including creating andmanaging administrative units. It's convenient for those who prefer a graphical interface.Option D is incorrect, The Azure CLI is a command-line tool for managing Azure resources. However, it does not support the creation ormanagement of administrative units in Microsoft Entra ID, so this option is not applicable.Reference: For more information about Microsoft Entra ID administrative units, please visit the below URLs:environments — using ACLs (Access Control Lists).On-premises AD Domain Services authentication over SMB for Azure file shares
A. Power Platform Admin centerwrongB. Microsoft Graph/PowerShellrightC.  Microsoft Entra admin centerrightD. Azure CLI
Administrative units in Microsoft Entra ID | Microsoft LearnCreate or delete administrative units - Microsoft Entra ID | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 52 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectAsk our ExpertsDid you like this Question?Question 32Domain: Implement and manage storageYou are managing an Azure Storage account configured with container soft delete. Which of the following statements aboutcontainer soft delete are true? (Select 3)
Explanation:Correct Answers: B, D and EYour AnswerB. Updating the retention period affects onlycontainers deleted after the change is madeD. Soft delete protects containers within a storageaccount but not the storage account itselfE. Container soft delete supports both general-purpose v2 accounts and accounts withhierarchical namespaceCorrect AnswerB. Updating the retention period affects onlycontainers deleted after the change is madeD. Soft delete protects containers within a storageaccount but not the storage account itselfE. Container soft delete supports both general-purpose v2 accounts and accounts withhierarchical namespace
Updating the retention period affects only containers deleted after the change is made.Soft delete protects containers within a storage account but not the storage account itself.Container soft delete supports both general-purpose v2 accounts and accounts with hierarchical namespace.
10/5/25, 15:20LMS | Whizlabs
Page 53 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Option B: Updating the retention period affects only containers deleted after the change is made is correct because when youchange the retention period, the new duration only applies to containers deleted going forward. Existing soft-deleted containers stillfollow the policy that was active at the time of deletion.Option D: Soft delete protects containers within a storage account but not the storage account itself is correct because thecontainer soft delete setting only applies to containers. If the entire storage account is deleted, no soft delete mechanism exists for itscontents unless a resource lock is configured.Option E: Container soft delete supports both general-purpose v2 accounts and accounts with hierarchical namespace is correctbecause It’s broadly supported across storage account types including Azure Data Lake Storage Gen2 (when HNS is enabled).Container soft delete is supported in:Why it’s correct: Retention is timestamp-bound. Soft-deleted containers “lock in” the retention period at deletion time.Why it’s correct: You need to set a resource lock to prevent unintended storage account deletion.
General-purpose v1 & v2 accountsBlock blob storage accountsBlob storage accountsStorage accounts with hierarchical namespace (used for Data Lake Gen2)
10/5/25, 15:20LMS | Whizlabs
Page 54 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Incorrect
                                               [Source: Microsoft Documentation]Option A: A soft-deleted container can be recovered even after its retention period ends, provided soft delete is still enabled isincorrect because once the retention period expires, the container is permanently deleted, regardless of whether soft delete is stillenabled.Option C: Soft-deleted blobs can be restored using container soft delete even if the container wasn’t deleted is incorrect becausecontainer soft delete only works when the entire container was deleted. If a blob is deleted individually and the container remains,blob soft delete or versioning is required to restore the blob. Reference:  Soft delete for containersAsk our ExpertsDid you like this Question?Question 33Domain: Deploy and manage Azure compute resourcesWhy it’s wrong: The soft delete setting only retains the container within the retention period (1-365 days). After that, the containeris unrecoverable.Why it’s wrong: Blob recovery without container deletion is outside the scope of container soft delete.
10/5/25, 15:20LMS | Whizlabs
Page 55 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
View Case Study
IncorrectTo ensure that all the virtual machines for WhizApp1 in Azure are protected by backups, which Azure service or feature should Whizlabsuse?
Explanation:Correct Answer: AAzure Backup is the service that allows Whizlabs to protect virtual machines and data in Azure by creating backups. It ensures that allvirtual machines for WhizApp1 are backed up as per the technical requirements. The backups are stored in the Recovery ServicesVault, which uses Azure Blob Storage for that purpose.
Reference:Ask our ExpertsDid you like this Question?Question 34Domain: Implement and manage storageYou are managing a virtual machine named "myVM", which is currently using Azure Disk Encryption and is tied to a key vault. You needto move this VM to a different resource group, subscription, and region using the Azure CLI. You need to drag and drop the steps in the correct order to achieve the migration successfully.A. Azure BackuprightB. Azure Site RecoverywrongC. Azure Blob StorageD. Azure File Sync
Option B: Incorrect. Azure Site Recovery is used for disaster recovery and does not directly address backup needs.Option C: Incorrect. Azure Blob Storage is for storing data, not for creating backups.Option D: Incorrect. Azure File Sync is used for file synchronization between on-premises and Azure storage, but it doesn't providefull virtual machine backup capabilities.Quickstart - Back up a VM with the Azure portal - Azure Backup | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 56 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Explanation:Correct Answers [Sequence]: B - A - D - C1. az vm deallocate --name myVM --resource-group oldResourceGroup2. az vm wait --name myVM --resource-group oldResourceGroup --deleted3. az group create --name newResourceGroup --location newRegion4. az vm create --name myVM --resource-group newResourceGroup --location newRegion --source oldResourceGroup
Step 1: Deallocate the VM [az vm deallocate --name myVM --resource-group oldResourceGroup]Your Answer1.D. az group create --name newResourceGroup--location newRegion2.B. az vm deallocate --name myVM --resource-group oldResourceGroup3.A. az vm wait --name myVM --resource-group oldResourceGroup --deleted4.C. az vm create --name myVM --resource-group newResourceGroup --locationnewRegion --source oldResourceGroupCorrect Answer1.B. az vm deallocate --name myVM --resource-group oldResourceGroup2.A. az vm wait --name myVM --resource-group oldResourceGroup --deleted3.D. az group create --namenewResourceGroup --location newRegion4.C. az vm create --name myVM --resource-group newResourceGroup --locationnewRegion --source oldResourceGroup
Why it’s first: Before moving or replicating a VM across regions, the VM must be stopped and deallocated to detach resourcesand prepare it for export.
10/5/25, 15:20LMS | Whizlabs
Page 57 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectStep 2: Wait for deletion confirmation [az vm wait --name myVM --resource-group oldResourceGroup --deleted]Step 3: Create a new resource group [az group create --name newResourceGroup --location newRegion]Step 4: Create the VM in the new region [az vm create --name myVM --resource-group newResourceGroup --location newRegion --source oldResourceGroup]Reference:Special cases to move Azure VMs to new subscription or resource group - Azure Resource Manager | Microsoft Learn Ask our ExpertsDid you like this Question?Question 35Domain: Monitor and maintain Azure resourcesWhizlabs International is a Europe based company. Due to new GDPR requirements, the company is planning to reorganize their Azureresources and needs to perform various resource management tasks.Drag the appropriate Azure services with respect to their definitions. Note: This is a Drag and Drop Matching Type Question.Why it’s next: The operation confirms that the VM and its related metadata are in a safe, deletable state. This ensures Azuredoesn't try to create a duplicate VM or conflict with name/ID references during the new deployment.Why it’s here: Before you deploy the VM in a new region, you must have a target resource group available in that region.Why it’s last: This command recreates the VM in the new location using the previously stored source settings. It's the final step toreinstantiate the VM in a new region and resource group.
10/5/25, 15:20LMS | Whizlabs
Page 58 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Explanation:Correct Answer: 1-C, 2-A and 3-BAzure Virtual Machine: This service is used to host virtual servers in the cloud and can be moved between resource groups orregionsAzure Resource Group: This component acts as a logical container for resources, making it easier to manage and organize themAzure Region: When you need to change the physical location of resources, you can move them to a different one of theseDetailed Explanation:-Your AnswersAzure Resource GroupThis component acts as a logical container for resources, making iteasier to manage and organize themAzure Virtual MachineThis service is used to host virtual servers in the cloud and can bemoved between resource groups or regionsAzure RegionWhen you need to change the physical location of resources, youcan move them to a different one of theseCorrect AnswersAzure Resource GroupThis component acts as a logical container for resources, making it easierto manage and organize themAzure Virtual MachineThis service is used to host virtual servers in the cloud and can be movedbetween resource groups or regionsAzure RegionWhen you need to change the physical location of resources, you canmove them to a different one of these
Azure Resource Group: Resource groups are logical containers for resources, and they help with managing and organizingresources within Azure. This is essential for efficient resource management.Azure Virtual Machine: Azure Virtual Machines can indeed be moved between resource groups or regions, allowing for flexibility inresource management and optimization.Azure Region: Azure regions represent the physical location of data centers. When you need to change the physical location ofresources, you can indeed move them to a different Azure region. This can be helpful for disaster recovery or optimization.
10/5/25, 15:20LMS | Whizlabs
Page 59 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectReference: Move resources to a new subscription or resource group - Azure Resource Manager | Microsoft LearnAsk our ExpertsDid you like this Question?Question 36Domain: Deploy and manage Azure compute resourcesYou are tasked with deploying Azure resources for a Node.js-based web application called WhizApp using an Infrastructure-as-Code(IaC) approach via Azure Bicep.Your goal is to ensure the following:
You review the Bicep configuration below:param location string = 'East US'resource appServicePlan 'Microsoft.Web/serverfarms@2022-03-01' = {  name: 'myAppServicePlan'  location: location  sku: {    name: 'P1V2'    tier: 'PremiumV2'  }}resource webApp 'Microsoft.Web/sites@2022-06-01' = {  name: 'WhizApp'  location: location  properties: {    serverFarmId: appServicePlan.id    siteConfig: {      alwaysOn: true      nodeVersion: '14'    }  }}Which of the following statements are true about this Bicep deployment? [Select three]The application is deployed to the East US region.It uses App Service Plan PremiumV2 (P1V2 SKU) to support production-grade features like high performance and autoscaling.The app requires Node.js version 14, and it must remain always running to avoid cold starts.
10/5/25, 15:20LMS | Whizlabs
Page 60 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Explanation:Correct Answers: A, B and DOption A is correct because - The App Service Plan specified is PremiumV2 (P1V2), a high-performance tier that supports Always On,custom domains, SSL, autoscaling, and more — all of which are essential for production workloads.Option B is correct because - The alwaysOn: true setting ensures the app doesn’t idle due to inactivity. It keeps the web app’s workerprocess running even when there are no HTTP requests — ideal for background tasks and cold-start prevention.Option D is correct because -The serverFarmId property directly links the web app to the App Service Plan (myAppServicePlan). Thisensures the app shares the same compute, billing, and scaling resources as other apps in the plan.Option C is incorrect because - Although Node.js 18 is supported on Azure, the Bicep configuration explicitly sets nodeVersion: '14'. Thisis a common mismatch trap.Option E is incorrect because - The app is deployed using the PremiumV2 plan, not the Free tier. Free tiers don’t support features likeAlways On or Node.js version customization.Reference:Ask our ExpertsDid you like this Question?Your AnswerA. The web app will be deployed to the PremiumV2App Service Plan, which supports Always On andautoscalingB. The alwaysOn property ensures that WhizAppdoes not enter idle state, reducing latency for first-time requests.D. The serverFarmId property links the web app tothe App Service Plan, enabling shared scaling andpricingCorrect AnswerA. The web app will be deployed to the PremiumV2App Service Plan, which supports Always On andautoscalingB. The alwaysOn property ensures that WhizAppdoes not enter idle state, reducing latency for first-time requests.D. The serverFarmId property links the web app tothe App Service Plan, enabling shared scaling andpricing
Why it’s correct: PremiumV2 offers all required production-grade features like Always On and autoscaling.Why it’s correct: Prevents cold start, ensuring better responsiveness for users.Why it’s correct: Enables compute sharing, resource scaling, and centralized billing.Why it’s wrong: The app is set to use Node.js v14, not v18.Why it’s wrong: This deployment is explicitly configured to use PremiumV2, not the Free tier.https://learn.microsoft.com/en-us/azure/app-service/provision-resource-bicep?pivots=app-service-bicep-linux
10/5/25, 15:20LMS | Whizlabs
Page 61 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectQuestion 37Domain: Monitor and maintain Azure resourcesYou are tasked with monitoring Azure virtual machines across multiple environments. Virtual machines have several components,each requiring its own level of monitoring. Match each VM layer to its most appropriate monitoring description.Note: Drag the appropriate feature name and drop them to the correct description
Explanation:Correct Answers: A-1, B-2, C-3 and D-4Virtual machine host: Underlying Azure Service Fabric that runs your virtual machine. Useful for tracking platform events like hostfailures or redeploymentsGuest operating system: Installed OS (Windows/Linux) inside the VM. Monitor using agents to track logs, resource usage, and systemhealthWorkloads: Critical background services (e.g., web servers, databases) that support application functions. Require telemetry forYour AnswersA. Virtual machine hostUnderlying Azure Service Fabric that runs your virtual machine.Useful for tracking platform events like host failures orredeploymentsB. Guest operating systemInstalled OS (Windows/Linux) inside the VM. Monitor using agents totrack logs, resource usage, and system healthC. WorkloadsCritical background services (e.g., web servers, databases) thatsupport application functions. Require telemetry for performanceand uptimeD. ApplicationsFrontend or business apps hosted on VMs, accessed by users.Requires monitoring for responsiveness, errors, and user experienceCorrect AnswersA. Virtual machine hostUnderlying Azure Service Fabric that runs your virtual machine. Useful fortracking platform events like host failures or redeploymentsB. Guest operating systemInstalled OS (Windows/Linux) inside the VM. Monitor using agents to tracklogs, resource usage, and system healthC. WorkloadsCritical background services (e.g., web servers, databases) that supportapplication functions. Require telemetry for performance and uptimeD. ApplicationsFrontend or business apps hosted on VMs, accessed by users. Requiresmonitoring for responsiveness, errors, and user experience
10/5/25, 15:20LMS | Whizlabs
Page 62 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
performance and uptimeApplications: Frontend or business apps hosted on VMs, accessed by users. Requires monitoring for responsiveness, errors, and userexperience.
[Source: Microsoft Documentation]Option A: Virtual machine host → Azure Service Fabric Monitoring is correct match: The VM host is the Azure-managed infrastructurewhere your VM runs. Monitoring this layer helps detect platform-level disruptions.Option B: Guest operating system → OS-Level Insights is correct match: This is the Windows or Linux OS installed inside the VM. It'syour responsibility to monitor its health, patches, and resource usage.Option C: Workloads → Backend Services Monitoring is correct match: Workloads refer to application support layers — such asdatabases, APIs, or middleware — that your actual apps rely on.Option D: Applications → End-User App Monitoring is correct match: These are the business-critical applications accessed by endusers, like ERP systems, customer portals, etc. Why it’s correct: Focuses on host-level reliability. Azure sends signals when the physical machine or hypervisor undergoesplanned or unplanned events.Why it’s correct:  Use diagnostics and performance counters to watch CPU, memory, and system event logs — helpful for capacityplanning and troubleshooting.Why it’s correct: These often drive the core logic or data layer of your app and need dedicated alerting for downtime or failures.Why it’s correct: Requires Application Performance Management (APM) tools like Application Insights to detect performanceissues and usage trends.
10/5/25, 15:20LMS | Whizlabs
Page 63 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
IncorrectView Case Study
IncorrectReference:  Monitor virtual machines with Azure Monitor - Azure Monitor | Microsoft LearnAsk our ExpertsDid you like this Question?Question 38Domain: Implement and manage storageTo copy the blueprint files to Azure over the Internet and ensure that they are stored in the archive storage tier, which Azure storagetype should Whizlabs use?
Explanation:Correct Answer: DAzure Blob Storage is suitable for storing unstructured data like the blueprint files, and it allows Whizlabs to copy files to Azure over theInternet. Additionally, Azure Blob Storage provides different storage tiers, including the archive storage tier, which can be used forlong-term storage with cost savings.Reference:Ask our ExpertsDid you like this Question?Question 39Domain: Manage Azure identities and governanceA. Azure File StoragewrongB. Azure Queue StorageC. Azure Table StorageD. Azure Blob Storageright
Options A, B and C are incorrect because File Storage, queues and table are not designed for storing files like blueprint files anddo not offer storage tiers like the archive storage tier.Access tiers for blob data - Azure Storage | Microsoft Learn
10/5/25, 15:20LMS | Whizlabs
Page 64 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
You're configuring external collaboration settings in Microsoft Entra ID for your organization. The security team provides two specificsecurity requirements:
Given these requirements, which two settings should you configure? (Select Two)
Explanation:Correct Answers: A and EOption A: "Guest user access is restricted to properties and memberships of their own directory objects" is correct beacuse - Thisdirectly meets the security team's requirement that guest users must only see their own directory data, helping to protect sensitiveuser and group information from external visibility.Guest users should not be able to view other users, groups, or memberships - they should only see their own profile and relatedinfo.Only administrators with specific roles (like “User Administrator” or “Guest Inviter”) should be able to invite external guest usersto the directory.A. Set "Guest user access is restricted to properties and memberships of their own directory objects" under Guest useraccessrightB. Set "Guest users have the same access as members" under Guest user accessC. Set "Anyone in the organization can invite guest users including guests and non-admins" under Guest invite settingsD. Set "Guest users have limited access to properties and memberships of directory objects" under Guest useraccesswrongE. Set "Only users assigned to specific admin roles can invite guest users" under Guest invite settingsright
This is the most restrictive setting available for guest access in Microsoft Entra ID.When this setting is enabled: Guest users can only view their own profile, groups they belong to, and nothing else. They cannotbrowse the full user directory, view other group memberships, or access other users’ data. 
10/5/25, 15:20LMS | Whizlabs
Page 65 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Option E: "Only users assigned to specific admin roles can invite guest users" is correct because - This aligns with the need for strictcontrol over guest onboarding and ensures that only authorized personnel can extend access to external users, which minimizes therisk of unauthorized sharing.
By enabling this setting: You restrict the ability to invite external users only to admins with specific roles like User Administrator,Global Administrator, or Guest Inviter. It prevents regular employees (and existing guests) from sending out invitations.
10/5/25, 15:20LMS | Whizlabs
Page 66 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
CorrectView Case StudyOption B: "Guest users have the same access as members" is incorrect because if you choose this setting: Guests can view alldirectory information available to member users, including other users, group details, and organizational structure. It’s meant forcollaborative environments where external users need full directory access — not secure environments.Option C: "Anyone in the organization can invite guest users including guests and non-admins" is incorrect because - Enabling thismeans: Any user including guests can invite more external users.There's no control over who adds external identities, which is a majorgovernance issue.Option D: "Guest users have limited access to properties and memberships of directory objects" is incorrect because - This settingdoes partially limit access, but: Guests can still see certain directory objects, such as non-hidden groups and their members.It doesn’tfully prevent them from seeing some directory-wide data.Reference:Ask our ExpertsDid you like this Question?Question 40Domain: Monitor and maintain Azure resourcesCan you send the security events of the virtual machines to the Log Analytics workspace?
Explanation:Answer – AYes, you can. Even though the virtual machines and the Log Analytics workspace are in separate locations, you can still connect thevirtual machines to the workspace.For more information on collecting data into a Log Analytics workspace, please visit the following URL-Why it’s wrong: This violates the first requirement, as guest users will gain too much visibility, putting internal information at risk.Why it’s wrong: It directly conflicts with the second requirement. You lose control of who can bring in external collaborators,increasing the risk of unwanted access.Why it’s wrong: While it sounds secure, it does not completely fulfill the first requirement. Guest users may still view other objectsbesides their own, which the security team wants to avoid.Configure external collaboration settings in Microsoft Entra ID
A. YesrightB. No
https://docs.microsoft.com/en-us/azure/azure-monitor/learn/quick-collect-azurevm
10/5/25, 15:20LMS | Whizlabs
Page 67 of 67https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/60703/report/8396634
Ask our ExpertsDid you like this Question?Finish Review
CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdHands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs

10/5/25, 15:19LMS | Whizlabs
Page 2 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
A team member has created a point-to-site VPN connection between a computer named "WorkstationA" and an Azure VirtualNetwork. Another point-to-site VPN connection needs to be made between the same Azure Virtual Network and a computer named"WorkstationB." The VPN client package was generated and installed on "WorkstationB." You need to ensure that you can create asuccessful point-to-site VPN connection.You decide to export the "Workstation A" client certificate and install it on "Workstation B."Would this solution fulfill the requirement?
Explanation:Answer – AYes, this is one of the requirements. This is also mentioned in the Microsoft documentation.
For more information on creating point-to-site VPN connections, please visit the below URL-Ask our ExpertsA. YesrightB. Nowrong
https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-point-to-site-resource-manager-portal
10/5/25, 15:19LMS | Whizlabs
Page 3 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectDid you like this Question?Question 2Domain: Implement and manage storageYou have a storage account named whizlabstore. You have created a file share named demo using the file service. You need toensure that users can connect to the file share from their home computers. Which of the following port should be open to provide theconnectivity?
Explanation:Answer – CTo access files from home computers, users have to use SMB protocol that expects port 445 to be open.This is clearly given in the Microsoft documentation.
A. 80wrongB. 443C. 445rightD. 3389
10/5/25, 15:19LMS | Whizlabs
Page 4 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectFor more information on using file shares in Azure, please visit the below URL-Ask our ExpertsDid you like this Question?Question 3Domain: Implement and manage storageA company has created a storage account in its Azure subscription. The name of the storage account is whizlabstore. They have alsocreated a file share named demo. They need to access the files in the file share via a UNC path.You need to fill in the following blocks to ensure that the right UNC path is provided.
Which of the following needs to go into Slot1?
Explanation:Answer – Fhttps://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-windows
A. blobB. blob.core.windows.netC. portal.azure.comD. fileE. file.core.windows.netF. whizlabstorerightG. demo
10/5/25, 15:19LMS | Whizlabs
Page 5 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectTo work with UNC path format, you have to mount the Azure file share with File Explorer. The UNC path format is:\\.file.core.windows.net\or in our case:\\whizlabstore.file.core.windows.net\demo For more information on using Aure file share service, please visit the below URLs-https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-windowshttps://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file?redirectedfrom=MSDNAsk our ExpertsDid you like this Question?Question 4Domain: Implement and manage storageA company has created a storage account in their Azure subscription. The name of the storage account is whizlabstore. They havealso created a file share named demo. They need to access the files in the file share via a UNC path.You need to fill in the following blocks to ensure that the right UNC path is provided.
Which of the following needs to go into Slot2?A. blobB. blob.core.windows.netC. portal.azure.comD. filewrongE. file.core.windows.netright
10/5/25, 15:19LMS | Whizlabs
Page 6 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectExplanation:Answer – ETo work with UNC path format, you have to mount the Azure file share with File Explorer. The UNC path format is:\\.file.core.windows.net\or in our case:\\whizlabstore.file.core.windows.net\demoFor more information on using Aure file share service, please visit the below URLs-
Ask our ExpertsDid you like this Question?Question 5Domain: Implement and manage storageA company has created a storage account in their Azure subscription. The name of the storage account is whizlabstore. They havealso created a file share named demo. They need to access the files in the file share via a UNC path.You need to fill in the following blocks to ensure that the right UNC path is provided.
Which of the following needs to go into Slot3?F. whizlabstoreG. demo
https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-windowshttps://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file?redirectedfrom=MSDN
A. blob
10/5/25, 15:19LMS | Whizlabs
Page 7 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectView Case StudyExplanation:Answer – GUNC stand for Universal naming convention. UNC is used  for Microsoft Windows for accessing shared network folder .and printer.Generic naming convention for UNC is given below: \\host-name\share-name\file pathTo work with UNC path format, you have to mount the Azure file share with File Explorer. The UNC path format is:\\.file.core.windows.net\or in our case:\\whizlabstore.file.core.windows.net\demoFrom the above is it clear that G is the correct answer  all other answers are wrong.For more information on using Azure file share service, please visit the below URLs-
Ask our ExpertsDid you like this Question?Question 6Domain: Implement and manage virtual networkingWould Virtual Machines launched in the whizlab-client virtual network automatically get registered in the private domain ofprivate.whizlabs.com if auto registration is enabled?B. blob.core.windows.netC. portal.azure.comwrongD. fileE. file.core.windows.netF. whizlabstoreG. demoright
https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-windowshttps://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file?redirectedfrom=MSDN
A. Yesright
10/5/25, 15:19LMS | Whizlabs
Page 8 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Explanation:Answer – ASo below is the representation of the network based on the details given in the question.
Since the whizlab-client is registered with the private hosted zone, automatic registration of VM’s is possible.This is also given in the Microsoft documentation.B. No
10/5/25, 15:19LMS | Whizlabs
Page 9 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
For more information on private DNS zones, please visit the below URL-
Ask our ExpertsDid you like this Question?Question 7Domain: Implement and manage virtual networkingA company has set up a Virtual Machine in Azure. A web server listening on port 80 and a DNS server has been installed on the Virtualmachine. A network security group is attached to the network interface for the virtual machine. The rules for the NSG are given below.Inbound Ruleshttps://docs.microsoft.com/en-us/azure/dns/private-dns-overviewhttps://docs.microsoft.com/en-us/azure/dns/private-dns-autoregistration
10/5/25, 15:19LMS | Whizlabs
Page 10 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Outbound Rules
If RuleB is deleted/omitted, please select the service through which Internet users connect to the virtual machine.
Explanation:Answer – DIf RuleB is deleted, users won’t be able to access port 80 and the web server.There is a Deny rule of RuleA for ports 50-60. Since DNS listens on port 53, you will not be able to access the DNS server. But you will stillbe able to connect to the virtual machine using Remote Desktop Protocol (RDP) under the Allow_rdp rule.Because of this logic, all other options are incorrect.For more information on network security, please visit the below URL-A. Through the web server B. Through the DNS server C. both Web and DNS serversD. Through RDPrightE. Through RDP, Web, and DNS servers
Azure network security groups overview | Microsoft Docs
10/5/25, 15:19LMS | Whizlabs
Page 11 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectAsk our ExpertsDid you like this Question?Question 8Domain: Implement and manage storageYour company has set up a storage account in Azure, as shown below.
The company needs to allow only connections to the storage account from an IP address range of 51.107.2.0 to 51.107.2.255. From whichof the following section of the storage account would you modify to fulfill this requirement?
Explanation:Answer – AThis can be done from the Networking, as shown below.A. NetworkingrightB. Advanced securityC. Soft DeleteD. Lifecycle Management
10/5/25, 15:19LMS | Whizlabs
Page 12 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
Ensure to click on “Selected networks” and then enter the IP address range.Since this is clear from the implementation, all other options are incorrect.For more information on the Firewall and virtual network feature, please visit the below URL-https://docs.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal Ask our ExpertsDid you like this Question?Question 9Domain: Implement and manage storageYour company has set up a storage account in Azure, as shown below.
10/5/25, 15:19LMS | Whizlabs
Page 13 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
There is a requirement to retain any blob data that might accidentally be deleted. The deleted data needs to be retained for 14 days.From which of the following option of the storage account would you modify to fulfill this requirement?
Explanation:Answer – CThis can be done from the Data Protection option/tab from the storage account at any time by using the Azure portal, PowerShell, orAzure CLI.
A. Firewall and virtual networksB. Advanced securityC. Data Protection(Soft Delete)rightD. Lifecycle Management
10/5/25, 15:19LMS | Whizlabs
Page 14 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
 Blob soft delete protects an individual blob, snapshot, or version from accidental deletes or overwrites by maintaining the deleteddata in the system for a specified period of time. During the retention period, you can restore a soft-deleted object to its state at thetime it was deleted.Since this is clear from the implementation, all other options are incorrect. Reference: Enable soft delete for blobs - Azure Storage | Microsoft Learn Ask our ExpertsDid you like this Question?Question 10Domain: Deploy and manage Azure compute resourcesA company wants to deploy a virtual machine using a Resource Manager template. The template needs to be submitted via Azure CLIcommands. The template is stored in a file named storage.json.You need to complete the below CLI command.
10/5/25, 15:19LMS | Whizlabs
Page 15 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into SLOT 1?
Explanation:Answer - BSLOT 1 covers the word "deployment".
All other options are incorrect.A. templatewrongB. deploymentrightC. resourceD. vm
10/5/25, 15:19LMS | Whizlabs
Page 16 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectFor more information on deploying templates via the CLI, please visit the below URL-Ask our ExpertsDid you like this Question?Question 11Domain: Deploy and manage Azure compute resourcesA company wants to deploy a virtual machine using a Resource Manager template. The template needs to be submitted via Azure CLIcommands. The template is stored in a file named storage.json.You need to complete the below CLI command.
Which of the following would go into SLOT 2?
Explanation:Answer - CSLOT 2 covers "--template-file" option.https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy-cli
A. --templateB. --template-uriC. --template-filerightD. --template-resource
10/5/25, 15:19LMS | Whizlabs
Page 17 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
All other options are incorrect.For more information on deploying templates via the CLI, please visit the below URL-Ask our ExpertsDid you like this Question?Question 12Domain: Manage Azure identities and governanceA company has set up an Azure subscription and a tenant. They want to ensure that only Virtual Machines of a particular SKU size canbe launched in their Azure account.They decide to implement Role-Based access control.Does this fulfill the requirement?https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-template-deploy-cli
A. YeswrongB. Noright
10/5/25, 15:19LMS | Whizlabs
Page 18 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer — BRole-based access control can be used to restrict access to resources. RBAC does not put any governance, regarding type ofresources to be created. If you need to limit the resource creation, like provision VM's  only of a particular SKU's, you need to implementAzure policies.You can use allowed virtual machine policy in this scenario: For more information on policy and role-based access control, please refer to following list. Policy -- Overview of Azure Policy - Azure Policy | Microsoft DocsRBAC -- https://docs.microsoft.com/en-us/azure/role-based-access-control/overviewAsk our ExpertsDid you like this Question?Question 13Domain: Manage Azure identities and governanceA company has set up an Azure subscription and a tenant. They want to ensure that only Virtual Machines of a particular SKU size canbe launched in their Azure account.They decide to implement Azure locks.Does this fulfill the requirement?
Explanation:Answer - BAzure locks are used to prevent users from accidentally deleting or modifying critical resources. If you need to limit the resourcecreation, like provision VM only of a particular SKU, you need to implement Azure policies. For more information on Azure locks, please visit the below URL-Allowed Virtual Machine SKUs (Deny): Specifies a set of virtual machine SKUs that you can deploy as parameter to this policy.Any  VM SKU which is not in the  parameter list, cannot be created as per  this policy. Users will get a message  “VM SKU “is notallowed by the policy -- Allowed Virtual Machine SKUs. 
A. YesB. Noright
10/5/25, 15:19LMS | Whizlabs
Page 19 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectAsk our ExpertsDid you like this Question?Question 14Domain: Manage Azure identities and governanceA company has set up an Azure subscription and a tenant. They want to ensure that only Virtual Machines of a particular SKU size canbe launched in their Azure account.They decide to implement Azure policies.Does this fulfill the requirement?
Explanation:Answer - AYes, this can be done with Azure policies. There is also already an in-built policy which can implement this policy as shown below.https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-lock-resources
A. YesrightB. No
10/5/25, 15:19LMS | Whizlabs
Page 20 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
For more information on an example on this, please visit the below URL-Ask our ExpertsDid you like this Question?Question 15Domain: Implement and manage virtual networkingA company plans to use Azure Network watcher to perform the following tasks.
Which of the following Network watcher feature would you use for the following requirement?"Find out if a network security rule is preventing a network packet from reaching a virtual machine hosted in an Azure virtualnetwork."https://docs.microsoft.com/en-us/azure/governance/policy/samples/allowed-skus-storage
Find out if a network security rule prevents a network packet from reaching a virtual machine hosted in an Azure virtualnetwork.Find out if there is outbound connectivity between an Azure virtual machine and an external host.
A. IP Flow Verifyright
10/5/25, 15:19LMS | Whizlabs
Page 21 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Explanation:Answer – AThis can be done with the IP Flow Verify feature. The Microsoft documentation mentions the following.
Option B is incorrect since this feature is used to get the next hop type and IP address of a specific VM packet. Option C is incorrect since this feature is used for deep-dive network packet capture.Option D is incorrect since this feature is a cloud-based solution that provides visibility into user and application activity in cloudnetworks.For more information on the IP Flow Verify feature, please visit the below URL-Ask our ExpertsDid you like this Question?B. Next HopC. Packet CapturewrongD. Traffic Analysis
https://docs.microsoft.com/en-us/azure/network-watcher/network-watcher-ip-flow-verify-overview
10/5/25, 15:19LMS | Whizlabs
Page 22 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectQuestion 16Domain: Implement and manage virtual networkingA company plans to use Azure Network watcher to perform the following tasks.
Which of the following network watcher feature would you use for the following requirement?"Find out if there is outbound connectivity between an Azure virtual machine and an external host."
Explanation:Answer – CThis can be done with the Connection Monitor feature. The Microsoft documentation mentions the following.
Find out if a network security rule prevents a network packet from reaching a virtual machine hosted in an Azure virtualnetwork.Find out if there is outbound connectivity between an Azure virtual machine and an external host.
A. IP Flow VerifywrongB. Next HopC. Connection MonitorrightD. Traffic Analytics
10/5/25, 15:19LMS | Whizlabs
Page 23 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectOption A is incorrect since this feature is used to verify traffic flow based on security group rules.Option B is incorrect since this feature is used to get the next hop type and IP address of a specific VM packet.Option D is incorrect since this feature is a cloud-based solution that provides visibility into user and application activity in cloudnetworks.For more information on the network watcher tool, please visit the below URL-
Ask our ExpertsDid you like this Question?Question 17Domain: Deploy and manage Azure compute resourcesA company is planning to deploy an application to a set of Virtual Machines in an Azure network. The company needs to have an SLAof 99.99% for the application hosted on the Virtual machines. Which of the following should be implemented to guarantee an SLA of99.99% on the infrastructure level?
Explanation:Answer – BYou can achieve 99.99% SLA on your virtual machines' infrastructure level by deploying them across availability zones.The Microsoft documentation mentions the following.https://docs.microsoft.com/en-us/azure/network-watcher/connection-monitor-overviewhttps://docs.microsoft.com/en-us/learn/modules/troubleshoot-azure-network-infrastructure/2-troubleshoot-networking-with-network-watcher
A. Make the virtual machines part of an availability set.B. Deploy the virtual machines across availability zones.rightC. Assign a standard public IP address to the virtual machines.D. Deploy single virtual machines across multiple regions.
10/5/25, 15:19LMS | Whizlabs
Page 24 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Option A is incorrect since availability sets can only guarantee an SLA of 99.95%.Option C is incorrect since this will not help ensure 99.99% availability for the architecture.Option D is incorrect since this is normally used for disaster recovery purposes.For more information on availability zones, please visit the below URL-Ask our ExpertsDid you like this Question?Question 18Domain: Implement and manage storageYour company wants to provision an Azure storage account. The storage account needs to meet the following requirements.
You need to complete the below command to create the storage account.https://docs.microsoft.com/en-us/azure/availability-zones/az-overview
Should be able to support hot, cool, and archive blob tiers.Should be able to provide fault tolerance if a disaster hits the Azure region, which has the storage account.Should minimize on costs.
10/5/25, 15:19LMS | Whizlabs
Page 25 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot1?
Explanation:Answer – CThe task requires to support the Hot, Cool, and Archive tiers. There is only one option from our list of options that can provide this:StorageV2 or General Purpose v2 Storage Account. With this storage account type, we will have the complete functionality of the BLOBservice.A. FileStorageB. StorageC. StorageV2rightD. TableE. BlockBlobStoragewrong
boDashboardMy CoursesHands-on LabsSandboxSupport

10/5/25, 15:19LMS | Whizlabs
Page 26 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
Option A is incorrect since it does not support the access tiers.Option B is incorrect since it does not support the access tiers.Option D is incorrect since this is a service and not a storage account kind.Option E is incorrect since it does not support the access tiers.For more information on storage accounts, please visit the below URL-Ask our ExpertsDid you like this Question?Question 19Domain: Implement and manage storageYour company wants to provision an Azure storage account. The storage account needs to meet the following requirements.https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview
Should be able to support hot, cool, and archive blob tiers.Should be able to provide fault tolerance if a disaster hits the Azure region, which has the storage account.Should minimize on costs.
10/5/25, 15:19LMS | Whizlabs
Page 27 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
You need to complete the below command to create the storage account.
Which of the following would go into Slot2?
Explanation:Answer – AStandard_GRS, which is geo-redundant storage would ensure that data is available in a secondary region if the primary region goesdown.The Microsoft documentation mentions the following.A. Standard_GRSrightB. Standard_LRSC. Standard_RAGRSD. Premium_LRS
10/5/25, 15:19LMS | Whizlabs
Page 28 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Options B and D are incorrect since these don’t guarantee that data will be available if a region goes down.Option C is incorrect since the costs would be more than Standard_GRS.For more information on geo-redundant storage, please visit the below URL-Ask our ExpertsDid you like this Question?Question 20Domain: Monitor and maintain Azure resourcesCurrently, in your production environment, containerized applications are running on the Azure Kubernetes Service cluster (AKScluster). Managed disks, for persistent storage, are being used. Currently, managed disk backup is being done via automation scripts.The scripts are hard to maintain. You're working as an Azure administrator, and are expected to suggest a backup solution formanaging disk, with the following requirements:1. It should support snapshot backup lifecycle which is policy-driven and provide fast backup and recovery  2. It should have a very light admin overhead. 3. The cost of the overall solution is low https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy-grs
10/5/25, 15:19LMS | Whizlabs
Page 29 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following solutions will you select? 
Explanation:Correct Answers: B and D 
Azure backup vault supports manage disk snapshot backup lifecycle, which is policy-driven and provides fast backup and recoveryfrom the snapshot of managed disk. The backup process of the backup vault does not cause any performance issues on the virtual machine. It has virtually noadministrative overhead and low cost.  We can easily create a backup vault from the backup center.Backup Center provides a single unified management experience in Azure for enterprises to govern, monitor, operate and analysebackups at scale. The following figure shows how a backup vault can be created from the backup centerA. Azure recovery service vault B. Azure Backup vault rightC. Azure site recovery wrongD. Azure Backup Center right
Option B is correct because a backup vault can be used for managing Azure disk snapshot life cycle management, as explainedlater.Option D is correct because the backup center is the best option for creating the backup vault Option A is incorrect because the recovery service, vault, does not support, disk snapshot life cycle management. Option C is incorrect because Azure site recovery is used for creating disaster recovery sites. 
10/5/25, 15:19LMS | Whizlabs
Page 30 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
For more details, please refer to the following Azure documentation link https://docs.microsoft.com/en-us/Azure/backup/disk-backup-overview https://docs.microsoft.com/en-us/Azure/backup/backup-center-overview
10/5/25, 15:19LMS | Whizlabs
Page 31 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectAsk our ExpertsDid you like this Question?Question 21Domain: Monitor and maintain Azure resourcesA team has set up Log Analytics for a virtual machine named demovm. They are running the following query in the Log AnalyticsWorkspace.Perf| where Computer == "demovm"| where ObjectName == "Processor" and CounterName == "% Processor Time"| summarize avg(CounterValue) by bin(TimeGenerated, 1h), Computer| render timechartIn which of the following formats will the data be displayed?
Explanation:Answer – DTo determine the format in which the data will be displayed, we need to understand the structure of the query being run in the LogAnalytics Workspace.1. Table with 2 Columns:Perf| where TimeGenerated > ago(1h)| project Computer, CounterValueOutput: A table with columns Computer and CounterValue2. Table with 3 Columns:A. table that has 2 columnswrongB. table that has 3 columnsC. graph that has the Computer values on the Y axisD. graph that has the avg(CounterValue) values on the Y axisright
If the query selects two specific fields, the result will be a table with two columns.Example Query:
If the query selects three specific fields, the result will be a table with three columns.
10/5/25, 15:19LMS | Whizlabs
Page 32 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectPerf| where TimeGenerated > ago(1h)| project Computer, CounterName, CounterValueOutput: A table with columns Computer, CounterName, and CounterValue.3. Graph with Computer Values on the Y Axis:Perf| where TimeGenerated > ago(1h)| summarize avg(CounterValue) by Computer| render barchartOutput: A graph (e.g., bar chart) with Computer values on the Y axis.4. Graph with avg(CounterValue) Values on the Y Axis:Perf| where TimeGenerated > ago(1h)| summarize avg(CounterValue) by Computer| render timechartOutput: A graph (e.g., time chart) with avg(CounterValue) values on the Y axis.Without the specific query, the most likely answer based on common usage patterns in Log Analytics is graph that has theavg(CounterValue) values on the Y axisThis is because queries often involve summarizing performance metrics and visualizing them over time or by different dimensions.For more information on performing log queries, please visit the URL below-Ask our ExpertsDid you like this Question?Question 22Domain: Deploy and manage Azure compute resourcesYou have a virtual machine (VM) named myVM that is using Azure Disk Encryption and is currently located in the resource groupoldResourceGroup in the region eastus. You need to recreate this VM in a different region (westus) and resource groupExample Query:
If the query is designed to visualize data with Computer values on the Y axis, it typically involves a summarization or aggregation.Example Query:
If the query is designed to visualize data with avg(CounterValue) on the Y axis, it involves summarization or aggregation.Example Query:
https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/log-query-overview
10/5/25, 15:19LMS | Whizlabs
Page 33 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
(newResourceGroup), since encrypted VMs cannot be moved across regions directly.Using the Azure CLI, arrange the following steps in the correct order to achieve this:
Explanation:Correct Answer: B, D, A, and CA virtual machine that is integrated with a key vault to implement Azure Disk Encryption for Linux VMs or Azure Disk Encryption forWindows VMs can be moved to another resource group when it is in a deallocated state.However, to move such a virtual machine to another subscription, you must disable encryption.To move a virtual machine (VM) named "myVM" to a different resource group, subscription, and region using the Azure CLI, here is thecorrect order of steps:The correct order of steps is B, D, A & C.
Reference:Ask our ExpertsDid you like this Question?Your Answer1.A. az vm wait --name myVM --resource-groupoldResourceGroup --deleted2.B. az vm deallocate --name myVM --resource-group oldResourceGroup3.D. az group create --namenewResourceGroup --location newRegion4.C. az vm create --name myVM --resource-group newResourceGroup --locationnewRegion --source oldResourceGroupCorrect Answer1.B. az vm deallocate --name myVM --resource-group oldResourceGroup2.D. az group create --namenewResourceGroup --location newRegion3.A. az vm wait --name myVM --resource-group oldResourceGroup --deleted4.C. az vm create --name myVM --resource-group newResourceGroup --locationnewRegion --source oldResourceGroup
B. az vm deallocate --name myVM --resource-group oldResourceGroup : Stop the VM in the old resource group.D. az group create --name newResourceGroup --location newRegion: Create a new resource group in the desired region.A. az vm wait --name myVM --resource-group oldResourceGroup --deleted: Wait for the VM to be deleted from the old resourcegroup.C. az vm create --name myVM --resource-group newResourceGroup --location newRegion --source oldResourceGroup : Movethe VM to the new resource group and region.Move Azure VMs to new subscription or resource group - Azure Resource Manager | Microsoft Learn
10/5/25, 15:19LMS | Whizlabs
Page 34 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
CorrectQuestion 23Domain: Deploy and manage Azure compute resourcesWhen managing virtual machine disks in Azure, which of the following options allows you to increase the size of a virtual hard disk(VHD) without detaching it from the virtual machine?
Explanation:Correct Answer: DAzure Managed Disks provide a convenient way to manage virtual machine disks. With Azure Managed Disks, you can easily increasethe size of a virtual hard disk (VHD) without detaching it from the virtual machine. This scalability feature allows you to adjust thestorage capacity as needed without disrupting the VM's operation.
Reference:Ask our ExpertsDid you like this Question?Question 24Domain: Deploy and manage Azure compute resourcesWhizlabs Corporation is looking to deploy containerized applications in Azure and needs a container registry to store their Dockerimages. Which of the following Azure service provides a private and secure repository for storing Docker container images?A. Azure Blob StorageB. Azure Disk EncryptionC. Azure Virtual Disk ResizewrongD. Azure Managed Disksright
Option A is incorrect because Azure Blob Storage is primarily used for unstructured data storage and is not directly related toresizing virtual machine disks.Option B is incorrect because Azure Disk Encryption is a security feature for encrypting virtual machine disks and does not offerdisk resizing capabilities.Option C is incorrect because there is no specific "Azure Virtual Disk Resize" feature. The resizing of virtual disks is typicallymanaged through Azure Managed Disks.Option D is correct because Azure managed disks can be resized by changing the configuration of the disk.Expand virtual hard disks attached to a Windows VM in an Azure - Azure Virtual Machines | Microsoft Learn
10/5/25, 15:19LMS | Whizlabs
Page 35 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Correct Answer: CAzure Container Registry (ACR) is a private and secure repository for storing Docker container images. It allows organizations tomanage and distribute container images securely, making it an essential service for containerized applications in Azure.
References:
Ask our ExpertsDid you like this Question?Question 25Domain: Manage Azure identities and governanceA company has set up an Azure subscription. They have provisioned a storage account and are currently using the BLOB service. Theywant to assign permissions to 3 user groups.A. Azure Kubernetes Service (AKS)B. Azure Container Instances (ACI)C. Azure Container Registry (ACR)rightD. Azure Container Service (ACS)
Option A is incorrect because Azure Kubernetes Service (AKS) is a managed Kubernetes container orchestration service, not acontainer registry.Option B is incorrect Azure Container Instances (ACI) is a serverless container service for running containers, but it does notprovide container image storage.Option C is correct because Azure Container Registry (ACR) is a private and secure repository for storing Docker containerimages. It allows organizations to manage and distribute container images securely, making it an essential service forcontainerized applications in Azure.Option D is incorrect because Azure Container Service (ACS) is an older service that has been deprecated in favor of AzureKubernetes Service (AKS) for managing Kubernetes clusters.Azure Container Registry | Microsoft AzureManaged container registries - Azure Container Registry | Microsoft Learn
GroupA – This group should have the ability to manage the storage account.GroupB – This group should be able to manage containers within a storage account.GroupC – This group should be given full access to Azure Storage blob containers and data, including assigning POSIX access
10/5/25, 15:19LMS | Whizlabs
Page 36 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
You need to assign the relevant Role-Based Access Control, ensuring the privilege of least access.Which of the following would you assign to GroupA?
Explanation:Answer – CThis can be accomplished by the Storage Account Contributor.The Microsoft documentation mentions the following.
Options A and B are incorrect since these would provide more permissions than required.Options D and E are incorrect since these roles don’t have the required permissions.For more information on built-in roles, please visit the below URL-control.
A. OwnerB. ContributorC. Storage Account ContributorrightD. Storage Blob Data ContributorE. Storage Blob Data Owner
10/5/25, 15:19LMS | Whizlabs
Page 37 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectAsk our ExpertsDid you like this Question?Question 26Domain: Manage Azure identities and governanceA company has set up an Azure subscription. They have provisioned a storage account and are currently using the BLOB service. Theywant to assign permissions to 3 user groups.
You need to assign the relevant Role-Based Access Control, ensuring the privilege of least access.Which of the following would you assign to GroupB?
Explanation:Answer – DThis can be accomplished with the Storage Blob Data Contributor.The Microsoft documentation mentions the following.https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
GroupA – This group should have the ability to manage the storage account.GroupB – This group should be able to manage containers within a storage account.GroupC – This group should be given full access to Azure Storage blob containers and data, including assigning POSIX accesscontrol.
A. OwnerB. ContributorC. Storage Account ContributorD. Storage Blob Data ContributorrightE. Storage Blob Data Owner
10/5/25, 15:19LMS | Whizlabs
Page 38 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Options A and B are incorrect since these would provide more permissions than required.Options C and E are incorrect since these roles don’t have the required permissions.For more information on built-in roles, please visit the below URL-Ask our ExpertsDid you like this Question?Question 27Domain: Manage Azure identities and governanceA company has set up an Azure subscription. They have provisioned a storage account and are currently using the BLOB service. Theywant to assign permissions to 3 user groups.
You need to assign the relevant Role-Based Access Control, ensuring the privilege of least access.https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
GroupA – This group should have the ability to manage the storage account.GroupB – This group should be able to manage containers within a storage account.GroupC – This group should be given full access to Azure Storage blob containers and data, including assigning POSIX accesscontrol.
10/5/25, 15:19LMS | Whizlabs
Page 39 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would you assign to GroupC?
Explanation:Answer – EThis can be accomplished with the Storage Blob Data Owner. The Microsoft documentation mentions the following.
Options A and B are incorrect since these would provide more permissions than required.Options C and D are incorrect since these roles don’t have the required permissions.For more information on built-in roles, please visit the below URL-Ask our ExpertsA. OwnerwrongB. ContributorC. Storage Account ContributorD. Storage Blob Data ContributorE. Storage Blob Data Ownerright
https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles
10/5/25, 15:19LMS | Whizlabs
Page 40 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectDid you like this Question?Question 28Domain: Manage Azure identities and governanceA company is planning to use the Azure Import/Export service to move data out of its Azure Storage account. Which of the followingservice could be used when defining the Azure Export job?
Explanation:Answer – AOnly the BLOB service is supported by the Export job feature. This is also given in the Microsoft documentation.
Since this is clearly mentioned, all other options are incorrect.For more information on Azure import/export requirements, please visit the below URL-A. BLOB storagerightB. File storageC. Queue storagewrongD. Table storage
10/5/25, 15:19LMS | Whizlabs
Page 41 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectAsk our ExpertsDid you like this Question?Question 29Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to add data disks to an existing virtual machine. Below is the incomplete script.
Which of the following would go into Slot1?
Explanation:Answer – BAn example of this is given in the Microsoft documentation.https://docs.microsoft.com/en-us/azure/storage/common/storage-import-export-requirements
A. New-AzDiskwrongB. New-AzDiskConfigrightC. Add-AzVMDataDiskD. Set-AzDisk
10/5/25, 15:19LMS | Whizlabs
Page 42 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on managing data disk, please visit the below URL-Ask our ExpertsDid you like this Question?Question 30Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to add data disks to an existing virtual machine. Below is the incomplete script.
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
10/5/25, 15:19LMS | Whizlabs
Page 43 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot2?
Explanation:Answer - AAn example of this is given in the Microsoft documentation.
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on managing data disk, please visit the below URL-Ask our ExpertsDid you like this Question?A. New-AzDiskrightB. New-AzDiskConfigC. Add-AzVMDataDiskwrongD. Set-AzDisk
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
10/5/25, 15:19LMS | Whizlabs
Page 44 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectQuestion 31Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to be used to add data disks to an existing virtual machine. Below is theincomplete script.
Which of the following would go into Slot3?
Explanation:Answer – CAn example of this is given in the Microsoft documentation.A. Set-AzVMB. UpdateAzVMwrongC. Get-AzVMrightD. New-AzVM
10/5/25, 15:19LMS | Whizlabs
Page 45 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on managing data disk, please visit the below URL-Ask our ExpertsDid you like this Question?Question 32Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to be used to add data disks to an existing virtual machine. Below is theincomplete script.https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
10/5/25, 15:19LMS | Whizlabs
Page 46 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot 4?
Explanation:Correct Answer - COption C is correct because Add-AzVMDataDisk is the appropriate command to attach a data disk to an existing virtual machine. Itallows specifying the virtual machine, data disk, and parameters like LUN and CreateOption. This matches the context of Slot 4 inthe script.An example of this is given in the Microsoft documentation.A. New-AzDiskB. New-AzDiskConfigwrongC. Add-AzVMDataDiskrightD. Set-AzDisk
10/5/25, 15:19LMS | Whizlabs
Page 47 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
Since this is given in the Microsoft documentation, all other options are incorrect.Option A is incorrect because New-AzDisk is used to create a new managed disk in Azure, not to attach a data disk to an existingvirtual machine. In this scenario, the disk has already been created, so this command is unnecessary.Option B is Incorrect because New-AzDiskConfig is used to create a configuration object for a new disk. While it is part of the processto define a disk, it does not act to attach the disk to a virtual machine.Option D is incorrect because Set-AzDisk is used to update the properties of an existing managed disk in Azure. It does not attach adata disk to a virtual machine, which is the required action for this scenario.Reference:Ask our ExpertsDid you like this Question?Question 33Domain: Deploy and manage Azure compute resourcesAs an IT admin, you have to develop scripts that need to be used to add data disks to an existing virtual machine. Below is theincomplete script.https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
10/5/25, 15:19LMS | Whizlabs
Page 48 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot5?
Explanation:Correct Answer – BThe Update-AzVM cmdlet is used to apply changes to an existing virtual machine after modifications have been made, such asadding a data disk. This ensures that the changes are saved and the VM configuration is updated accordingly
Option A is incorrect. Set-AzVM: This cmdlet is used to set the properties of a virtual machine object in memory. It does not applyA. Set-AzVMwrongB. Update-AzVMrightC. Get-AzVMD. New-AzVM
10/5/25, 15:19LMS | Whizlabs
Page 49 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correctchanges to the actual VM in Azure. It is typically used in conjunction with other cmdlets to build a VM configuration before creating orupdating the VM.Option C is incorrect. Get-AzVM: This cmdlet retrieves information about an existing virtual machine. It is used to get the current stateand properties of a VM but does not apply any changes to the VM.Option D is incorrect. New-AzVM: This cmdlet is used to create a new virtual machine. It is not applicable for updating an existing VMwith additional data disks.For more information on managing data disks, please visit the below URL-Ask our ExpertsDid you like this Question?Question 34Domain: Deploy and manage Azure compute resourcesYou have an Azure virtual machine based on the Windows Server 2016 image. You implement Azure backup for the virtual machine.You want to restore the virtual machine by using the Replace existing option.You need to go ahead and replace the virtual machine using the Azure Backup option. You have started the backup operation but itfailed and is showing an error message: VM is not in a state to allow backups.Which of the following should be done to solve this problem?
Explanation:Correct Answer – BThe backup operation failed because the VM is in Failed state. For a successful backup, the VM state should be Running, Stopped, orStopped (deallocated).https://docs.microsoft.com/en-us/azure/virtual-machines/windows/tutorial-manage-data-disk
A. Create a custom image.B. Stop the virtual machine.rightC. Allocate a new disk.D. Enable encryption on the disk.
10/5/25, 15:19LMS | Whizlabs
Page 50 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
Reference:Troubleshoot backup errors with Azure VMs - Azure Backup | Microsoft LearnAsk our ExpertsDid you like this Question?Question 35Domain: Manage Azure identities and governanceYou have an Azure subscription named whizlabstaging. Under the subscription, you create a resource group named whizlabs-rg.Then you create an Azure policy based on the “Not allowed resources types” definition. Here you define the parameters asMicrosoft.Network.virtual networks as the not allowed resource type. You assign this policy to the Tenant Root Group and a VirtualNetwork does not already exist in this subscription.Would you be able to create a virtual machine in the whizlabs-rg resource group?A. YesB. Noright
10/5/25, 15:19LMS | Whizlabs
Page 51 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer — BAzure policy is applied to the Tenant Root Group. It means that it would be applied to all subscriptions and all resource groups withinthe subscription. A VM can be created only inside a network. If you need to create a virtual machine, you must have permission tocreate virtual network resources, required for VM provisioning. This policy “not allowed resources type" includes Microsoft.Network in its parameter list. So the policy will not allow the creation of anynetwork resources. So, B is the correct answer. For more information on creating Azure Policies, please visit the below URL:Ask our ExpertsDid you like this Question?Question 36Domain: Implement and manage virtual networkingA company currently has the following networks defined in Azure.NameAddress spacewhizlab-vnet110.1.0.0/16whizlab-vnet210.2.0.0/16whizlab-vnet310.3.0.0/16All virtual networks are hosting virtual machines with varying workloads. A virtual machine named whizlab-detect hosted in whizlab-vnet2. This virtual machine will have an intrusion detection software installed on it. All traffic on all virtual networks must be routed viathis virtual machine.You need to complete the required steps for implementing this requirement.You are going to create the virtual network peering connection for all of the virtual networks. Which of the following is important to setfor the virtual network peering connection?https://docs.microsoft.com/en-us/azure/governance/policy/overview
10/5/25, 15:19LMS | Whizlabs
Page 52 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Explanation:Correct Answer – CTo ensure that traffic can be forwarded across networks, you need to enable forwarded traffic settings.This is like the Hub and spoke model given in the Microsoft documentation wherein you need to enable forwarded traffic.
Option A is incorrect. The Classic deployment model is outdated and not recommended for new deployments. Azure ResourceManager (ARM) is the preferred deployment model, offering more features and better management capabilitiesA. Set the virtual network deployment model as Classic.B. Set the virtual network access settings as Disabled.C. Set the forwarded traffic settings as Enabled.rightD. Enable “Allow gateway transit”.
10/5/25, 15:19LMS | Whizlabs
Page 53 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectOption B is incorrect. Disabling virtual network access would prevent any communication between the virtual networks, whichcontradicts the requirement to route all traffic through the whizlab-detect VM.Option D is incorrect This setting is used to allow a virtual network to use a VPN gateway in a peered virtual network. It is not relevant tothe requirement of routing all traffic through a specific VM for intrusion detection.For more information on the hub-spoke setup, please visit the below URL-Ask our ExpertsDid you like this Question?Question 37Domain: Implement and manage virtual networkingA company currently has the following networks defined in Azure.NameAddress spacewhizlab-vnet110.1.0.0/16whizlab-vnet210.2.0.0/16whizlab-vnet310.3.0.0/16All virtual networks are hosting virtual machines with varying workloads. A virtual machine named whizlab-detect hosted in whizlab-vnet2. This virtual machine will have an intrusion detection software installed on it. All traffic on all virtual networks must be routed viathis virtual machine(intrusion-based device).You need to complete the required steps for implementing this requirement.Which of the following would you need to create additional to ensure that traffic is sent via the virtual machine hosting the intrusionsoftware?https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/hybrid-networking/hub-spoke
A. A new route tablerightB. Add an address spaceC. Add DNS servers
10/5/25, 15:19LMS | Whizlabs
Page 54 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer – AIn order to ensure that traffic is routed via the intrusion-based device, you need to set up a route table and add the route table to thesubnets in the other virtual networks.The diagram of the hub and spoke model also includes the use of a User-defined route (UDR), which is nothing but a custom routetable.
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on working with route tables, please visit the below URLs-
Ask our ExpertsDid you like this Question?Question 38D. Add a service endpoint
https://docs.microsoft.com/en-us/azure/virtual-network/tutorial-create-route-table-portalhttps://docs.microsoft.com/en-us/azure/virtual-wan/scenario-route-through-nva
10/5/25, 15:19LMS | Whizlabs
Page 55 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Domain: Implement and manage virtual networkingA company currently has the following networks defined in Azure.NameAddress spacewhizlab-vnet110.1.0.0/16whizlab-vnet210.2.0.0/16whizlab-vnet310.3.0.0/16All virtual networks are hosting virtual machines with varying workloads. A virtual machine named whizlab-detect is hosted inwhizlab-vnet2. This virtual machine will have an intrusion detection software installed on it. All traffic on all virtual networks must berouted via this virtual machine(intrusion-based device)You need to complete the required steps for implementing this requirement.Which of the following needs to be enabled on the virtual machine whizlab-detect?
Explanation:Answer - AIn order to ensure traffic can be forwarded, you need to enable IP forwarding. An example of this is given in the Microsoftdocumentation.A. Enable IP forwarding.rightB. Enable the identity for the virtual machine.C. Add an extension to the virtual machine.D. Change the size of the virtual machine.
10/5/25, 15:19LMS | Whizlabs
Page 56 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
 
Since this is clearly given in the Microsoft documentation, all other options are incorrect.For more information on working with route tables, please visit the below URL-https://docs.microsoft.com/en-us/azure/virtual-network/tutorial-create-route-table-portal
10/5/25, 15:19LMS | Whizlabs
Page 57 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
CorrectAsk our ExpertsDid you like this Question?Question 39Domain: Manage Azure identities and governanceA company is planning to use Azure for the various services they offer. They want to ensure that they can bill each department for theresources they consume. They decide to use Azure policies to separate the bills department wise.Would this fulfill the requirement?
Explanation:Answer – BAzure policies are used from a governance perspective and can’t be used to create bills department wise.For more information on Azure policies, please visit the below URL-Ask our ExpertsDid you like this Question?Question 40Domain: Manage Azure identities and governanceA company is planning to use Azure for the various services they offer. They want to ensure that they can bill each department for theresources they consume. They decide to use Azure resource tags to separate the bills department wise.Would this fulfill the requirement?A. YesB. Noright
https://docs.microsoft.com/en-us/azure/governance/policy/overview
A. YesrightB. No
10/5/25, 15:19LMS | Whizlabs
Page 58 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer – AYes, you can use resource tags to organize your Azure resources and also apply billing techniques department wise. The Microsoftdocumentation mentions the following.
For more information on tagging resources, please visit the below URLs-
Ask our ExpertsDid you like this Question?Question 41Domain: Manage Azure identities and governanceA company is planning to use Azure for the various services they offer. They want to ensure that they can bill each department for theresources they consume. They decide to use Azure role-based access control to separate the bills department wise.https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/tag-resourceshttps://docs.microsoft.com/en-us/azure/cloud-adoption-framework/decision-guides/resource-tagging/?toc=/azure/azure-resource-manager/management/toc.json
10/5/25, 15:19LMS | Whizlabs
Page 59 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectWould this fulfill the requirement?
Explanation:Answer – BThis is used to control access to resources and can’t be used for billing purposes.For more information on Role-based access control, please visit the below URL-Ask our ExpertsDid you like this Question?Question 42Domain: Manage Azure identities and governanceYour company uses Azure Virtual Machines for its enterprise applications. You need to use Azure Policy to do some of the morecommon tasks related to creating, assigning, and managing policies across your organization. You can create a policy with the RESTAPI for Azure Policy Definitions. The REST API allows you to create and delete policy definitions and get information about existingdefinitions.Is this statement correct? [Select Yes or No]
Explanation:Correct Answer – AThe statement is correct. The REST API for Azure Policy Definitions allows you to create, delete, and get information about policydefinitions. It also enables you to create, assign, and manage policies across your organization.Reference: Tutorial: Build policies to enforce compliance - Azure Policy | Microsoft LearnAzure REST API reference documentation | Microsoft LearnA. YesB. Noright
https://docs.microsoft.com/en-us/azure/role-based-access-control/overview
A. YesrightB. Nowrong
10/5/25, 15:19LMS | Whizlabs
Page 60 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectAsk our ExpertsDid you like this Question?Question 43Domain: Manage Azure identities and governanceA company has the following resources deployed to their Azure subscription.NameTypeResource Groupwhizlab-vnet1Virtual Networkwhizlabs-rgwhizlab-vnet2Virtual Networkwhizlabs-rgwhizlabvmVirtual machinewhizlabs-rg The virtual machine whizlabvm is currently in a running state.The company now assigns the below Azure policy. 
 
10/5/25, 15:19LMS | Whizlabs
Page 61 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Incorrect
The Not Allowed resources types areWould the state of the virtual machine change to deallocated?
Explanation:Correct Answer – BAzure policies would only highlight the compliance of existing resources and enforce the policy restrictions on new resources.Here, the virtual machine whizlabvm is currently in a running state, and the company assigns the "Not allowed resource types Azurepolicy" Not allowed resource types (Deny): Prevents a list of resource types from being deployed.Hence the state of the virtual machine would remain as it is.For more information on Azure policies, please visit the below URL-
Ask our ExpertsDid you like this Question?Question 44Domain: Manage Azure identities and governanceMicrosoft.Network/virtualNetworksMicrosoft/Compute/virtualMachinesA. YeswrongB. Noright
Overview of Azure Policy - Azure Policy | Microsoft Docs1Overview of Azure Policy - Azure Policy | Microsoft Docs2
10/5/25, 15:19LMS | Whizlabs
Page 62 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
A company has the following resources deployed to their Azure subscription.NameTypeResource Groupwhizlab-vnet1Virtual Networkwhizlabs-rgwhizlab-vnet2Virtual Networkwhizlabs-rgwhizlabvmVirtual machinewhizlabs-rg The virtual machine whizlabvm is currently running.The company now assigns the below Azure policy.
 
The Not Allowed resources types areWould an administrator be able to modify the address space of whizlab-vnet2?Microsoft.Network/virtualNetworksMicrosoft/Compute/virtualMachines
10/5/25, 15:19LMS | Whizlabs
Page 63 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectExplanation:Answer – BAzure Policy: "Not Allowed Resource Types"The policy blocks:Microsoft.Network/virtualNetworks → affects virtual networksMicrosoft.Compute/virtualMachines → affects virtual machinesThis means any operation that involves creating, updating, or modifying these resource types is denied, even if the resources alreadyexist.Changing the address space of a virtual network is considered a modification to Microsoft.Network/virtualNetworks resource type.Since this type is explicitly disallowed by the policy, no changes can be made even by an administrator.Azure policies apply at the subscription or resource group level, and they enforce compliance by blocking actions that violate therules.The policy doesn’t just prevent the creation of new virtual networks or VMs; it also blocks updates to existing ones.Even though whizlab-vnet2 already exists, modifying its configuration (like address space) is treated as an update and is thereforenot permitted.For more information on Azure policies, please visit the URL below-Ask our ExpertsDid you like this Question?Question 45Domain: Implement and manage storageA team is currently storing all of their objects in an Azure storage account. They are using the Azure Blob service. They want to create alifecycle management rule that would do the following.The Lifecycle rule would be applied to a container called demo and a folder within the container called data.You have to complete the following JSON snippet for the Lifecycle rule.A. YeswrongB. Noright
https://docs.microsoft.com/en-us/azure/governance/policy/overview
Change the objects' tier level to the cool tier if they have not been modified in the past 30 days.Archive an object if they have not been modified in the past 90 days.
10/5/25, 15:19LMS | Whizlabs
Page 64 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Which of the following would go into Slot1?
Explanation:Answer – DThe format of the prefixMatch is container/folder: demo/data. An example of this is given in the Microsoft documentation.
A. demowrongB. dataC. data/demoD. demo/dataright
10/5/25, 15:19LMS | Whizlabs
Page 65 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectSince this is clearly mentioned in the Microsoft documentation, all other options are invalid.For more information on lifecycle management rules, please visit the below URL-Ask our ExpertsDid you like this Question?Question 46Domain: Implement and manage storageA team is currently storing all of their objects in an Azure storage account. They are using the Azure Blob service. They want to create alifecycle management rule that would do the following.The Lifecycle rule would be applied to a container called demo and a folder within the container called data.You have to complete the following JSON snippet for the Lifecycle rule.
Which of the following would go into Slot2?
Explanation:https://docs.microsoft.com/en-us/azure/storage/blobs/storage-lifecycle-management-concepts
Change the objects' tier level to the cool tier if they have not been modified in the past 30 days.Archive an object if they have not been modified in the past 90 days.
A. 15B. 30rightC. 90D. 120
10/5/25, 15:19LMS | Whizlabs
Page 66 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectAnswer – BSince the question states that we need to move the objects to the cool tier after 30 days, this should be the value for tierToCool.
An example of this is given in the Microsoft documentation.Since this is clearly mentioned in the Microsoft documentation, all other options are invalid.For more information on lifecycle management rules, please visit the below URL-Ask our ExpertsDid you like this Question?Question 47Domain: Implement and manage storageA team is currently storing all of their objects in an Azure storage account. They are using the Azure Blob service. They want to create alifecycle management rule that would do the following.https://docs.microsoft.com/en-us/azure/storage/blobs/storage-lifecycle-management-concepts
Change the objects' tier level to the cool tier if they have not been modified in the past 30 days.Archive an object if they have not been modified in the past 90 days.
10/5/25, 15:19LMS | Whizlabs
Page 67 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
The Lifecycle rule would be applied to a container called demo and a folder within the container called data.You have to complete the following JSON snippet for the Lifecycle rule.
Which of the following would go into Slot3?
Explanation:Answer – CSince the question states that we need to move the objects to the archive tier after 90 days, this should be the value fortierToArchive.A. 15B. 30C. 90rightD. 120
10/5/25, 15:19LMS | Whizlabs
Page 68 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
Since this is clearly mentioned in the Microsoft documentation, all other options are invalid.For more information on lifecycle management rules, please visit the below URL-Ask our ExpertsDid you like this Question?Question 48Domain: Implement and manage storageA team is currently making use of an Azure storage account as shown below
https://docs.microsoft.com/en-us/azure/storage/blobs/storage-lifecycle-management-concepts
10/5/25, 15:19LMS | Whizlabs
Page 69 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
A file named audio.log has been uploaded to a container called demo.Which of the following is a valid URL that could be used to access the file?
Explanation:Answer – CThe URL of the accessing an object must be https://<storageAccountName>.blob.core.windows.net /<containerName>/<objectName>:https://whizlabstore.blob.core.windows.net/demo/audio.logThe Microsoft documentation mentions the following on the format of the URL for blob objects.
Since this is clearly mentioned in the Microsoft documentation, all other options are invalid.For more information on the blob service, please visit the below URLA. https://whizlabstore/demo/audio.logB. https://whizlabstore.blob.core.windows.net/audio.logC. https://whizlabstore.blob.core.windows.net/demo/audio.logrightD. https://whizlabstore/audio.log
https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction
10/5/25, 15:19LMS | Whizlabs
Page 70 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectAsk our ExpertsDid you like this Question?Question 49Domain: Implement and manage storageA team is currently making use of an Azure storage account, as shown below.
A file named audio.log has been uploaded to a container called demo.You need to allow users to download the object. The access should be granted for a day only. You need to provide a secure way toaccess the object. Which of the following would you implement for this purpose?
Explanation:Answer – CThe secure way to implement this is to generate a shared access signature. The Microsoft documentation mentions the following.A. Provide access Keys.B. Mark public access on the container.C. Generate a shared access signature.rightD. Mark public access on the object.wrong
10/5/25, 15:19LMS | Whizlabs
Page 71 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
Correct
All of the other ways are incorrect since they don’t provide secure access to the storage account object.For more information on Shared access signatures, please visit the below URL-Ask our ExpertsDid you like this Question?Question 50Domain: Manage Azure identities and governanceA company currently has a set of Azure virtual machines. They want to ensure that their IT administrative team gets alert when any ofthe virtual machines are shut down.They decide to create alerts based on Activity Logs in Azure Monitor.Would this fulfill the requirement?https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview
A. YesrightB. No
10/5/25, 15:19LMS | Whizlabs
Page 72 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectExplanation:Answer – AThe Activity Log service provides insights for all resource activities within your subscription. An example of events recorded is shownbelow.
You can create alerts based on the Activity logs.For more information on Azure activity logs, please visit the below URLs-Ask our ExpertsDid you like this Question?Question 51Domain: Manage Azure identities and governanceA company currently has a set of Azure virtual machines. They want to ensure that their IT administrative team gets alert when any ofthe virtual machines are shut down.They decide to create alerts in the Azure Advisor service.https://docs.microsoft.com/en-us/azure/azure-monitor/platform/activity-log
10/5/25, 15:19LMS | Whizlabs
Page 73 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectWould this fulfill the requirement?
Explanation:Answer – BThe Azure Advisor service is used as a recommendation engine and can’t be used to record virtual machines' activities.For more information on Azure Advisor, please visit the below URL-Ask our ExpertsDid you like this Question?Question 52Domain: Manage Azure identities and governanceA company currently has a set of Azure virtual machines. They want to ensure that their IT administrative team gets alert when anyvirtual machines are shut down.They decide to create alerts in the Service Health service.Would this fulfill the requirement?
Explanation:Answer – BThe Service Health service is used to inform users of the health of Azure-based services.For more information on Azure Service Health, please visit the below URL-A. YesB. Noright
https://docs.microsoft.com/en-us/azure/advisor/advisor-overview
A. YesB. Noright
https://azure.microsoft.com/en-us/features/service-health
10/5/25, 15:19LMS | Whizlabs
Page 74 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectView Case StudyAsk our ExpertsDid you like this Question?Question 53Domain: Implement and manage storageYou need to provision the Azure storage account. You need to complete the below Azure CLI script for this.
Which of the following would go into Slot1?
Explanation:Answer- BWe need to keep costs minimized. There is no mention in the question on Fault tolerance and disaster recovery. We can opt for LocalRedundant storage.Since this is the most cost-effective approach, all other options are incorrect.For more information on Data Redundancy, please visit the below URL-Ask our ExpertsA. Standard_GRSB. Standard_LRSrightC. Standard_RAGRSwrongD. Standard_ZRS
https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy
10/5/25, 15:19LMS | Whizlabs
Page 75 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
IncorrectView Case StudyDid you like this Question?Question 54Domain: Implement and manage virtual networkingYou need to configure a VPN connection for whizlabs-net2. Which of the following would you need to configure in the virtual network?
Explanation:Answer – BFor the Virtual network, you need to have a gateway subnet.The Microsoft documentation mentions the following.
Since this is clearly mentioned in the documentation, all other options are incorrect.A. An additional address spaceB. A gateway subnetrightC. A peering connectionD. An express route connectionwrong
10/5/25, 15:19LMS | Whizlabs
Page 76 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327
CorrectView Case StudyFor more information on Site-to-Site VPN connections, please visit the below URL-Ask our ExpertsDid you like this Question?Question 55Domain: Implement and manage virtual networkingYou have to ensure that users can communicate with the virtual machine whizlabapi on port number 80. You decide to create anOutbound rule in the Network Security Group associated with the virtual machine's network interface.Would this fulfill the requirement?
Explanation:Answer – BYou need to add an Inbound security rule and not an Outbound Security rule.For more information on network security, please visit the below URL-Ask our ExpertsDid you like this Question?Finish Reviewhttps://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-site-to-site-resource-manager-portal
A. YesB. Noright
https://docs.microsoft.com/en-us/azure/virtual-network/security-overview
10/5/25, 15:19LMS | Whizlabs
Page 77 of 77https://www.whizlabs.com/learn/course/microsoft-azure-certification-az-104/298/quiz/17868/report/8435327CategoriesPopular CoursesCompanyLegalSupport
Need help? Pleaseor+91 6364678444
©2025, Whizlabs Software Pvt. Ltd. All rights reserved.cdHands-on LabsSandboxSubscriptionFor BusinessLibraryCloud Computing CertificationsAmazon Web Services (AWS)Microsoft AzureGoogle CloudDevOpsCyber SecurityMicrosoft Power PlatformMicrosoft 365 CertificationsJava CertificationsAWS Certified Solutions Architect AssociateAWS Certified Cloud PractitionerMicrosoft Azure Exam AZ-204 CertificationMicrosoft Azure Exam AZ-900 CertificationGoogle Cloud Certified Associate Cloud EngineerMicrosoft Power Platform Fundamentals (PL-900)HashiCorp Certified Terraform Associate Certific…Snowflake SnowPro Core CertificationDocker Certified AssociateAbout UsBlogReviewsCareersTeam AccountPrivacy PolicyTerms of UseEULARefund PolicyPrograms GuaranteeContact UsFAQs
